{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcd2c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "67fa5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.Module):\n",
    "    def __init__(self, out_shape, activation=None, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.out_shape = out_shape\n",
    "        self.is_built = False\n",
    "        self.activation = activation\n",
    "    def __call__(self, X, w=None, b=None):\n",
    "        \n",
    "        ## Initializing for the firs time\n",
    "        if not self.is_built:\n",
    "            self.w = tf.Variable(tf.random.normal([X.shape[-1],self.out_shape]), name='w')\n",
    "            self.b = tf.Variable(tf.zeros([self.out_shape]), name='b')\n",
    "            self.is_built = True\n",
    "        \n",
    "        ## For predictign with custom weights  \n",
    "        ## Forward propagation\n",
    "        if w is None and b is None:\n",
    "            y = tf.matmul(X, self.w) + self.b\n",
    "        else:\n",
    "            y = tf.matmul(X, w) + b\n",
    "        \n",
    "        ## Adding activation function\n",
    "        \n",
    "        if self.activation=='relu':\n",
    "            y = tf.nn.relu(y)\n",
    "        elif self.activation=='sigmoid':\n",
    "            y = tf.nn.sigmoid(y)\n",
    "            \n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83c2bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.Module):\n",
    "    def __init__(self, layers, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.layers = layers\n",
    "    \n",
    "    def __call__(self, X, w=None, b=None):\n",
    "        inputs = X\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if w is None and b is None:\n",
    "                inputs = layer(inputs)\n",
    "            else:\n",
    "                inputs = layer(inputs, w[i], b[i])\n",
    "        return inputs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5226afd",
   "metadata": {},
   "source": [
    "### Simple Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b19f75d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant([[0,0], [0,1], [1,0], [1,1]], dtype='float32')\n",
    "Y = tf.constant([[0], [1], [1], [0]], dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5c93e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Dense(3, activation ='sigmoid')\n",
    "dense2 = Dense(1)\n",
    "\n",
    "model1 = Model([dense1, dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f6cd99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: \n",
      " mean_squared_error: 1.0311150550842285\n",
      "Epoch 2: \n",
      " mean_squared_error: 0.5170043706893921\n",
      "Epoch 3: \n",
      " mean_squared_error: 0.3466901481151581\n",
      "Epoch 4: \n",
      " mean_squared_error: 0.2897663712501526\n",
      "Epoch 5: \n",
      " mean_squared_error: 0.2705887258052826\n",
      "Epoch 6: \n",
      " mean_squared_error: 0.26400744915008545\n",
      "Epoch 7: \n",
      " mean_squared_error: 0.26163437962532043\n",
      "Epoch 8: \n",
      " mean_squared_error: 0.2606702446937561\n",
      "Epoch 9: \n",
      " mean_squared_error: 0.2601810097694397\n",
      "Epoch 10: \n",
      " mean_squared_error: 0.25985443592071533\n",
      "Epoch 11: \n",
      " mean_squared_error: 0.2595866024494171\n",
      "Epoch 12: \n",
      " mean_squared_error: 0.2593424320220947\n",
      "Epoch 13: \n",
      " mean_squared_error: 0.2591102719306946\n",
      "Epoch 14: \n",
      " mean_squared_error: 0.25888592004776\n",
      "Epoch 15: \n",
      " mean_squared_error: 0.2586681544780731\n",
      "Epoch 16: \n",
      " mean_squared_error: 0.25845617055892944\n",
      "Epoch 17: \n",
      " mean_squared_error: 0.25824975967407227\n",
      "Epoch 18: \n",
      " mean_squared_error: 0.2580486536026001\n",
      "Epoch 19: \n",
      " mean_squared_error: 0.257852703332901\n",
      "Epoch 20: \n",
      " mean_squared_error: 0.25766175985336304\n",
      "Epoch 21: \n",
      " mean_squared_error: 0.2574757933616638\n",
      "Epoch 22: \n",
      " mean_squared_error: 0.2572944760322571\n",
      "Epoch 23: \n",
      " mean_squared_error: 0.2571178376674652\n",
      "Epoch 24: \n",
      " mean_squared_error: 0.25694552063941956\n",
      "Epoch 25: \n",
      " mean_squared_error: 0.25677764415740967\n",
      "Epoch 26: \n",
      " mean_squared_error: 0.256614089012146\n",
      "Epoch 27: \n",
      " mean_squared_error: 0.25645458698272705\n",
      "Epoch 28: \n",
      " mean_squared_error: 0.2562990188598633\n",
      "Epoch 29: \n",
      " mean_squared_error: 0.25614744424819946\n",
      "Epoch 30: \n",
      " mean_squared_error: 0.2559996545314789\n",
      "Epoch 31: \n",
      " mean_squared_error: 0.255855530500412\n",
      "Epoch 32: \n",
      " mean_squared_error: 0.25571495294570923\n",
      "Epoch 33: \n",
      " mean_squared_error: 0.25557783246040344\n",
      "Epoch 34: \n",
      " mean_squared_error: 0.25544410943984985\n",
      "Epoch 35: \n",
      " mean_squared_error: 0.25531381368637085\n",
      "Epoch 36: \n",
      " mean_squared_error: 0.2551865577697754\n",
      "Epoch 37: \n",
      " mean_squared_error: 0.2550625205039978\n",
      "Epoch 38: \n",
      " mean_squared_error: 0.25494158267974854\n",
      "Epoch 39: \n",
      " mean_squared_error: 0.25482356548309326\n",
      "Epoch 40: \n",
      " mean_squared_error: 0.2547083795070648\n",
      "Epoch 41: \n",
      " mean_squared_error: 0.2545960545539856\n",
      "Epoch 42: \n",
      " mean_squared_error: 0.2544865012168884\n",
      "Epoch 43: \n",
      " mean_squared_error: 0.2543795108795166\n",
      "Epoch 44: \n",
      " mean_squared_error: 0.25427520275115967\n",
      "Epoch 45: \n",
      " mean_squared_error: 0.2541733980178833\n",
      "Epoch 46: \n",
      " mean_squared_error: 0.2540740966796875\n",
      "Epoch 47: \n",
      " mean_squared_error: 0.25397711992263794\n",
      "Epoch 48: \n",
      " mean_squared_error: 0.2538824677467346\n",
      "Epoch 49: \n",
      " mean_squared_error: 0.25379008054733276\n",
      "Epoch 50: \n",
      " mean_squared_error: 0.25370001792907715\n",
      "Epoch 51: \n",
      " mean_squared_error: 0.25361204147338867\n",
      "Epoch 52: \n",
      " mean_squared_error: 0.25352612137794495\n",
      "Epoch 53: \n",
      " mean_squared_error: 0.25344234704971313\n",
      "Epoch 54: \n",
      " mean_squared_error: 0.253360390663147\n",
      "Epoch 55: \n",
      " mean_squared_error: 0.2532805800437927\n",
      "Epoch 56: \n",
      " mean_squared_error: 0.2532026171684265\n",
      "Epoch 57: \n",
      " mean_squared_error: 0.25312650203704834\n",
      "Epoch 58: \n",
      " mean_squared_error: 0.25305214524269104\n",
      "Epoch 59: \n",
      " mean_squared_error: 0.2529795169830322\n",
      "Epoch 60: \n",
      " mean_squared_error: 0.2529086470603943\n",
      "Epoch 61: \n",
      " mean_squared_error: 0.25283944606781006\n",
      "Epoch 62: \n",
      " mean_squared_error: 0.25277191400527954\n",
      "Epoch 63: \n",
      " mean_squared_error: 0.2527059018611908\n",
      "Epoch 64: \n",
      " mean_squared_error: 0.2526414394378662\n",
      "Epoch 65: \n",
      " mean_squared_error: 0.252578467130661\n",
      "Epoch 66: \n",
      " mean_squared_error: 0.2525169849395752\n",
      "Epoch 67: \n",
      " mean_squared_error: 0.25245702266693115\n",
      "Epoch 68: \n",
      " mean_squared_error: 0.252398282289505\n",
      "Epoch 69: \n",
      " mean_squared_error: 0.25234100222587585\n",
      "Epoch 70: \n",
      " mean_squared_error: 0.25228506326675415\n",
      "Epoch 71: \n",
      " mean_squared_error: 0.2522304058074951\n",
      "Epoch 72: \n",
      " mean_squared_error: 0.25217700004577637\n",
      "Epoch 73: \n",
      " mean_squared_error: 0.2521248161792755\n",
      "Epoch 74: \n",
      " mean_squared_error: 0.2520737946033478\n",
      "Epoch 75: \n",
      " mean_squared_error: 0.2520240545272827\n",
      "Epoch 76: \n",
      " mean_squared_error: 0.2519753575325012\n",
      "Epoch 77: \n",
      " mean_squared_error: 0.25192779302597046\n",
      "Epoch 78: \n",
      " mean_squared_error: 0.25188136100769043\n",
      "Epoch 79: \n",
      " mean_squared_error: 0.2518359124660492\n",
      "Epoch 80: \n",
      " mean_squared_error: 0.2517915964126587\n",
      "Epoch 81: \n",
      " mean_squared_error: 0.2517482042312622\n",
      "Epoch 82: \n",
      " mean_squared_error: 0.2517058551311493\n",
      "Epoch 83: \n",
      " mean_squared_error: 0.2516644299030304\n",
      "Epoch 84: \n",
      " mean_squared_error: 0.2516239881515503\n",
      "Epoch 85: \n",
      " mean_squared_error: 0.2515844404697418\n",
      "Epoch 86: \n",
      " mean_squared_error: 0.2515457272529602\n",
      "Epoch 87: \n",
      " mean_squared_error: 0.2515079379081726\n",
      "Epoch 88: \n",
      " mean_squared_error: 0.25147104263305664\n",
      "Epoch 89: \n",
      " mean_squared_error: 0.25143492221832275\n",
      "Epoch 90: \n",
      " mean_squared_error: 0.25139957666397095\n",
      "Epoch 91: \n",
      " mean_squared_error: 0.251365065574646\n",
      "Epoch 92: \n",
      " mean_squared_error: 0.25133129954338074\n",
      "Epoch 93: \n",
      " mean_squared_error: 0.25129830837249756\n",
      "Epoch 94: \n",
      " mean_squared_error: 0.2512660622596741\n",
      "Epoch 95: \n",
      " mean_squared_error: 0.2512344717979431\n",
      "Epoch 96: \n",
      " mean_squared_error: 0.25120365619659424\n",
      "Epoch 97: \n",
      " mean_squared_error: 0.2511734664440155\n",
      "Epoch 98: \n",
      " mean_squared_error: 0.2511439621448517\n",
      "Epoch 99: \n",
      " mean_squared_error: 0.251115083694458\n",
      "Epoch 100: \n",
      " mean_squared_error: 0.251086950302124\n",
      "Epoch 101: \n",
      " mean_squared_error: 0.251059353351593\n",
      "Epoch 102: \n",
      " mean_squared_error: 0.251032292842865\n",
      "Epoch 103: \n",
      " mean_squared_error: 0.2510058879852295\n",
      "Epoch 104: \n",
      " mean_squared_error: 0.2509799599647522\n",
      "Epoch 105: \n",
      " mean_squared_error: 0.250954806804657\n",
      "Epoch 106: \n",
      " mean_squared_error: 0.25092998147010803\n",
      "Epoch 107: \n",
      " mean_squared_error: 0.2509058117866516\n",
      "Epoch 108: \n",
      " mean_squared_error: 0.25088220834732056\n",
      "Epoch 109: \n",
      " mean_squared_error: 0.25085902214050293\n",
      "Epoch 110: \n",
      " mean_squared_error: 0.2508363723754883\n",
      "Epoch 111: \n",
      " mean_squared_error: 0.25081419944763184\n",
      "Epoch 112: \n",
      " mean_squared_error: 0.2507925033569336\n",
      "Epoch 113: \n",
      " mean_squared_error: 0.25077128410339355\n",
      "Epoch 114: \n",
      " mean_squared_error: 0.25075045228004456\n",
      "Epoch 115: \n",
      " mean_squared_error: 0.25073015689849854\n",
      "Epoch 116: \n",
      " mean_squared_error: 0.25071030855178833\n",
      "Epoch 117: \n",
      " mean_squared_error: 0.25069084763526917\n",
      "Epoch 118: \n",
      " mean_squared_error: 0.2506716847419739\n",
      "Epoch 119: \n",
      " mean_squared_error: 0.25065308809280396\n",
      "Epoch 120: \n",
      " mean_squared_error: 0.25063472986221313\n",
      "Epoch 121: \n",
      " mean_squared_error: 0.2506168782711029\n",
      "Epoch 122: \n",
      " mean_squared_error: 0.25059929490089417\n",
      "Epoch 123: \n",
      " mean_squared_error: 0.25058218836784363\n",
      "Epoch 124: \n",
      " mean_squared_error: 0.25056540966033936\n",
      "Epoch 125: \n",
      " mean_squared_error: 0.2505488991737366\n",
      "Epoch 126: \n",
      " mean_squared_error: 0.2505328059196472\n",
      "Epoch 127: \n",
      " mean_squared_error: 0.25051701068878174\n",
      "Epoch 128: \n",
      " mean_squared_error: 0.2505016028881073\n",
      "Epoch 129: \n",
      " mean_squared_error: 0.2504863739013672\n",
      "Epoch 130: \n",
      " mean_squared_error: 0.2504715919494629\n",
      "Epoch 131: \n",
      " mean_squared_error: 0.2504570186138153\n",
      "Epoch 132: \n",
      " mean_squared_error: 0.25044286251068115\n",
      "Epoch 133: \n",
      " mean_squared_error: 0.2504289150238037\n",
      "Epoch 134: \n",
      " mean_squared_error: 0.250415176153183\n",
      "Epoch 135: \n",
      " mean_squared_error: 0.2504018247127533\n",
      "Epoch 136: \n",
      " mean_squared_error: 0.2503887414932251\n",
      "Epoch 137: \n",
      " mean_squared_error: 0.2503758668899536\n",
      "Epoch 138: \n",
      " mean_squared_error: 0.25036320090293884\n",
      "Epoch 139: \n",
      " mean_squared_error: 0.2503509223461151\n",
      "Epoch 140: \n",
      " mean_squared_error: 0.25033876299858093\n",
      "Epoch 141: \n",
      " mean_squared_error: 0.250326931476593\n",
      "Epoch 142: \n",
      " mean_squared_error: 0.25031524896621704\n",
      "Epoch 143: \n",
      " mean_squared_error: 0.25030389428138733\n",
      "Epoch 144: \n",
      " mean_squared_error: 0.25029265880584717\n",
      "Epoch 145: \n",
      " mean_squared_error: 0.2502817213535309\n",
      "Epoch 146: \n",
      " mean_squared_error: 0.25027093291282654\n",
      "Epoch 147: \n",
      " mean_squared_error: 0.2502604126930237\n",
      "Epoch 148: \n",
      " mean_squared_error: 0.250249981880188\n",
      "Epoch 149: \n",
      " mean_squared_error: 0.25023990869522095\n",
      "Epoch 150: \n",
      " mean_squared_error: 0.25022998452186584\n",
      "Epoch 151: \n",
      " mean_squared_error: 0.2502201795578003\n",
      "Epoch 152: \n",
      " mean_squared_error: 0.25021058320999146\n",
      "Epoch 153: \n",
      " mean_squared_error: 0.25020116567611694\n",
      "Epoch 154: \n",
      " mean_squared_error: 0.25019192695617676\n",
      "Epoch 155: \n",
      " mean_squared_error: 0.2501828670501709\n",
      "Epoch 156: \n",
      " mean_squared_error: 0.25017401576042175\n",
      "Epoch 157: \n",
      " mean_squared_error: 0.25016525387763977\n",
      "Epoch 158: \n",
      " mean_squared_error: 0.2501567006111145\n",
      "Epoch 159: \n",
      " mean_squared_error: 0.2501482665538788\n",
      "Epoch 160: \n",
      " mean_squared_error: 0.25014007091522217\n",
      "Epoch 161: \n",
      " mean_squared_error: 0.25013190507888794\n",
      "Epoch 162: \n",
      " mean_squared_error: 0.2501239776611328\n",
      "Epoch 163: \n",
      " mean_squared_error: 0.2501161992549896\n",
      "Epoch 164: \n",
      " mean_squared_error: 0.25010839104652405\n",
      "Epoch 165: \n",
      " mean_squared_error: 0.25010085105895996\n",
      "Epoch 166: \n",
      " mean_squared_error: 0.2500934600830078\n",
      "Epoch 167: \n",
      " mean_squared_error: 0.2500862181186676\n",
      "Epoch 168: \n",
      " mean_squared_error: 0.25007903575897217\n",
      "Epoch 169: \n",
      " mean_squared_error: 0.2500719726085663\n",
      "Epoch 170: \n",
      " mean_squared_error: 0.25006502866744995\n",
      "Epoch 171: \n",
      " mean_squared_error: 0.2500583231449127\n",
      "Epoch 172: \n",
      " mean_squared_error: 0.2500515580177307\n",
      "Epoch 173: \n",
      " mean_squared_error: 0.2500450015068054\n",
      "Epoch 174: \n",
      " mean_squared_error: 0.2500385642051697\n",
      "Epoch 175: \n",
      " mean_squared_error: 0.2500322461128235\n",
      "Epoch 176: \n",
      " mean_squared_error: 0.25002598762512207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177: \n",
      " mean_squared_error: 0.2500198483467102\n",
      "Epoch 178: \n",
      " mean_squared_error: 0.2500137686729431\n",
      "Epoch 179: \n",
      " mean_squared_error: 0.25000786781311035\n",
      "Epoch 180: \n",
      " mean_squared_error: 0.25000205636024475\n",
      "Epoch 181: \n",
      " mean_squared_error: 0.24999627470970154\n",
      "Epoch 182: \n",
      " mean_squared_error: 0.24999059736728668\n",
      "Epoch 183: \n",
      " mean_squared_error: 0.24998505413532257\n",
      "Epoch 184: \n",
      " mean_squared_error: 0.24997952580451965\n",
      "Epoch 185: \n",
      " mean_squared_error: 0.24997404217720032\n",
      "Epoch 186: \n",
      " mean_squared_error: 0.24996879696846008\n",
      "Epoch 187: \n",
      " mean_squared_error: 0.24996355175971985\n",
      "Epoch 188: \n",
      " mean_squared_error: 0.24995842576026917\n",
      "Epoch 189: \n",
      " mean_squared_error: 0.2499532699584961\n",
      "Epoch 190: \n",
      " mean_squared_error: 0.24994826316833496\n",
      "Epoch 191: \n",
      " mean_squared_error: 0.24994336068630219\n",
      "Epoch 192: \n",
      " mean_squared_error: 0.24993856251239777\n",
      "Epoch 193: \n",
      " mean_squared_error: 0.24993379414081573\n",
      "Epoch 194: \n",
      " mean_squared_error: 0.24992899596691132\n",
      "Epoch 195: \n",
      " mean_squared_error: 0.24992439150810242\n",
      "Epoch 196: \n",
      " mean_squared_error: 0.2499198168516159\n",
      "Epoch 197: \n",
      " mean_squared_error: 0.24991527199745178\n",
      "Epoch 198: \n",
      " mean_squared_error: 0.2499108463525772\n",
      "Epoch 199: \n",
      " mean_squared_error: 0.24990637600421906\n",
      "Epoch 200: \n",
      " mean_squared_error: 0.24990206956863403\n",
      "Epoch 201: \n",
      " mean_squared_error: 0.2498977929353714\n",
      "Epoch 202: \n",
      " mean_squared_error: 0.24989356100559235\n",
      "Epoch 203: \n",
      " mean_squared_error: 0.2498893439769745\n",
      "Epoch 204: \n",
      " mean_squared_error: 0.24988529086112976\n",
      "Epoch 205: \n",
      " mean_squared_error: 0.24988120794296265\n",
      "Epoch 206: \n",
      " mean_squared_error: 0.24987724423408508\n",
      "Epoch 207: \n",
      " mean_squared_error: 0.24987328052520752\n",
      "Epoch 208: \n",
      " mean_squared_error: 0.24986937642097473\n",
      "Epoch 209: \n",
      " mean_squared_error: 0.24986550211906433\n",
      "Epoch 210: \n",
      " mean_squared_error: 0.24986165761947632\n",
      "Epoch 211: \n",
      " mean_squared_error: 0.24985796213150024\n",
      "Epoch 212: \n",
      " mean_squared_error: 0.2498541623353958\n",
      "Epoch 213: \n",
      " mean_squared_error: 0.24985046684741974\n",
      "Epoch 214: \n",
      " mean_squared_error: 0.2498469352722168\n",
      "Epoch 215: \n",
      " mean_squared_error: 0.2498432695865631\n",
      "Epoch 216: \n",
      " mean_squared_error: 0.24983979761600494\n",
      "Epoch 217: \n",
      " mean_squared_error: 0.24983620643615723\n",
      "Epoch 218: \n",
      " mean_squared_error: 0.24983279407024384\n",
      "Epoch 219: \n",
      " mean_squared_error: 0.24982932209968567\n",
      "Epoch 220: \n",
      " mean_squared_error: 0.24982596933841705\n",
      "Epoch 221: \n",
      " mean_squared_error: 0.24982257187366486\n",
      "Epoch 222: \n",
      " mean_squared_error: 0.24981927871704102\n",
      "Epoch 223: \n",
      " mean_squared_error: 0.24981603026390076\n",
      "Epoch 224: \n",
      " mean_squared_error: 0.2498127669095993\n",
      "Epoch 225: \n",
      " mean_squared_error: 0.24980948865413666\n",
      "Epoch 226: \n",
      " mean_squared_error: 0.24980640411376953\n",
      "Epoch 227: \n",
      " mean_squared_error: 0.24980318546295166\n",
      "Epoch 228: \n",
      " mean_squared_error: 0.24980005621910095\n",
      "Epoch 229: \n",
      " mean_squared_error: 0.2497970014810562\n",
      "Epoch 230: \n",
      " mean_squared_error: 0.2497938722372055\n",
      "Epoch 231: \n",
      " mean_squared_error: 0.24979087710380554\n",
      "Epoch 232: \n",
      " mean_squared_error: 0.24978789687156677\n",
      "Epoch 233: \n",
      " mean_squared_error: 0.2497849464416504\n",
      "Epoch 234: \n",
      " mean_squared_error: 0.24978196620941162\n",
      "Epoch 235: \n",
      " mean_squared_error: 0.24977895617485046\n",
      "Epoch 236: \n",
      " mean_squared_error: 0.24977613985538483\n",
      "Epoch 237: \n",
      " mean_squared_error: 0.24977326393127441\n",
      "Epoch 238: \n",
      " mean_squared_error: 0.2497704029083252\n",
      "Epoch 239: \n",
      " mean_squared_error: 0.24976754188537598\n",
      "Epoch 240: \n",
      " mean_squared_error: 0.24976474046707153\n",
      "Epoch 241: \n",
      " mean_squared_error: 0.24976198375225067\n",
      "Epoch 242: \n",
      " mean_squared_error: 0.249759241938591\n",
      "Epoch 243: \n",
      " mean_squared_error: 0.24975647032260895\n",
      "Epoch 244: \n",
      " mean_squared_error: 0.24975374341011047\n",
      "Epoch 245: \n",
      " mean_squared_error: 0.24975106120109558\n",
      "Epoch 246: \n",
      " mean_squared_error: 0.24974842369556427\n",
      "Epoch 247: \n",
      " mean_squared_error: 0.24974577128887177\n",
      "Epoch 248: \n",
      " mean_squared_error: 0.24974310398101807\n",
      "Epoch 249: \n",
      " mean_squared_error: 0.24974045157432556\n",
      "Epoch 250: \n",
      " mean_squared_error: 0.24973785877227783\n",
      "Epoch 251: \n",
      " mean_squared_error: 0.2497352957725525\n",
      "Epoch 252: \n",
      " mean_squared_error: 0.2497328221797943\n",
      "Epoch 253: \n",
      " mean_squared_error: 0.2497301995754242\n",
      "Epoch 254: \n",
      " mean_squared_error: 0.24972769618034363\n",
      "Epoch 255: \n",
      " mean_squared_error: 0.24972517788410187\n",
      "Epoch 256: \n",
      " mean_squared_error: 0.2497226595878601\n",
      "Epoch 257: \n",
      " mean_squared_error: 0.24972014129161835\n",
      "Epoch 258: \n",
      " mean_squared_error: 0.24971771240234375\n",
      "Epoch 259: \n",
      " mean_squared_error: 0.24971522390842438\n",
      "Epoch 260: \n",
      " mean_squared_error: 0.24971280992031097\n",
      "Epoch 261: \n",
      " mean_squared_error: 0.24971038103103638\n",
      "Epoch 262: \n",
      " mean_squared_error: 0.24970798194408417\n",
      "Epoch 263: \n",
      " mean_squared_error: 0.24970558285713196\n",
      "Epoch 264: \n",
      " mean_squared_error: 0.24970319867134094\n",
      "Epoch 265: \n",
      " mean_squared_error: 0.24970081448554993\n",
      "Epoch 266: \n",
      " mean_squared_error: 0.24969840049743652\n",
      "Epoch 267: \n",
      " mean_squared_error: 0.24969607591629028\n",
      "Epoch 268: \n",
      " mean_squared_error: 0.24969372153282166\n",
      "Epoch 269: \n",
      " mean_squared_error: 0.2496914267539978\n",
      "Epoch 270: \n",
      " mean_squared_error: 0.24968913197517395\n",
      "Epoch 271: \n",
      " mean_squared_error: 0.24968686699867249\n",
      "Epoch 272: \n",
      " mean_squared_error: 0.24968452751636505\n",
      "Epoch 273: \n",
      " mean_squared_error: 0.24968217313289642\n",
      "Epoch 274: \n",
      " mean_squared_error: 0.24967995285987854\n",
      "Epoch 275: \n",
      " mean_squared_error: 0.24967768788337708\n",
      "Epoch 276: \n",
      " mean_squared_error: 0.24967536330223083\n",
      "Epoch 277: \n",
      " mean_squared_error: 0.24967315793037415\n",
      "Epoch 278: \n",
      " mean_squared_error: 0.24967096745967865\n",
      "Epoch 279: \n",
      " mean_squared_error: 0.24966874718666077\n",
      "Epoch 280: \n",
      " mean_squared_error: 0.2496665120124817\n",
      "Epoch 281: \n",
      " mean_squared_error: 0.249664306640625\n",
      "Epoch 282: \n",
      " mean_squared_error: 0.24966208636760712\n",
      "Epoch 283: \n",
      " mean_squared_error: 0.24965983629226685\n",
      "Epoch 284: \n",
      " mean_squared_error: 0.24965769052505493\n",
      "Epoch 285: \n",
      " mean_squared_error: 0.24965545535087585\n",
      "Epoch 286: \n",
      " mean_squared_error: 0.24965332448482513\n",
      "Epoch 287: \n",
      " mean_squared_error: 0.24965111911296844\n",
      "Epoch 288: \n",
      " mean_squared_error: 0.24964900314807892\n",
      "Epoch 289: \n",
      " mean_squared_error: 0.24964682757854462\n",
      "Epoch 290: \n",
      " mean_squared_error: 0.24964465200901031\n",
      "Epoch 291: \n",
      " mean_squared_error: 0.24964246153831482\n",
      "Epoch 292: \n",
      " mean_squared_error: 0.24964044988155365\n",
      "Epoch 293: \n",
      " mean_squared_error: 0.24963825941085815\n",
      "Epoch 294: \n",
      " mean_squared_error: 0.24963611364364624\n",
      "Epoch 295: \n",
      " mean_squared_error: 0.2496339976787567\n",
      "Epoch 296: \n",
      " mean_squared_error: 0.24963191151618958\n",
      "Epoch 297: \n",
      " mean_squared_error: 0.24962979555130005\n",
      "Epoch 298: \n",
      " mean_squared_error: 0.2496277391910553\n",
      "Epoch 299: \n",
      " mean_squared_error: 0.24962551891803741\n",
      "Epoch 300: \n",
      " mean_squared_error: 0.24962350726127625\n",
      "Epoch 301: \n",
      " mean_squared_error: 0.24962136149406433\n",
      "Epoch 302: \n",
      " mean_squared_error: 0.2496192753314972\n",
      "Epoch 303: \n",
      " mean_squared_error: 0.24961714446544647\n",
      "Epoch 304: \n",
      " mean_squared_error: 0.24961507320404053\n",
      "Epoch 305: \n",
      " mean_squared_error: 0.24961301684379578\n",
      "Epoch 306: \n",
      " mean_squared_error: 0.2496109902858734\n",
      "Epoch 307: \n",
      " mean_squared_error: 0.2496088594198227\n",
      "Epoch 308: \n",
      " mean_squared_error: 0.24960678815841675\n",
      "Epoch 309: \n",
      " mean_squared_error: 0.2496047168970108\n",
      "Epoch 310: \n",
      " mean_squared_error: 0.24960267543792725\n",
      "Epoch 311: \n",
      " mean_squared_error: 0.2496006339788437\n",
      "Epoch 312: \n",
      " mean_squared_error: 0.24959860742092133\n",
      "Epoch 313: \n",
      " mean_squared_error: 0.24959653615951538\n",
      "Epoch 314: \n",
      " mean_squared_error: 0.24959446489810944\n",
      "Epoch 315: \n",
      " mean_squared_error: 0.24959242343902588\n",
      "Epoch 316: \n",
      " mean_squared_error: 0.24959033727645874\n",
      "Epoch 317: \n",
      " mean_squared_error: 0.24958832561969757\n",
      "Epoch 318: \n",
      " mean_squared_error: 0.249586284160614\n",
      "Epoch 319: \n",
      " mean_squared_error: 0.24958427250385284\n",
      "Epoch 320: \n",
      " mean_squared_error: 0.2495822012424469\n",
      "Epoch 321: \n",
      " mean_squared_error: 0.24958017468452454\n",
      "Epoch 322: \n",
      " mean_squared_error: 0.24957819283008575\n",
      "Epoch 323: \n",
      " mean_squared_error: 0.2495761215686798\n",
      "Epoch 324: \n",
      " mean_squared_error: 0.24957412481307983\n",
      "Epoch 325: \n",
      " mean_squared_error: 0.2495719939470291\n",
      "Epoch 326: \n",
      " mean_squared_error: 0.24957002699375153\n",
      "Epoch 327: \n",
      " mean_squared_error: 0.24956795573234558\n",
      "Epoch 328: \n",
      " mean_squared_error: 0.249565988779068\n",
      "Epoch 329: \n",
      " mean_squared_error: 0.24956390261650085\n",
      "Epoch 330: \n",
      " mean_squared_error: 0.24956192076206207\n",
      "Epoch 331: \n",
      " mean_squared_error: 0.2495599389076233\n",
      "Epoch 332: \n",
      " mean_squared_error: 0.24955792725086212\n",
      "Epoch 333: \n",
      " mean_squared_error: 0.24955591559410095\n",
      "Epoch 334: \n",
      " mean_squared_error: 0.2495538741350174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335: \n",
      " mean_squared_error: 0.2495518922805786\n",
      "Epoch 336: \n",
      " mean_squared_error: 0.24954982101917267\n",
      "Epoch 337: \n",
      " mean_squared_error: 0.2495478242635727\n",
      "Epoch 338: \n",
      " mean_squared_error: 0.24954573810100555\n",
      "Epoch 339: \n",
      " mean_squared_error: 0.24954384565353394\n",
      "Epoch 340: \n",
      " mean_squared_error: 0.24954169988632202\n",
      "Epoch 341: \n",
      " mean_squared_error: 0.24953973293304443\n",
      "Epoch 342: \n",
      " mean_squared_error: 0.24953770637512207\n",
      "Epoch 343: \n",
      " mean_squared_error: 0.24953573942184448\n",
      "Epoch 344: \n",
      " mean_squared_error: 0.2495337426662445\n",
      "Epoch 345: \n",
      " mean_squared_error: 0.24953168630599976\n",
      "Epoch 346: \n",
      " mean_squared_error: 0.24952968955039978\n",
      "Epoch 347: \n",
      " mean_squared_error: 0.24952766299247742\n",
      "Epoch 348: \n",
      " mean_squared_error: 0.24952566623687744\n",
      "Epoch 349: \n",
      " mean_squared_error: 0.24952363967895508\n",
      "Epoch 350: \n",
      " mean_squared_error: 0.2495216280221939\n",
      "Epoch 351: \n",
      " mean_squared_error: 0.24951955676078796\n",
      "Epoch 352: \n",
      " mean_squared_error: 0.24951758980751038\n",
      "Epoch 353: \n",
      " mean_squared_error: 0.2495155781507492\n",
      "Epoch 354: \n",
      " mean_squared_error: 0.24951355159282684\n",
      "Epoch 355: \n",
      " mean_squared_error: 0.24951153993606567\n",
      "Epoch 356: \n",
      " mean_squared_error: 0.24950943887233734\n",
      "Epoch 357: \n",
      " mean_squared_error: 0.24950750172138214\n",
      "Epoch 358: \n",
      " mean_squared_error: 0.24950546026229858\n",
      "Epoch 359: \n",
      " mean_squared_error: 0.24950343370437622\n",
      "Epoch 360: \n",
      " mean_squared_error: 0.24950140714645386\n",
      "Epoch 361: \n",
      " mean_squared_error: 0.24949942529201508\n",
      "Epoch 362: \n",
      " mean_squared_error: 0.24949733912944794\n",
      "Epoch 363: \n",
      " mean_squared_error: 0.24949531257152557\n",
      "Epoch 364: \n",
      " mean_squared_error: 0.24949334561824799\n",
      "Epoch 365: \n",
      " mean_squared_error: 0.24949125945568085\n",
      "Epoch 366: \n",
      " mean_squared_error: 0.24948923289775848\n",
      "Epoch 367: \n",
      " mean_squared_error: 0.24948732554912567\n",
      "Epoch 368: \n",
      " mean_squared_error: 0.24948517978191376\n",
      "Epoch 369: \n",
      " mean_squared_error: 0.2494831681251526\n",
      "Epoch 370: \n",
      " mean_squared_error: 0.2494811713695526\n",
      "Epoch 371: \n",
      " mean_squared_error: 0.24947911500930786\n",
      "Epoch 372: \n",
      " mean_squared_error: 0.2494770884513855\n",
      "Epoch 373: \n",
      " mean_squared_error: 0.24947500228881836\n",
      "Epoch 374: \n",
      " mean_squared_error: 0.2494729608297348\n",
      "Epoch 375: \n",
      " mean_squared_error: 0.24947091937065125\n",
      "Epoch 376: \n",
      " mean_squared_error: 0.24946892261505127\n",
      "Epoch 377: \n",
      " mean_squared_error: 0.24946685135364532\n",
      "Epoch 378: \n",
      " mean_squared_error: 0.24946480989456177\n",
      "Epoch 379: \n",
      " mean_squared_error: 0.24946269392967224\n",
      "Epoch 380: \n",
      " mean_squared_error: 0.24946068227291107\n",
      "Epoch 381: \n",
      " mean_squared_error: 0.2494586557149887\n",
      "Epoch 382: \n",
      " mean_squared_error: 0.24945659935474396\n",
      "Epoch 383: \n",
      " mean_squared_error: 0.24945448338985443\n",
      "Epoch 384: \n",
      " mean_squared_error: 0.24945247173309326\n",
      "Epoch 385: \n",
      " mean_squared_error: 0.2494504153728485\n",
      "Epoch 386: \n",
      " mean_squared_error: 0.24944835901260376\n",
      "Epoch 387: \n",
      " mean_squared_error: 0.24944628775119781\n",
      "Epoch 388: \n",
      " mean_squared_error: 0.24944421648979187\n",
      "Epoch 389: \n",
      " mean_squared_error: 0.24944216012954712\n",
      "Epoch 390: \n",
      " mean_squared_error: 0.2494400590658188\n",
      "Epoch 391: \n",
      " mean_squared_error: 0.24943804740905762\n",
      "Epoch 392: \n",
      " mean_squared_error: 0.2494359016418457\n",
      "Epoch 393: \n",
      " mean_squared_error: 0.24943387508392334\n",
      "Epoch 394: \n",
      " mean_squared_error: 0.2494318038225174\n",
      "Epoch 395: \n",
      " mean_squared_error: 0.24942970275878906\n",
      "Epoch 396: \n",
      " mean_squared_error: 0.24942758679389954\n",
      "Epoch 397: \n",
      " mean_squared_error: 0.2494255006313324\n",
      "Epoch 398: \n",
      " mean_squared_error: 0.24942344427108765\n",
      "Epoch 399: \n",
      " mean_squared_error: 0.2494213581085205\n",
      "Epoch 400: \n",
      " mean_squared_error: 0.24941924214363098\n",
      "Epoch 401: \n",
      " mean_squared_error: 0.24941714107990265\n",
      "Epoch 402: \n",
      " mean_squared_error: 0.24941504001617432\n",
      "Epoch 403: \n",
      " mean_squared_error: 0.24941298365592957\n",
      "Epoch 404: \n",
      " mean_squared_error: 0.24941089749336243\n",
      "Epoch 405: \n",
      " mean_squared_error: 0.2494087517261505\n",
      "Epoch 406: \n",
      " mean_squared_error: 0.2494066059589386\n",
      "Epoch 407: \n",
      " mean_squared_error: 0.24940451979637146\n",
      "Epoch 408: \n",
      " mean_squared_error: 0.24940241873264313\n",
      "Epoch 409: \n",
      " mean_squared_error: 0.2494003176689148\n",
      "Epoch 410: \n",
      " mean_squared_error: 0.24939823150634766\n",
      "Epoch 411: \n",
      " mean_squared_error: 0.24939602613449097\n",
      "Epoch 412: \n",
      " mean_squared_error: 0.24939388036727905\n",
      "Epoch 413: \n",
      " mean_squared_error: 0.24939179420471191\n",
      "Epoch 414: \n",
      " mean_squared_error: 0.24938969314098358\n",
      "Epoch 415: \n",
      " mean_squared_error: 0.24938759207725525\n",
      "Epoch 416: \n",
      " mean_squared_error: 0.24938541650772095\n",
      "Epoch 417: \n",
      " mean_squared_error: 0.24938325583934784\n",
      "Epoch 418: \n",
      " mean_squared_error: 0.24938108026981354\n",
      "Epoch 419: \n",
      " mean_squared_error: 0.2493789792060852\n",
      "Epoch 420: \n",
      " mean_squared_error: 0.2493768036365509\n",
      "Epoch 421: \n",
      " mean_squared_error: 0.24937468767166138\n",
      "Epoch 422: \n",
      " mean_squared_error: 0.2493724524974823\n",
      "Epoch 423: \n",
      " mean_squared_error: 0.24937035143375397\n",
      "Epoch 424: \n",
      " mean_squared_error: 0.24936820566654205\n",
      "Epoch 425: \n",
      " mean_squared_error: 0.24936607480049133\n",
      "Epoch 426: \n",
      " mean_squared_error: 0.24936389923095703\n",
      "Epoch 427: \n",
      " mean_squared_error: 0.24936169385910034\n",
      "Epoch 428: \n",
      " mean_squared_error: 0.24935951828956604\n",
      "Epoch 429: \n",
      " mean_squared_error: 0.24935737252235413\n",
      "Epoch 430: \n",
      " mean_squared_error: 0.24935513734817505\n",
      "Epoch 431: \n",
      " mean_squared_error: 0.24935296177864075\n",
      "Epoch 432: \n",
      " mean_squared_error: 0.24935078620910645\n",
      "Epoch 433: \n",
      " mean_squared_error: 0.24934853613376617\n",
      "Epoch 434: \n",
      " mean_squared_error: 0.24934636056423187\n",
      "Epoch 435: \n",
      " mean_squared_error: 0.24934419989585876\n",
      "Epoch 436: \n",
      " mean_squared_error: 0.24934199452400208\n",
      "Epoch 437: \n",
      " mean_squared_error: 0.249339759349823\n",
      "Epoch 438: \n",
      " mean_squared_error: 0.2493375539779663\n",
      "Epoch 439: \n",
      " mean_squared_error: 0.24933533370494843\n",
      "Epoch 440: \n",
      " mean_squared_error: 0.24933317303657532\n",
      "Epoch 441: \n",
      " mean_squared_error: 0.24933095276355743\n",
      "Epoch 442: \n",
      " mean_squared_error: 0.24932873249053955\n",
      "Epoch 443: \n",
      " mean_squared_error: 0.24932649731636047\n",
      "Epoch 444: \n",
      " mean_squared_error: 0.2493242770433426\n",
      "Epoch 445: \n",
      " mean_squared_error: 0.24932202696800232\n",
      "Epoch 446: \n",
      " mean_squared_error: 0.24931980669498444\n",
      "Epoch 447: \n",
      " mean_squared_error: 0.24931755661964417\n",
      "Epoch 448: \n",
      " mean_squared_error: 0.2493152916431427\n",
      "Epoch 449: \n",
      " mean_squared_error: 0.24931305646896362\n",
      "Epoch 450: \n",
      " mean_squared_error: 0.24931076169013977\n",
      "Epoch 451: \n",
      " mean_squared_error: 0.2493085265159607\n",
      "Epoch 452: \n",
      " mean_squared_error: 0.24930627644062042\n",
      "Epoch 453: \n",
      " mean_squared_error: 0.24930398166179657\n",
      "Epoch 454: \n",
      " mean_squared_error: 0.2493017166852951\n",
      "Epoch 455: \n",
      " mean_squared_error: 0.24929943680763245\n",
      "Epoch 456: \n",
      " mean_squared_error: 0.24929718673229218\n",
      "Epoch 457: \n",
      " mean_squared_error: 0.24929490685462952\n",
      "Epoch 458: \n",
      " mean_squared_error: 0.24929261207580566\n",
      "Epoch 459: \n",
      " mean_squared_error: 0.2492903470993042\n",
      "Epoch 460: \n",
      " mean_squared_error: 0.24928805232048035\n",
      "Epoch 461: \n",
      " mean_squared_error: 0.24928569793701172\n",
      "Epoch 462: \n",
      " mean_squared_error: 0.24928346276283264\n",
      "Epoch 463: \n",
      " mean_squared_error: 0.2492811530828476\n",
      "Epoch 464: \n",
      " mean_squared_error: 0.24927884340286255\n",
      "Epoch 465: \n",
      " mean_squared_error: 0.2492765188217163\n",
      "Epoch 466: \n",
      " mean_squared_error: 0.24927422404289246\n",
      "Epoch 467: \n",
      " mean_squared_error: 0.2492719143629074\n",
      "Epoch 468: \n",
      " mean_squared_error: 0.24926955997943878\n",
      "Epoch 469: \n",
      " mean_squared_error: 0.24926720559597015\n",
      "Epoch 470: \n",
      " mean_squared_error: 0.2492649257183075\n",
      "Epoch 471: \n",
      " mean_squared_error: 0.24926252663135529\n",
      "Epoch 472: \n",
      " mean_squared_error: 0.24926021695137024\n",
      "Epoch 473: \n",
      " mean_squared_error: 0.2492578625679016\n",
      "Epoch 474: \n",
      " mean_squared_error: 0.24925555288791656\n",
      "Epoch 475: \n",
      " mean_squared_error: 0.24925321340560913\n",
      "Epoch 476: \n",
      " mean_squared_error: 0.24925079941749573\n",
      "Epoch 477: \n",
      " mean_squared_error: 0.2492484748363495\n",
      "Epoch 478: \n",
      " mean_squared_error: 0.24924609065055847\n",
      "Epoch 479: \n",
      " mean_squared_error: 0.24924364686012268\n",
      "Epoch 480: \n",
      " mean_squared_error: 0.24924133718013763\n",
      "Epoch 481: \n",
      " mean_squared_error: 0.2492389678955078\n",
      "Epoch 482: \n",
      " mean_squared_error: 0.2492365539073944\n",
      "Epoch 483: \n",
      " mean_squared_error: 0.24923411011695862\n",
      "Epoch 484: \n",
      " mean_squared_error: 0.24923178553581238\n",
      "Epoch 485: \n",
      " mean_squared_error: 0.24922941625118256\n",
      "Epoch 486: \n",
      " mean_squared_error: 0.24922700226306915\n",
      "Epoch 487: \n",
      " mean_squared_error: 0.24922455847263336\n",
      "Epoch 488: \n",
      " mean_squared_error: 0.24922214448451996\n",
      "Epoch 489: \n",
      " mean_squared_error: 0.24921973049640656\n",
      "Epoch 490: \n",
      " mean_squared_error: 0.24921727180480957\n",
      "Epoch 491: \n",
      " mean_squared_error: 0.24921487271785736\n",
      "Epoch 492: \n",
      " mean_squared_error: 0.24921244382858276\n",
      "Epoch 493: \n",
      " mean_squared_error: 0.24921000003814697\n",
      "Epoch 494: \n",
      " mean_squared_error: 0.24920761585235596\n",
      "Epoch 495: \n",
      " mean_squared_error: 0.2492050975561142\n",
      "Epoch 496: \n",
      " mean_squared_error: 0.24920260906219482\n",
      "Epoch 497: \n",
      " mean_squared_error: 0.2492002695798874\n",
      "Epoch 498: \n",
      " mean_squared_error: 0.2491978108882904\n",
      "Epoch 499: \n",
      " mean_squared_error: 0.24919527769088745\n",
      "Epoch 500: \n",
      " mean_squared_error: 0.24919280409812927\n",
      "Epoch 501: \n",
      " mean_squared_error: 0.2491903156042099\n",
      "Epoch 502: \n",
      " mean_squared_error: 0.24918779730796814\n",
      "Epoch 503: \n",
      " mean_squared_error: 0.24918538331985474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504: \n",
      " mean_squared_error: 0.24918285012245178\n",
      "Epoch 505: \n",
      " mean_squared_error: 0.24918043613433838\n",
      "Epoch 506: \n",
      " mean_squared_error: 0.24917787313461304\n",
      "Epoch 507: \n",
      " mean_squared_error: 0.2491753250360489\n",
      "Epoch 508: \n",
      " mean_squared_error: 0.24917291104793549\n",
      "Epoch 509: \n",
      " mean_squared_error: 0.24917036294937134\n",
      "Epoch 510: \n",
      " mean_squared_error: 0.24916782975196838\n",
      "Epoch 511: \n",
      " mean_squared_error: 0.24916526675224304\n",
      "Epoch 512: \n",
      " mean_squared_error: 0.24916279315948486\n",
      "Epoch 513: \n",
      " mean_squared_error: 0.24916018545627594\n",
      "Epoch 514: \n",
      " mean_squared_error: 0.24915769696235657\n",
      "Epoch 515: \n",
      " mean_squared_error: 0.24915507435798645\n",
      "Epoch 516: \n",
      " mean_squared_error: 0.24915249645709991\n",
      "Epoch 517: \n",
      " mean_squared_error: 0.24914997816085815\n",
      "Epoch 518: \n",
      " mean_squared_error: 0.24914748966693878\n",
      "Epoch 519: \n",
      " mean_squared_error: 0.24914482235908508\n",
      "Epoch 520: \n",
      " mean_squared_error: 0.24914228916168213\n",
      "Epoch 521: \n",
      " mean_squared_error: 0.2491396814584732\n",
      "Epoch 522: \n",
      " mean_squared_error: 0.24913708865642548\n",
      "Epoch 523: \n",
      " mean_squared_error: 0.24913451075553894\n",
      "Epoch 524: \n",
      " mean_squared_error: 0.2491319328546524\n",
      "Epoch 525: \n",
      " mean_squared_error: 0.2491292655467987\n",
      "Epoch 526: \n",
      " mean_squared_error: 0.24912668764591217\n",
      "Epoch 527: \n",
      " mean_squared_error: 0.24912410974502563\n",
      "Epoch 528: \n",
      " mean_squared_error: 0.24912142753601074\n",
      "Epoch 529: \n",
      " mean_squared_error: 0.2491188645362854\n",
      "Epoch 530: \n",
      " mean_squared_error: 0.2491162121295929\n",
      "Epoch 531: \n",
      " mean_squared_error: 0.2491135597229004\n",
      "Epoch 532: \n",
      " mean_squared_error: 0.24911090731620789\n",
      "Epoch 533: \n",
      " mean_squared_error: 0.24910829961299896\n",
      "Epoch 534: \n",
      " mean_squared_error: 0.24910563230514526\n",
      "Epoch 535: \n",
      " mean_squared_error: 0.2491028904914856\n",
      "Epoch 536: \n",
      " mean_squared_error: 0.24910029768943787\n",
      "Epoch 537: \n",
      " mean_squared_error: 0.24909758567810059\n",
      "Epoch 538: \n",
      " mean_squared_error: 0.2490949034690857\n",
      "Epoch 539: \n",
      " mean_squared_error: 0.2490922510623932\n",
      "Epoch 540: \n",
      " mean_squared_error: 0.24908959865570068\n",
      "Epoch 541: \n",
      " mean_squared_error: 0.24908685684204102\n",
      "Epoch 542: \n",
      " mean_squared_error: 0.24908414483070374\n",
      "Epoch 543: \n",
      " mean_squared_error: 0.24908150732517242\n",
      "Epoch 544: \n",
      " mean_squared_error: 0.24907870590686798\n",
      "Epoch 545: \n",
      " mean_squared_error: 0.2490760087966919\n",
      "Epoch 546: \n",
      " mean_squared_error: 0.24907326698303223\n",
      "Epoch 547: \n",
      " mean_squared_error: 0.24907051026821136\n",
      "Epoch 548: \n",
      " mean_squared_error: 0.24906781315803528\n",
      "Epoch 549: \n",
      " mean_squared_error: 0.24906505644321442\n",
      "Epoch 550: \n",
      " mean_squared_error: 0.24906232953071594\n",
      "Epoch 551: \n",
      " mean_squared_error: 0.2490594983100891\n",
      "Epoch 552: \n",
      " mean_squared_error: 0.24905678629875183\n",
      "Epoch 553: \n",
      " mean_squared_error: 0.24905404448509216\n",
      "Epoch 554: \n",
      " mean_squared_error: 0.24905122816562653\n",
      "Epoch 555: \n",
      " mean_squared_error: 0.24904842674732208\n",
      "Epoch 556: \n",
      " mean_squared_error: 0.249045729637146\n",
      "Epoch 557: \n",
      " mean_squared_error: 0.24904285371303558\n",
      "Epoch 558: \n",
      " mean_squared_error: 0.24904006719589233\n",
      "Epoch 559: \n",
      " mean_squared_error: 0.2490372359752655\n",
      "Epoch 560: \n",
      " mean_squared_error: 0.24903444945812225\n",
      "Epoch 561: \n",
      " mean_squared_error: 0.24903158843517303\n",
      "Epoch 562: \n",
      " mean_squared_error: 0.24902880191802979\n",
      "Epoch 563: \n",
      " mean_squared_error: 0.24902591109275818\n",
      "Epoch 564: \n",
      " mean_squared_error: 0.24902312457561493\n",
      "Epoch 565: \n",
      " mean_squared_error: 0.24902021884918213\n",
      "Epoch 566: \n",
      " mean_squared_error: 0.24901734292507172\n",
      "Epoch 567: \n",
      " mean_squared_error: 0.2490144968032837\n",
      "Epoch 568: \n",
      " mean_squared_error: 0.24901162087917328\n",
      "Epoch 569: \n",
      " mean_squared_error: 0.24900880455970764\n",
      "Epoch 570: \n",
      " mean_squared_error: 0.24900585412979126\n",
      "Epoch 571: \n",
      " mean_squared_error: 0.24900300800800323\n",
      "Epoch 572: \n",
      " mean_squared_error: 0.24900013208389282\n",
      "Epoch 573: \n",
      " mean_squared_error: 0.24899719655513763\n",
      "Epoch 574: \n",
      " mean_squared_error: 0.24899426102638245\n",
      "Epoch 575: \n",
      " mean_squared_error: 0.24899135529994965\n",
      "Epoch 576: \n",
      " mean_squared_error: 0.24898843467235565\n",
      "Epoch 577: \n",
      " mean_squared_error: 0.24898549914360046\n",
      "Epoch 578: \n",
      " mean_squared_error: 0.24898254871368408\n",
      "Epoch 579: \n",
      " mean_squared_error: 0.2489795982837677\n",
      "Epoch 580: \n",
      " mean_squared_error: 0.24897664785385132\n",
      "Epoch 581: \n",
      " mean_squared_error: 0.24897374212741852\n",
      "Epoch 582: \n",
      " mean_squared_error: 0.24897077679634094\n",
      "Epoch 583: \n",
      " mean_squared_error: 0.24896782636642456\n",
      "Epoch 584: \n",
      " mean_squared_error: 0.24896478652954102\n",
      "Epoch 585: \n",
      " mean_squared_error: 0.24896173179149628\n",
      "Epoch 586: \n",
      " mean_squared_error: 0.24895881116390228\n",
      "Epoch 587: \n",
      " mean_squared_error: 0.24895578622817993\n",
      "Epoch 588: \n",
      " mean_squared_error: 0.24895280599594116\n",
      "Epoch 589: \n",
      " mean_squared_error: 0.24894976615905762\n",
      "Epoch 590: \n",
      " mean_squared_error: 0.24894669651985168\n",
      "Epoch 591: \n",
      " mean_squared_error: 0.24894371628761292\n",
      "Epoch 592: \n",
      " mean_squared_error: 0.24894064664840698\n",
      "Epoch 593: \n",
      " mean_squared_error: 0.24893757700920105\n",
      "Epoch 594: \n",
      " mean_squared_error: 0.2489345222711563\n",
      "Epoch 595: \n",
      " mean_squared_error: 0.24893146753311157\n",
      "Epoch 596: \n",
      " mean_squared_error: 0.24892838299274445\n",
      "Epoch 597: \n",
      " mean_squared_error: 0.2489253133535385\n",
      "Epoch 598: \n",
      " mean_squared_error: 0.248922199010849\n",
      "Epoch 599: \n",
      " mean_squared_error: 0.24891912937164307\n",
      "Epoch 600: \n",
      " mean_squared_error: 0.24891602993011475\n",
      "Epoch 601: \n",
      " mean_squared_error: 0.2489129602909088\n",
      "Epoch 602: \n",
      " mean_squared_error: 0.24890974164009094\n",
      "Epoch 603: \n",
      " mean_squared_error: 0.248906672000885\n",
      "Epoch 604: \n",
      " mean_squared_error: 0.24890358746051788\n",
      "Epoch 605: \n",
      " mean_squared_error: 0.2489004135131836\n",
      "Epoch 606: \n",
      " mean_squared_error: 0.24889720976352692\n",
      "Epoch 607: \n",
      " mean_squared_error: 0.2488941103219986\n",
      "Epoch 608: \n",
      " mean_squared_error: 0.24889089167118073\n",
      "Epoch 609: \n",
      " mean_squared_error: 0.24888771772384644\n",
      "Epoch 610: \n",
      " mean_squared_error: 0.24888455867767334\n",
      "Epoch 611: \n",
      " mean_squared_error: 0.24888135492801666\n",
      "Epoch 612: \n",
      " mean_squared_error: 0.2488781213760376\n",
      "Epoch 613: \n",
      " mean_squared_error: 0.2488749623298645\n",
      "Epoch 614: \n",
      " mean_squared_error: 0.24887177348136902\n",
      "Epoch 615: \n",
      " mean_squared_error: 0.24886846542358398\n",
      "Epoch 616: \n",
      " mean_squared_error: 0.2488652765750885\n",
      "Epoch 617: \n",
      " mean_squared_error: 0.24886205792427063\n",
      "Epoch 618: \n",
      " mean_squared_error: 0.24885883927345276\n",
      "Epoch 619: \n",
      " mean_squared_error: 0.24885554611682892\n",
      "Epoch 620: \n",
      " mean_squared_error: 0.24885229766368866\n",
      "Epoch 621: \n",
      " mean_squared_error: 0.2488490343093872\n",
      "Epoch 622: \n",
      " mean_squared_error: 0.24884574115276337\n",
      "Epoch 623: \n",
      " mean_squared_error: 0.24884240329265594\n",
      "Epoch 624: \n",
      " mean_squared_error: 0.2488390952348709\n",
      "Epoch 625: \n",
      " mean_squared_error: 0.24883581697940826\n",
      "Epoch 626: \n",
      " mean_squared_error: 0.24883250892162323\n",
      "Epoch 627: \n",
      " mean_squared_error: 0.24882909655570984\n",
      "Epoch 628: \n",
      " mean_squared_error: 0.2488258183002472\n",
      "Epoch 629: \n",
      " mean_squared_error: 0.24882245063781738\n",
      "Epoch 630: \n",
      " mean_squared_error: 0.24881911277770996\n",
      "Epoch 631: \n",
      " mean_squared_error: 0.24881577491760254\n",
      "Epoch 632: \n",
      " mean_squared_error: 0.24881242215633392\n",
      "Epoch 633: \n",
      " mean_squared_error: 0.24880899488925934\n",
      "Epoch 634: \n",
      " mean_squared_error: 0.24880562722682953\n",
      "Epoch 635: \n",
      " mean_squared_error: 0.24880221486091614\n",
      "Epoch 636: \n",
      " mean_squared_error: 0.24879877269268036\n",
      "Epoch 637: \n",
      " mean_squared_error: 0.24879541993141174\n",
      "Epoch 638: \n",
      " mean_squared_error: 0.24879202246665955\n",
      "Epoch 639: \n",
      " mean_squared_error: 0.24878856539726257\n",
      "Epoch 640: \n",
      " mean_squared_error: 0.2487851232290268\n",
      "Epoch 641: \n",
      " mean_squared_error: 0.2487817108631134\n",
      "Epoch 642: \n",
      " mean_squared_error: 0.24877819418907166\n",
      "Epoch 643: \n",
      " mean_squared_error: 0.2487747073173523\n",
      "Epoch 644: \n",
      " mean_squared_error: 0.24877123534679413\n",
      "Epoch 645: \n",
      " mean_squared_error: 0.24876771867275238\n",
      "Epoch 646: \n",
      " mean_squared_error: 0.24876423180103302\n",
      "Epoch 647: \n",
      " mean_squared_error: 0.24876078963279724\n",
      "Epoch 648: \n",
      " mean_squared_error: 0.24875721335411072\n",
      "Epoch 649: \n",
      " mean_squared_error: 0.2487536370754242\n",
      "Epoch 650: \n",
      " mean_squared_error: 0.24875012040138245\n",
      "Epoch 651: \n",
      " mean_squared_error: 0.2487465888261795\n",
      "Epoch 652: \n",
      " mean_squared_error: 0.2487429976463318\n",
      "Epoch 653: \n",
      " mean_squared_error: 0.24873948097229004\n",
      "Epoch 654: \n",
      " mean_squared_error: 0.24873585999011993\n",
      "Epoch 655: \n",
      " mean_squared_error: 0.2487322837114334\n",
      "Epoch 656: \n",
      " mean_squared_error: 0.2487286627292633\n",
      "Epoch 657: \n",
      " mean_squared_error: 0.2487250715494156\n",
      "Epoch 658: \n",
      " mean_squared_error: 0.24872145056724548\n",
      "Epoch 659: \n",
      " mean_squared_error: 0.24871787428855896\n",
      "Epoch 660: \n",
      " mean_squared_error: 0.24871423840522766\n",
      "Epoch 661: \n",
      " mean_squared_error: 0.2487105131149292\n",
      "Epoch 662: \n",
      " mean_squared_error: 0.2487068921327591\n",
      "Epoch 663: \n",
      " mean_squared_error: 0.2487032413482666\n",
      "Epoch 664: \n",
      " mean_squared_error: 0.24869954586029053\n",
      "Epoch 665: \n",
      " mean_squared_error: 0.24869582056999207\n",
      "Epoch 666: \n",
      " mean_squared_error: 0.2486920952796936\n",
      "Epoch 667: \n",
      " mean_squared_error: 0.2486884742975235\n",
      "Epoch 668: \n",
      " mean_squared_error: 0.24868476390838623\n",
      "Epoch 669: \n",
      " mean_squared_error: 0.2486809939146042\n",
      "Epoch 670: \n",
      " mean_squared_error: 0.2486772984266281\n",
      "Epoch 671: \n",
      " mean_squared_error: 0.24867351353168488\n",
      "Epoch 672: \n",
      " mean_squared_error: 0.24866974353790283\n",
      "Epoch 673: \n",
      " mean_squared_error: 0.2486659735441208\n",
      "Epoch 674: \n",
      " mean_squared_error: 0.24866221845149994\n",
      "Epoch 675: \n",
      " mean_squared_error: 0.24865837395191193\n",
      "Epoch 676: \n",
      " mean_squared_error: 0.2486545890569687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 677: \n",
      " mean_squared_error: 0.24865075945854187\n",
      "Epoch 678: \n",
      " mean_squared_error: 0.24864692986011505\n",
      "Epoch 679: \n",
      " mean_squared_error: 0.24864314496517181\n",
      "Epoch 680: \n",
      " mean_squared_error: 0.2486393004655838\n",
      "Epoch 681: \n",
      " mean_squared_error: 0.248635396361351\n",
      "Epoch 682: \n",
      " mean_squared_error: 0.2486315220594406\n",
      "Epoch 683: \n",
      " mean_squared_error: 0.24862761795520782\n",
      "Epoch 684: \n",
      " mean_squared_error: 0.2486238181591034\n",
      "Epoch 685: \n",
      " mean_squared_error: 0.24861983954906464\n",
      "Epoch 686: \n",
      " mean_squared_error: 0.24861589074134827\n",
      "Epoch 687: \n",
      " mean_squared_error: 0.24861197173595428\n",
      "Epoch 688: \n",
      " mean_squared_error: 0.2486080378293991\n",
      "Epoch 689: \n",
      " mean_squared_error: 0.24860411882400513\n",
      "Epoch 690: \n",
      " mean_squared_error: 0.24860014021396637\n",
      "Epoch 691: \n",
      " mean_squared_error: 0.24859619140625\n",
      "Epoch 692: \n",
      " mean_squared_error: 0.24859222769737244\n",
      "Epoch 693: \n",
      " mean_squared_error: 0.2485881745815277\n",
      "Epoch 694: \n",
      " mean_squared_error: 0.24858419597148895\n",
      "Epoch 695: \n",
      " mean_squared_error: 0.248580202460289\n",
      "Epoch 696: \n",
      " mean_squared_error: 0.24857613444328308\n",
      "Epoch 697: \n",
      " mean_squared_error: 0.24857205152511597\n",
      "Epoch 698: \n",
      " mean_squared_error: 0.24856802821159363\n",
      "Epoch 699: \n",
      " mean_squared_error: 0.24856393039226532\n",
      "Epoch 700: \n",
      " mean_squared_error: 0.24855992197990417\n",
      "Epoch 701: \n",
      " mean_squared_error: 0.24855577945709229\n",
      "Epoch 702: \n",
      " mean_squared_error: 0.24855168163776398\n",
      "Epoch 703: \n",
      " mean_squared_error: 0.24854762852191925\n",
      "Epoch 704: \n",
      " mean_squared_error: 0.24854342639446259\n",
      "Epoch 705: \n",
      " mean_squared_error: 0.24853932857513428\n",
      "Epoch 706: \n",
      " mean_squared_error: 0.2485351860523224\n",
      "Epoch 707: \n",
      " mean_squared_error: 0.24853093922138214\n",
      "Epoch 708: \n",
      " mean_squared_error: 0.24852679669857025\n",
      "Epoch 709: \n",
      " mean_squared_error: 0.2485225796699524\n",
      "Epoch 710: \n",
      " mean_squared_error: 0.2485184222459793\n",
      "Epoch 711: \n",
      " mean_squared_error: 0.24851420521736145\n",
      "Epoch 712: \n",
      " mean_squared_error: 0.24850991368293762\n",
      "Epoch 713: \n",
      " mean_squared_error: 0.24850571155548096\n",
      "Epoch 714: \n",
      " mean_squared_error: 0.24850142002105713\n",
      "Epoch 715: \n",
      " mean_squared_error: 0.24849718809127808\n",
      "Epoch 716: \n",
      " mean_squared_error: 0.24849286675453186\n",
      "Epoch 717: \n",
      " mean_squared_error: 0.2484886348247528\n",
      "Epoch 718: \n",
      " mean_squared_error: 0.24848434329032898\n",
      "Epoch 719: \n",
      " mean_squared_error: 0.24847997725009918\n",
      "Epoch 720: \n",
      " mean_squared_error: 0.24847570061683655\n",
      "Epoch 721: \n",
      " mean_squared_error: 0.24847131967544556\n",
      "Epoch 722: \n",
      " mean_squared_error: 0.24846696853637695\n",
      "Epoch 723: \n",
      " mean_squared_error: 0.24846257269382477\n",
      "Epoch 724: \n",
      " mean_squared_error: 0.24845820665359497\n",
      "Epoch 725: \n",
      " mean_squared_error: 0.2484537810087204\n",
      "Epoch 726: \n",
      " mean_squared_error: 0.2484494000673294\n",
      "Epoch 727: \n",
      " mean_squared_error: 0.24844494462013245\n",
      "Epoch 728: \n",
      " mean_squared_error: 0.24844051897525787\n",
      "Epoch 729: \n",
      " mean_squared_error: 0.2484360933303833\n",
      "Epoch 730: \n",
      " mean_squared_error: 0.24843168258666992\n",
      "Epoch 731: \n",
      " mean_squared_error: 0.248427152633667\n",
      "Epoch 732: \n",
      " mean_squared_error: 0.2484225630760193\n",
      "Epoch 733: \n",
      " mean_squared_error: 0.2484181523323059\n",
      "Epoch 734: \n",
      " mean_squared_error: 0.2484135627746582\n",
      "Epoch 735: \n",
      " mean_squared_error: 0.24840909242630005\n",
      "Epoch 736: \n",
      " mean_squared_error: 0.24840447306632996\n",
      "Epoch 737: \n",
      " mean_squared_error: 0.24839992821216583\n",
      "Epoch 738: \n",
      " mean_squared_error: 0.2483953982591629\n",
      "Epoch 739: \n",
      " mean_squared_error: 0.2483908087015152\n",
      "Epoch 740: \n",
      " mean_squared_error: 0.2483862191438675\n",
      "Epoch 741: \n",
      " mean_squared_error: 0.24838152527809143\n",
      "Epoch 742: \n",
      " mean_squared_error: 0.2483769655227661\n",
      "Epoch 743: \n",
      " mean_squared_error: 0.24837230145931244\n",
      "Epoch 744: \n",
      " mean_squared_error: 0.24836762249469757\n",
      "Epoch 745: \n",
      " mean_squared_error: 0.2483629584312439\n",
      "Epoch 746: \n",
      " mean_squared_error: 0.24835826456546783\n",
      "Epoch 747: \n",
      " mean_squared_error: 0.24835357069969177\n",
      "Epoch 748: \n",
      " mean_squared_error: 0.24834886193275452\n",
      "Epoch 749: \n",
      " mean_squared_error: 0.2483440637588501\n",
      "Epoch 750: \n",
      " mean_squared_error: 0.24833932518959045\n",
      "Epoch 751: \n",
      " mean_squared_error: 0.24833449721336365\n",
      "Epoch 752: \n",
      " mean_squared_error: 0.248329758644104\n",
      "Epoch 753: \n",
      " mean_squared_error: 0.24832497537136078\n",
      "Epoch 754: \n",
      " mean_squared_error: 0.24832020699977875\n",
      "Epoch 755: \n",
      " mean_squared_error: 0.24831539392471313\n",
      "Epoch 756: \n",
      " mean_squared_error: 0.24831046164035797\n",
      "Epoch 757: \n",
      " mean_squared_error: 0.24830563366413116\n",
      "Epoch 758: \n",
      " mean_squared_error: 0.2483007311820984\n",
      "Epoch 759: \n",
      " mean_squared_error: 0.2482958883047104\n",
      "Epoch 760: \n",
      " mean_squared_error: 0.2482910007238388\n",
      "Epoch 761: \n",
      " mean_squared_error: 0.24828600883483887\n",
      "Epoch 762: \n",
      " mean_squared_error: 0.24828103184700012\n",
      "Epoch 763: \n",
      " mean_squared_error: 0.24827615916728973\n",
      "Epoch 764: \n",
      " mean_squared_error: 0.248271182179451\n",
      "Epoch 765: \n",
      " mean_squared_error: 0.24826617538928986\n",
      "Epoch 766: \n",
      " mean_squared_error: 0.24826116859912872\n",
      "Epoch 767: \n",
      " mean_squared_error: 0.24825623631477356\n",
      "Epoch 768: \n",
      " mean_squared_error: 0.24825116991996765\n",
      "Epoch 769: \n",
      " mean_squared_error: 0.24824605882167816\n",
      "Epoch 770: \n",
      " mean_squared_error: 0.24824105203151703\n",
      "Epoch 771: \n",
      " mean_squared_error: 0.24823595583438873\n",
      "Epoch 772: \n",
      " mean_squared_error: 0.24823087453842163\n",
      "Epoch 773: \n",
      " mean_squared_error: 0.24822574853897095\n",
      "Epoch 774: \n",
      " mean_squared_error: 0.24822062253952026\n",
      "Epoch 775: \n",
      " mean_squared_error: 0.2482154369354248\n",
      "Epoch 776: \n",
      " mean_squared_error: 0.24821028113365173\n",
      "Epoch 777: \n",
      " mean_squared_error: 0.24820512533187866\n",
      "Epoch 778: \n",
      " mean_squared_error: 0.24819988012313843\n",
      "Epoch 779: \n",
      " mean_squared_error: 0.24819466471672058\n",
      "Epoch 780: \n",
      " mean_squared_error: 0.24818940460681915\n",
      "Epoch 781: \n",
      " mean_squared_error: 0.2481842041015625\n",
      "Epoch 782: \n",
      " mean_squared_error: 0.24817895889282227\n",
      "Epoch 783: \n",
      " mean_squared_error: 0.24817365407943726\n",
      "Epoch 784: \n",
      " mean_squared_error: 0.24816833436489105\n",
      "Epoch 785: \n",
      " mean_squared_error: 0.24816301465034485\n",
      "Epoch 786: \n",
      " mean_squared_error: 0.24815770983695984\n",
      "Epoch 787: \n",
      " mean_squared_error: 0.24815233051776886\n",
      "Epoch 788: \n",
      " mean_squared_error: 0.24814698100090027\n",
      "Epoch 789: \n",
      " mean_squared_error: 0.24814152717590332\n",
      "Epoch 790: \n",
      " mean_squared_error: 0.24813616275787354\n",
      "Epoch 791: \n",
      " mean_squared_error: 0.2481306791305542\n",
      "Epoch 792: \n",
      " mean_squared_error: 0.24812527000904083\n",
      "Epoch 793: \n",
      " mean_squared_error: 0.2481197863817215\n",
      "Epoch 794: \n",
      " mean_squared_error: 0.24811434745788574\n",
      "Epoch 795: \n",
      " mean_squared_error: 0.24810877442359924\n",
      "Epoch 796: \n",
      " mean_squared_error: 0.2481032758951187\n",
      "Epoch 797: \n",
      " mean_squared_error: 0.24809777736663818\n",
      "Epoch 798: \n",
      " mean_squared_error: 0.24809223413467407\n",
      "Epoch 799: \n",
      " mean_squared_error: 0.2480866014957428\n",
      "Epoch 800: \n",
      " mean_squared_error: 0.2480810135602951\n",
      "Epoch 801: \n",
      " mean_squared_error: 0.24807536602020264\n",
      "Epoch 802: \n",
      " mean_squared_error: 0.24806977808475494\n",
      "Epoch 803: \n",
      " mean_squared_error: 0.24806413054466248\n",
      "Epoch 804: \n",
      " mean_squared_error: 0.24805843830108643\n",
      "Epoch 805: \n",
      " mean_squared_error: 0.24805279076099396\n",
      "Epoch 806: \n",
      " mean_squared_error: 0.2480471134185791\n",
      "Epoch 807: \n",
      " mean_squared_error: 0.24804136157035828\n",
      "Epoch 808: \n",
      " mean_squared_error: 0.24803556501865387\n",
      "Epoch 809: \n",
      " mean_squared_error: 0.24802985787391663\n",
      "Epoch 810: \n",
      " mean_squared_error: 0.2480240762233734\n",
      "Epoch 811: \n",
      " mean_squared_error: 0.2480182647705078\n",
      "Epoch 812: \n",
      " mean_squared_error: 0.2480124533176422\n",
      "Epoch 813: \n",
      " mean_squared_error: 0.24800652265548706\n",
      "Epoch 814: \n",
      " mean_squared_error: 0.24800068140029907\n",
      "Epoch 815: \n",
      " mean_squared_error: 0.24799476563930511\n",
      "Epoch 816: \n",
      " mean_squared_error: 0.24798889458179474\n",
      "Epoch 817: \n",
      " mean_squared_error: 0.24798297882080078\n",
      "Epoch 818: \n",
      " mean_squared_error: 0.24797700345516205\n",
      "Epoch 819: \n",
      " mean_squared_error: 0.2479710876941681\n",
      "Epoch 820: \n",
      " mean_squared_error: 0.24796505272388458\n",
      "Epoch 821: \n",
      " mean_squared_error: 0.24795907735824585\n",
      "Epoch 822: \n",
      " mean_squared_error: 0.24795302748680115\n",
      "Epoch 823: \n",
      " mean_squared_error: 0.24794696271419525\n",
      "Epoch 824: \n",
      " mean_squared_error: 0.24794094264507294\n",
      "Epoch 825: \n",
      " mean_squared_error: 0.24793483316898346\n",
      "Epoch 826: \n",
      " mean_squared_error: 0.24792872369289398\n",
      "Epoch 827: \n",
      " mean_squared_error: 0.24792258441448212\n",
      "Epoch 828: \n",
      " mean_squared_error: 0.24791641533374786\n",
      "Epoch 829: \n",
      " mean_squared_error: 0.247910276055336\n",
      "Epoch 830: \n",
      " mean_squared_error: 0.24790409207344055\n",
      "Epoch 831: \n",
      " mean_squared_error: 0.24789781868457794\n",
      "Epoch 832: \n",
      " mean_squared_error: 0.2478915899991989\n",
      "Epoch 833: \n",
      " mean_squared_error: 0.24788528680801392\n",
      "Epoch 834: \n",
      " mean_squared_error: 0.2478790134191513\n",
      "Epoch 835: \n",
      " mean_squared_error: 0.2478727102279663\n",
      "Epoch 836: \n",
      " mean_squared_error: 0.2478664219379425\n",
      "Epoch 837: \n",
      " mean_squared_error: 0.24786007404327393\n",
      "Epoch 838: \n",
      " mean_squared_error: 0.24785371124744415\n",
      "Epoch 839: \n",
      " mean_squared_error: 0.2478472739458084\n",
      "Epoch 840: \n",
      " mean_squared_error: 0.24784088134765625\n",
      "Epoch 841: \n",
      " mean_squared_error: 0.24783439934253693\n",
      "Epoch 842: \n",
      " mean_squared_error: 0.2478279173374176\n",
      "Epoch 843: \n",
      " mean_squared_error: 0.24782146513462067\n",
      "Epoch 844: \n",
      " mean_squared_error: 0.24781498312950134\n",
      "Epoch 845: \n",
      " mean_squared_error: 0.24780848622322083\n",
      "Epoch 846: \n",
      " mean_squared_error: 0.24780181050300598\n",
      "Epoch 847: \n",
      " mean_squared_error: 0.24779529869556427\n",
      "Epoch 848: \n",
      " mean_squared_error: 0.247788667678833\n",
      "Epoch 849: \n",
      " mean_squared_error: 0.24778206646442413\n",
      "Epoch 850: \n",
      " mean_squared_error: 0.24777543544769287\n",
      "Epoch 851: \n",
      " mean_squared_error: 0.24776874482631683\n",
      "Epoch 852: \n",
      " mean_squared_error: 0.2477620393037796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853: \n",
      " mean_squared_error: 0.24775531888008118\n",
      "Epoch 854: \n",
      " mean_squared_error: 0.2477484941482544\n",
      "Epoch 855: \n",
      " mean_squared_error: 0.24774183332920074\n",
      "Epoch 856: \n",
      " mean_squared_error: 0.247734934091568\n",
      "Epoch 857: \n",
      " mean_squared_error: 0.24772824347019196\n",
      "Epoch 858: \n",
      " mean_squared_error: 0.2477213740348816\n",
      "Epoch 859: \n",
      " mean_squared_error: 0.24771445989608765\n",
      "Epoch 860: \n",
      " mean_squared_error: 0.2477075755596161\n",
      "Epoch 861: \n",
      " mean_squared_error: 0.24770066142082214\n",
      "Epoch 862: \n",
      " mean_squared_error: 0.2476937174797058\n",
      "Epoch 863: \n",
      " mean_squared_error: 0.24768680334091187\n",
      "Epoch 864: \n",
      " mean_squared_error: 0.24767981469631195\n",
      "Epoch 865: \n",
      " mean_squared_error: 0.24767275154590607\n",
      "Epoch 866: \n",
      " mean_squared_error: 0.247665673494339\n",
      "Epoch 867: \n",
      " mean_squared_error: 0.2476586103439331\n",
      "Epoch 868: \n",
      " mean_squared_error: 0.24765151739120483\n",
      "Epoch 869: \n",
      " mean_squared_error: 0.24764439463615417\n",
      "Epoch 870: \n",
      " mean_squared_error: 0.2476373016834259\n",
      "Epoch 871: \n",
      " mean_squared_error: 0.24763011932373047\n",
      "Epoch 872: \n",
      " mean_squared_error: 0.24762290716171265\n",
      "Epoch 873: \n",
      " mean_squared_error: 0.24761569499969482\n",
      "Epoch 874: \n",
      " mean_squared_error: 0.24760843813419342\n",
      "Epoch 875: \n",
      " mean_squared_error: 0.24760115146636963\n",
      "Epoch 876: \n",
      " mean_squared_error: 0.24759387969970703\n",
      "Epoch 877: \n",
      " mean_squared_error: 0.24758650362491608\n",
      "Epoch 878: \n",
      " mean_squared_error: 0.24757921695709229\n",
      "Epoch 879: \n",
      " mean_squared_error: 0.24757173657417297\n",
      "Epoch 880: \n",
      " mean_squared_error: 0.24756434559822083\n",
      "Epoch 881: \n",
      " mean_squared_error: 0.2475568950176239\n",
      "Epoch 882: \n",
      " mean_squared_error: 0.24754942953586578\n",
      "Epoch 883: \n",
      " mean_squared_error: 0.24754194915294647\n",
      "Epoch 884: \n",
      " mean_squared_error: 0.2475343644618988\n",
      "Epoch 885: \n",
      " mean_squared_error: 0.24752691388130188\n",
      "Epoch 886: \n",
      " mean_squared_error: 0.24751925468444824\n",
      "Epoch 887: \n",
      " mean_squared_error: 0.24751177430152893\n",
      "Epoch 888: \n",
      " mean_squared_error: 0.24750405550003052\n",
      "Epoch 889: \n",
      " mean_squared_error: 0.24749639630317688\n",
      "Epoch 890: \n",
      " mean_squared_error: 0.24748867750167847\n",
      "Epoch 891: \n",
      " mean_squared_error: 0.24748091399669647\n",
      "Epoch 892: \n",
      " mean_squared_error: 0.24747318029403687\n",
      "Epoch 893: \n",
      " mean_squared_error: 0.24746543169021606\n",
      "Epoch 894: \n",
      " mean_squared_error: 0.2474576085805893\n",
      "Epoch 895: \n",
      " mean_squared_error: 0.24744980037212372\n",
      "Epoch 896: \n",
      " mean_squared_error: 0.24744191765785217\n",
      "Epoch 897: \n",
      " mean_squared_error: 0.24743399024009705\n",
      "Epoch 898: \n",
      " mean_squared_error: 0.24742606282234192\n",
      "Epoch 899: \n",
      " mean_squared_error: 0.2474181056022644\n",
      "Epoch 900: \n",
      " mean_squared_error: 0.2474101185798645\n",
      "Epoch 901: \n",
      " mean_squared_error: 0.2474021315574646\n",
      "Epoch 902: \n",
      " mean_squared_error: 0.2473941296339035\n",
      "Epoch 903: \n",
      " mean_squared_error: 0.24738597869873047\n",
      "Epoch 904: \n",
      " mean_squared_error: 0.2473779320716858\n",
      "Epoch 905: \n",
      " mean_squared_error: 0.24736975133419037\n",
      "Epoch 906: \n",
      " mean_squared_error: 0.24736160039901733\n",
      "Epoch 907: \n",
      " mean_squared_error: 0.24735337495803833\n",
      "Epoch 908: \n",
      " mean_squared_error: 0.2473452240228653\n",
      "Epoch 909: \n",
      " mean_squared_error: 0.24733687937259674\n",
      "Epoch 910: \n",
      " mean_squared_error: 0.24732860922813416\n",
      "Epoch 911: \n",
      " mean_squared_error: 0.24732030928134918\n",
      "Epoch 912: \n",
      " mean_squared_error: 0.24731191992759705\n",
      "Epoch 913: \n",
      " mean_squared_error: 0.2473035454750061\n",
      "Epoch 914: \n",
      " mean_squared_error: 0.2472950667142868\n",
      "Epoch 915: \n",
      " mean_squared_error: 0.2472866326570511\n",
      "Epoch 916: \n",
      " mean_squared_error: 0.24727818369865417\n",
      "Epoch 917: \n",
      " mean_squared_error: 0.2472696304321289\n",
      "Epoch 918: \n",
      " mean_squared_error: 0.24726107716560364\n",
      "Epoch 919: \n",
      " mean_squared_error: 0.24725253880023956\n",
      "Epoch 920: \n",
      " mean_squared_error: 0.24724391102790833\n",
      "Epoch 921: \n",
      " mean_squared_error: 0.2472352534532547\n",
      "Epoch 922: \n",
      " mean_squared_error: 0.24722659587860107\n",
      "Epoch 923: \n",
      " mean_squared_error: 0.24721784889698029\n",
      "Epoch 924: \n",
      " mean_squared_error: 0.2472090721130371\n",
      "Epoch 925: \n",
      " mean_squared_error: 0.2472003549337387\n",
      "Epoch 926: \n",
      " mean_squared_error: 0.2471914291381836\n",
      "Epoch 927: \n",
      " mean_squared_error: 0.2471826821565628\n",
      "Epoch 928: \n",
      " mean_squared_error: 0.2471737414598465\n",
      "Epoch 929: \n",
      " mean_squared_error: 0.247164785861969\n",
      "Epoch 930: \n",
      " mean_squared_error: 0.24715590476989746\n",
      "Epoch 931: \n",
      " mean_squared_error: 0.24714690446853638\n",
      "Epoch 932: \n",
      " mean_squared_error: 0.2471379190683365\n",
      "Epoch 933: \n",
      " mean_squared_error: 0.24712882936000824\n",
      "Epoch 934: \n",
      " mean_squared_error: 0.24711976945400238\n",
      "Epoch 935: \n",
      " mean_squared_error: 0.24711060523986816\n",
      "Epoch 936: \n",
      " mean_squared_error: 0.24710139632225037\n",
      "Epoch 937: \n",
      " mean_squared_error: 0.24709227681159973\n",
      "Epoch 938: \n",
      " mean_squared_error: 0.24708294868469238\n",
      "Epoch 939: \n",
      " mean_squared_error: 0.24707362055778503\n",
      "Epoch 940: \n",
      " mean_squared_error: 0.24706436693668365\n",
      "Epoch 941: \n",
      " mean_squared_error: 0.24705499410629272\n",
      "Epoch 942: \n",
      " mean_squared_error: 0.247045636177063\n",
      "Epoch 943: \n",
      " mean_squared_error: 0.24703621864318848\n",
      "Epoch 944: \n",
      " mean_squared_error: 0.24702680110931396\n",
      "Epoch 945: \n",
      " mean_squared_error: 0.2470172941684723\n",
      "Epoch 946: \n",
      " mean_squared_error: 0.24700775742530823\n",
      "Epoch 947: \n",
      " mean_squared_error: 0.2469981461763382\n",
      "Epoch 948: \n",
      " mean_squared_error: 0.24698854982852936\n",
      "Epoch 949: \n",
      " mean_squared_error: 0.24697887897491455\n",
      "Epoch 950: \n",
      " mean_squared_error: 0.24696922302246094\n",
      "Epoch 951: \n",
      " mean_squared_error: 0.24695944786071777\n",
      "Epoch 952: \n",
      " mean_squared_error: 0.24694962799549103\n",
      "Epoch 953: \n",
      " mean_squared_error: 0.24693986773490906\n",
      "Epoch 954: \n",
      " mean_squared_error: 0.24693003296852112\n",
      "Epoch 955: \n",
      " mean_squared_error: 0.24692019820213318\n",
      "Epoch 956: \n",
      " mean_squared_error: 0.24691028892993927\n",
      "Epoch 957: \n",
      " mean_squared_error: 0.2469002902507782\n",
      "Epoch 958: \n",
      " mean_squared_error: 0.24689029157161713\n",
      "Epoch 959: \n",
      " mean_squared_error: 0.24688029289245605\n",
      "Epoch 960: \n",
      " mean_squared_error: 0.246870219707489\n",
      "Epoch 961: \n",
      " mean_squared_error: 0.24686001241207123\n",
      "Epoch 962: \n",
      " mean_squared_error: 0.2468498945236206\n",
      "Epoch 963: \n",
      " mean_squared_error: 0.246839702129364\n",
      "Epoch 964: \n",
      " mean_squared_error: 0.24682943522930145\n",
      "Epoch 965: \n",
      " mean_squared_error: 0.2468191683292389\n",
      "Epoch 966: \n",
      " mean_squared_error: 0.24680881202220917\n",
      "Epoch 967: \n",
      " mean_squared_error: 0.24679845571517944\n",
      "Epoch 968: \n",
      " mean_squared_error: 0.24678802490234375\n",
      "Epoch 969: \n",
      " mean_squared_error: 0.24677760899066925\n",
      "Epoch 970: \n",
      " mean_squared_error: 0.2467671036720276\n",
      "Epoch 971: \n",
      " mean_squared_error: 0.24675655364990234\n",
      "Epoch 972: \n",
      " mean_squared_error: 0.2467460334300995\n",
      "Epoch 973: \n",
      " mean_squared_error: 0.2467353343963623\n",
      "Epoch 974: \n",
      " mean_squared_error: 0.2467246651649475\n",
      "Epoch 975: \n",
      " mean_squared_error: 0.24671398103237152\n",
      "Epoch 976: \n",
      " mean_squared_error: 0.24670325219631195\n",
      "Epoch 977: \n",
      " mean_squared_error: 0.2466925084590912\n",
      "Epoch 978: \n",
      " mean_squared_error: 0.2466815859079361\n",
      "Epoch 979: \n",
      " mean_squared_error: 0.2466706931591034\n",
      "Epoch 980: \n",
      " mean_squared_error: 0.2466597557067871\n",
      "Epoch 981: \n",
      " mean_squared_error: 0.24664877355098724\n",
      "Epoch 982: \n",
      " mean_squared_error: 0.246637761592865\n",
      "Epoch 983: \n",
      " mean_squared_error: 0.24662670493125916\n",
      "Epoch 984: \n",
      " mean_squared_error: 0.24661558866500854\n",
      "Epoch 985: \n",
      " mean_squared_error: 0.24660444259643555\n",
      "Epoch 986: \n",
      " mean_squared_error: 0.24659328162670135\n",
      "Epoch 987: \n",
      " mean_squared_error: 0.24658195674419403\n",
      "Epoch 988: \n",
      " mean_squared_error: 0.24657069146633148\n",
      "Epoch 989: \n",
      " mean_squared_error: 0.24655941128730774\n",
      "Epoch 990: \n",
      " mean_squared_error: 0.24654796719551086\n",
      "Epoch 991: \n",
      " mean_squared_error: 0.24653655290603638\n",
      "Epoch 992: \n",
      " mean_squared_error: 0.24652501940727234\n",
      "Epoch 993: \n",
      " mean_squared_error: 0.24651354551315308\n",
      "Epoch 994: \n",
      " mean_squared_error: 0.24650192260742188\n",
      "Epoch 995: \n",
      " mean_squared_error: 0.24649029970169067\n",
      "Epoch 996: \n",
      " mean_squared_error: 0.24647867679595947\n",
      "Epoch 997: \n",
      " mean_squared_error: 0.2464669644832611\n",
      "Epoch 998: \n",
      " mean_squared_error: 0.24645516276359558\n",
      "Epoch 999: \n",
      " mean_squared_error: 0.24644330143928528\n",
      "Epoch 1000: \n",
      " mean_squared_error: 0.24643146991729736\n",
      "Epoch 1001: \n",
      " mean_squared_error: 0.24641956388950348\n",
      "Epoch 1002: \n",
      " mean_squared_error: 0.24640758335590363\n",
      "Epoch 1003: \n",
      " mean_squared_error: 0.24639557301998138\n",
      "Epoch 1004: \n",
      " mean_squared_error: 0.24638348817825317\n",
      "Epoch 1005: \n",
      " mean_squared_error: 0.24637146294116974\n",
      "Epoch 1006: \n",
      " mean_squared_error: 0.246359184384346\n",
      "Epoch 1007: \n",
      " mean_squared_error: 0.24634701013565063\n",
      "Epoch 1008: \n",
      " mean_squared_error: 0.2463347464799881\n",
      "Epoch 1009: \n",
      " mean_squared_error: 0.24632234871387482\n",
      "Epoch 1010: \n",
      " mean_squared_error: 0.2463100254535675\n",
      "Epoch 1011: \n",
      " mean_squared_error: 0.24629762768745422\n",
      "Epoch 1012: \n",
      " mean_squared_error: 0.24628518521785736\n",
      "Epoch 1013: \n",
      " mean_squared_error: 0.24627262353897095\n",
      "Epoch 1014: \n",
      " mean_squared_error: 0.24625995755195618\n",
      "Epoch 1015: \n",
      " mean_squared_error: 0.24624735116958618\n",
      "Epoch 1016: \n",
      " mean_squared_error: 0.2462347000837326\n",
      "Epoch 1017: \n",
      " mean_squared_error: 0.2462218999862671\n",
      "Epoch 1018: \n",
      " mean_squared_error: 0.24620909988880157\n",
      "Epoch 1019: \n",
      " mean_squared_error: 0.24619626998901367\n",
      "Epoch 1020: \n",
      " mean_squared_error: 0.2461833357810974\n",
      "Epoch 1021: \n",
      " mean_squared_error: 0.24617040157318115\n",
      "Epoch 1022: \n",
      " mean_squared_error: 0.24615734815597534\n",
      "Epoch 1023: \n",
      " mean_squared_error: 0.24614427983760834\n",
      "Epoch 1024: \n",
      " mean_squared_error: 0.24613122642040253\n",
      "Epoch 1025: \n",
      " mean_squared_error: 0.24611800909042358\n",
      "Epoch 1026: \n",
      " mean_squared_error: 0.24610477685928345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027: \n",
      " mean_squared_error: 0.24609145522117615\n",
      "Epoch 1028: \n",
      " mean_squared_error: 0.24607813358306885\n",
      "Epoch 1029: \n",
      " mean_squared_error: 0.24606472253799438\n",
      "Epoch 1030: \n",
      " mean_squared_error: 0.24605116248130798\n",
      "Epoch 1031: \n",
      " mean_squared_error: 0.24603766202926636\n",
      "Epoch 1032: \n",
      " mean_squared_error: 0.24602408707141876\n",
      "Epoch 1033: \n",
      " mean_squared_error: 0.24601048231124878\n",
      "Epoch 1034: \n",
      " mean_squared_error: 0.24599668383598328\n",
      "Epoch 1035: \n",
      " mean_squared_error: 0.24598293006420135\n",
      "Epoch 1036: \n",
      " mean_squared_error: 0.24596913158893585\n",
      "Epoch 1037: \n",
      " mean_squared_error: 0.24595525860786438\n",
      "Epoch 1038: \n",
      " mean_squared_error: 0.24594128131866455\n",
      "Epoch 1039: \n",
      " mean_squared_error: 0.2459273338317871\n",
      "Epoch 1040: \n",
      " mean_squared_error: 0.2459132820367813\n",
      "Epoch 1041: \n",
      " mean_squared_error: 0.24589917063713074\n",
      "Epoch 1042: \n",
      " mean_squared_error: 0.2458849847316742\n",
      "Epoch 1043: \n",
      " mean_squared_error: 0.2458707094192505\n",
      "Epoch 1044: \n",
      " mean_squared_error: 0.2458564192056656\n",
      "Epoch 1045: \n",
      " mean_squared_error: 0.24584200978279114\n",
      "Epoch 1046: \n",
      " mean_squared_error: 0.2458276003599167\n",
      "Epoch 1047: \n",
      " mean_squared_error: 0.2458130419254303\n",
      "Epoch 1048: \n",
      " mean_squared_error: 0.24579863250255585\n",
      "Epoch 1049: \n",
      " mean_squared_error: 0.2457839846611023\n",
      "Epoch 1050: \n",
      " mean_squared_error: 0.24576923251152039\n",
      "Epoch 1051: \n",
      " mean_squared_error: 0.24575451016426086\n",
      "Epoch 1052: \n",
      " mean_squared_error: 0.2457396537065506\n",
      "Epoch 1053: \n",
      " mean_squared_error: 0.24572479724884033\n",
      "Epoch 1054: \n",
      " mean_squared_error: 0.2457098513841629\n",
      "Epoch 1055: \n",
      " mean_squared_error: 0.2456948608160019\n",
      "Epoch 1056: \n",
      " mean_squared_error: 0.2456798106431961\n",
      "Epoch 1057: \n",
      " mean_squared_error: 0.24566461145877838\n",
      "Epoch 1058: \n",
      " mean_squared_error: 0.24564939737319946\n",
      "Epoch 1059: \n",
      " mean_squared_error: 0.24563413858413696\n",
      "Epoch 1060: \n",
      " mean_squared_error: 0.2456188201904297\n",
      "Epoch 1061: \n",
      " mean_squared_error: 0.24560341238975525\n",
      "Epoch 1062: \n",
      " mean_squared_error: 0.24558791518211365\n",
      "Epoch 1063: \n",
      " mean_squared_error: 0.24557241797447205\n",
      "Epoch 1064: \n",
      " mean_squared_error: 0.24555683135986328\n",
      "Epoch 1065: \n",
      " mean_squared_error: 0.24554112553596497\n",
      "Epoch 1066: \n",
      " mean_squared_error: 0.2455253005027771\n",
      "Epoch 1067: \n",
      " mean_squared_error: 0.24550952017307281\n",
      "Epoch 1068: \n",
      " mean_squared_error: 0.24549363553524017\n",
      "Epoch 1069: \n",
      " mean_squared_error: 0.24547769129276276\n",
      "Epoch 1070: \n",
      " mean_squared_error: 0.2454616278409958\n",
      "Epoch 1071: \n",
      " mean_squared_error: 0.24544557929039001\n",
      "Epoch 1072: \n",
      " mean_squared_error: 0.24542935192584991\n",
      "Epoch 1073: \n",
      " mean_squared_error: 0.24541307985782623\n",
      "Epoch 1074: \n",
      " mean_squared_error: 0.24539676308631897\n",
      "Epoch 1075: \n",
      " mean_squared_error: 0.24538037180900574\n",
      "Epoch 1076: \n",
      " mean_squared_error: 0.24536386132240295\n",
      "Epoch 1077: \n",
      " mean_squared_error: 0.24534739553928375\n",
      "Epoch 1078: \n",
      " mean_squared_error: 0.24533076584339142\n",
      "Epoch 1079: \n",
      " mean_squared_error: 0.24531406164169312\n",
      "Epoch 1080: \n",
      " mean_squared_error: 0.24529725313186646\n",
      "Epoch 1081: \n",
      " mean_squared_error: 0.2452804446220398\n",
      "Epoch 1082: \n",
      " mean_squared_error: 0.24526357650756836\n",
      "Epoch 1083: \n",
      " mean_squared_error: 0.24524657428264618\n",
      "Epoch 1084: \n",
      " mean_squared_error: 0.24522948265075684\n",
      "Epoch 1085: \n",
      " mean_squared_error: 0.2452124059200287\n",
      "Epoch 1086: \n",
      " mean_squared_error: 0.24519513547420502\n",
      "Epoch 1087: \n",
      " mean_squared_error: 0.24517787992954254\n",
      "Epoch 1088: \n",
      " mean_squared_error: 0.24516047537326813\n",
      "Epoch 1089: \n",
      " mean_squared_error: 0.24514305591583252\n",
      "Epoch 1090: \n",
      " mean_squared_error: 0.24512545764446259\n",
      "Epoch 1091: \n",
      " mean_squared_error: 0.24510782957077026\n",
      "Epoch 1092: \n",
      " mean_squared_error: 0.24509018659591675\n",
      "Epoch 1093: \n",
      " mean_squared_error: 0.24507242441177368\n",
      "Epoch 1094: \n",
      " mean_squared_error: 0.24505454301834106\n",
      "Epoch 1095: \n",
      " mean_squared_error: 0.24503658711910248\n",
      "Epoch 1096: \n",
      " mean_squared_error: 0.24501857161521912\n",
      "Epoch 1097: \n",
      " mean_squared_error: 0.24500052630901337\n",
      "Epoch 1098: \n",
      " mean_squared_error: 0.24498236179351807\n",
      "Epoch 1099: \n",
      " mean_squared_error: 0.2449640929698944\n",
      "Epoch 1100: \n",
      " mean_squared_error: 0.2449457347393036\n",
      "Epoch 1101: \n",
      " mean_squared_error: 0.24492725729942322\n",
      "Epoch 1102: \n",
      " mean_squared_error: 0.24490877985954285\n",
      "Epoch 1103: \n",
      " mean_squared_error: 0.24489018321037292\n",
      "Epoch 1104: \n",
      " mean_squared_error: 0.24487148225307465\n",
      "Epoch 1105: \n",
      " mean_squared_error: 0.2448527216911316\n",
      "Epoch 1106: \n",
      " mean_squared_error: 0.24483388662338257\n",
      "Epoch 1107: \n",
      " mean_squared_error: 0.244814932346344\n",
      "Epoch 1108: \n",
      " mean_squared_error: 0.24479593336582184\n",
      "Epoch 1109: \n",
      " mean_squared_error: 0.24477684497833252\n",
      "Epoch 1110: \n",
      " mean_squared_error: 0.24475762248039246\n",
      "Epoch 1111: \n",
      " mean_squared_error: 0.24473842978477478\n",
      "Epoch 1112: \n",
      " mean_squared_error: 0.24471889436244965\n",
      "Epoch 1113: \n",
      " mean_squared_error: 0.24469950795173645\n",
      "Epoch 1114: \n",
      " mean_squared_error: 0.2446799874305725\n",
      "Epoch 1115: \n",
      " mean_squared_error: 0.24466031789779663\n",
      "Epoch 1116: \n",
      " mean_squared_error: 0.24464051425457\n",
      "Epoch 1117: \n",
      " mean_squared_error: 0.24462074041366577\n",
      "Epoch 1118: \n",
      " mean_squared_error: 0.24460089206695557\n",
      "Epoch 1119: \n",
      " mean_squared_error: 0.24458079040050507\n",
      "Epoch 1120: \n",
      " mean_squared_error: 0.24456079304218292\n",
      "Epoch 1121: \n",
      " mean_squared_error: 0.2445405125617981\n",
      "Epoch 1122: \n",
      " mean_squared_error: 0.24452023208141327\n",
      "Epoch 1123: \n",
      " mean_squared_error: 0.2444998323917389\n",
      "Epoch 1124: \n",
      " mean_squared_error: 0.24447940289974213\n",
      "Epoch 1125: \n",
      " mean_squared_error: 0.24445883929729462\n",
      "Epoch 1126: \n",
      " mean_squared_error: 0.24443821609020233\n",
      "Epoch 1127: \n",
      " mean_squared_error: 0.24441736936569214\n",
      "Epoch 1128: \n",
      " mean_squared_error: 0.24439652264118195\n",
      "Epoch 1129: \n",
      " mean_squared_error: 0.24437564611434937\n",
      "Epoch 1130: \n",
      " mean_squared_error: 0.24435457587242126\n",
      "Epoch 1131: \n",
      " mean_squared_error: 0.24433335661888123\n",
      "Epoch 1132: \n",
      " mean_squared_error: 0.24431216716766357\n",
      "Epoch 1133: \n",
      " mean_squared_error: 0.2442907691001892\n",
      "Epoch 1134: \n",
      " mean_squared_error: 0.24426929652690887\n",
      "Epoch 1135: \n",
      " mean_squared_error: 0.24424779415130615\n",
      "Epoch 1136: \n",
      " mean_squared_error: 0.24422606825828552\n",
      "Epoch 1137: \n",
      " mean_squared_error: 0.24420437216758728\n",
      "Epoch 1138: \n",
      " mean_squared_error: 0.24418260157108307\n",
      "Epoch 1139: \n",
      " mean_squared_error: 0.24416057765483856\n",
      "Epoch 1140: \n",
      " mean_squared_error: 0.2441384345293045\n",
      "Epoch 1141: \n",
      " mean_squared_error: 0.24411635100841522\n",
      "Epoch 1142: \n",
      " mean_squared_error: 0.2440940886735916\n",
      "Epoch 1143: \n",
      " mean_squared_error: 0.24407175183296204\n",
      "Epoch 1144: \n",
      " mean_squared_error: 0.24404922127723694\n",
      "Epoch 1145: \n",
      " mean_squared_error: 0.24402667582035065\n",
      "Epoch 1146: \n",
      " mean_squared_error: 0.24400398135185242\n",
      "Epoch 1147: \n",
      " mean_squared_error: 0.2439812272787094\n",
      "Epoch 1148: \n",
      " mean_squared_error: 0.24395830929279327\n",
      "Epoch 1149: \n",
      " mean_squared_error: 0.24393528699874878\n",
      "Epoch 1150: \n",
      " mean_squared_error: 0.24391213059425354\n",
      "Epoch 1151: \n",
      " mean_squared_error: 0.2438889443874359\n",
      "Epoch 1152: \n",
      " mean_squared_error: 0.24386563897132874\n",
      "Epoch 1153: \n",
      " mean_squared_error: 0.24384212493896484\n",
      "Epoch 1154: \n",
      " mean_squared_error: 0.24381858110427856\n",
      "Epoch 1155: \n",
      " mean_squared_error: 0.24379491806030273\n",
      "Epoch 1156: \n",
      " mean_squared_error: 0.24377116560935974\n",
      "Epoch 1157: \n",
      " mean_squared_error: 0.24374723434448242\n",
      "Epoch 1158: \n",
      " mean_squared_error: 0.24372325837612152\n",
      "Epoch 1159: \n",
      " mean_squared_error: 0.2436991035938263\n",
      "Epoch 1160: \n",
      " mean_squared_error: 0.24367481470108032\n",
      "Epoch 1161: \n",
      " mean_squared_error: 0.24365055561065674\n",
      "Epoch 1162: \n",
      " mean_squared_error: 0.24362607300281525\n",
      "Epoch 1163: \n",
      " mean_squared_error: 0.243601456284523\n",
      "Epoch 1164: \n",
      " mean_squared_error: 0.24357682466506958\n",
      "Epoch 1165: \n",
      " mean_squared_error: 0.24355198442935944\n",
      "Epoch 1166: \n",
      " mean_squared_error: 0.24352705478668213\n",
      "Epoch 1167: \n",
      " mean_squared_error: 0.24350197613239288\n",
      "Epoch 1168: \n",
      " mean_squared_error: 0.2434767633676529\n",
      "Epoch 1169: \n",
      " mean_squared_error: 0.2434515655040741\n",
      "Epoch 1170: \n",
      " mean_squared_error: 0.2434261590242386\n",
      "Epoch 1171: \n",
      " mean_squared_error: 0.24340051412582397\n",
      "Epoch 1172: \n",
      " mean_squared_error: 0.24337488412857056\n",
      "Epoch 1173: \n",
      " mean_squared_error: 0.2433491349220276\n",
      "Epoch 1174: \n",
      " mean_squared_error: 0.2433232218027115\n",
      "Epoch 1175: \n",
      " mean_squared_error: 0.24329720437526703\n",
      "Epoch 1176: \n",
      " mean_squared_error: 0.24327106773853302\n",
      "Epoch 1177: \n",
      " mean_squared_error: 0.2432447373867035\n",
      "Epoch 1178: \n",
      " mean_squared_error: 0.2432183474302292\n",
      "Epoch 1179: \n",
      " mean_squared_error: 0.24319183826446533\n",
      "Epoch 1180: \n",
      " mean_squared_error: 0.24316520988941193\n",
      "Epoch 1181: \n",
      " mean_squared_error: 0.2431384176015854\n",
      "Epoch 1182: \n",
      " mean_squared_error: 0.2431114912033081\n",
      "Epoch 1183: \n",
      " mean_squared_error: 0.24308449029922485\n",
      "Epoch 1184: \n",
      " mean_squared_error: 0.2430572807788849\n",
      "Epoch 1185: \n",
      " mean_squared_error: 0.24302998185157776\n",
      "Epoch 1186: \n",
      " mean_squared_error: 0.2430025190114975\n",
      "Epoch 1187: \n",
      " mean_squared_error: 0.24297499656677246\n",
      "Epoch 1188: \n",
      " mean_squared_error: 0.2429472655057907\n",
      "Epoch 1189: \n",
      " mean_squared_error: 0.2429194450378418\n",
      "Epoch 1190: \n",
      " mean_squared_error: 0.24289146065711975\n",
      "Epoch 1191: \n",
      " mean_squared_error: 0.24286338686943054\n",
      "Epoch 1192: \n",
      " mean_squared_error: 0.24283510446548462\n",
      "Epoch 1193: \n",
      " mean_squared_error: 0.24280670285224915\n",
      "Epoch 1194: \n",
      " mean_squared_error: 0.2427782118320465\n",
      "Epoch 1195: \n",
      " mean_squared_error: 0.24274954199790955\n",
      "Epoch 1196: \n",
      " mean_squared_error: 0.24272075295448303\n",
      "Epoch 1197: \n",
      " mean_squared_error: 0.24269181489944458\n",
      "Epoch 1198: \n",
      " mean_squared_error: 0.24266278743743896\n",
      "Epoch 1199: \n",
      " mean_squared_error: 0.24263350665569305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1200: \n",
      " mean_squared_error: 0.24260418117046356\n",
      "Epoch 1201: \n",
      " mean_squared_error: 0.24257466197013855\n",
      "Epoch 1202: \n",
      " mean_squared_error: 0.24254503846168518\n",
      "Epoch 1203: \n",
      " mean_squared_error: 0.2425152063369751\n",
      "Epoch 1204: \n",
      " mean_squared_error: 0.24248532950878143\n",
      "Epoch 1205: \n",
      " mean_squared_error: 0.24245518445968628\n",
      "Epoch 1206: \n",
      " mean_squared_error: 0.24242499470710754\n",
      "Epoch 1207: \n",
      " mean_squared_error: 0.2423945665359497\n",
      "Epoch 1208: \n",
      " mean_squared_error: 0.24236413836479187\n",
      "Epoch 1209: \n",
      " mean_squared_error: 0.24233344197273254\n",
      "Epoch 1210: \n",
      " mean_squared_error: 0.24230264127254486\n",
      "Epoch 1211: \n",
      " mean_squared_error: 0.24227164685726166\n",
      "Epoch 1212: \n",
      " mean_squared_error: 0.24224048852920532\n",
      "Epoch 1213: \n",
      " mean_squared_error: 0.24220922589302063\n",
      "Epoch 1214: \n",
      " mean_squared_error: 0.242177814245224\n",
      "Epoch 1215: \n",
      " mean_squared_error: 0.2421463280916214\n",
      "Epoch 1216: \n",
      " mean_squared_error: 0.24211454391479492\n",
      "Epoch 1217: \n",
      " mean_squared_error: 0.2420826554298401\n",
      "Epoch 1218: \n",
      " mean_squared_error: 0.24205060303211212\n",
      "Epoch 1219: \n",
      " mean_squared_error: 0.24201837182044983\n",
      "Epoch 1220: \n",
      " mean_squared_error: 0.24198609590530396\n",
      "Epoch 1221: \n",
      " mean_squared_error: 0.2419535219669342\n",
      "Epoch 1222: \n",
      " mean_squared_error: 0.24192078411579132\n",
      "Epoch 1223: \n",
      " mean_squared_error: 0.24188798666000366\n",
      "Epoch 1224: \n",
      " mean_squared_error: 0.24185505509376526\n",
      "Epoch 1225: \n",
      " mean_squared_error: 0.24182188510894775\n",
      "Epoch 1226: \n",
      " mean_squared_error: 0.24178852140903473\n",
      "Epoch 1227: \n",
      " mean_squared_error: 0.24175497889518738\n",
      "Epoch 1228: \n",
      " mean_squared_error: 0.24172134697437286\n",
      "Epoch 1229: \n",
      " mean_squared_error: 0.24168755114078522\n",
      "Epoch 1230: \n",
      " mean_squared_error: 0.24165348708629608\n",
      "Epoch 1231: \n",
      " mean_squared_error: 0.24161943793296814\n",
      "Epoch 1232: \n",
      " mean_squared_error: 0.24158507585525513\n",
      "Epoch 1233: \n",
      " mean_squared_error: 0.24155060946941376\n",
      "Epoch 1234: \n",
      " mean_squared_error: 0.24151593446731567\n",
      "Epoch 1235: \n",
      " mean_squared_error: 0.24148106575012207\n",
      "Epoch 1236: \n",
      " mean_squared_error: 0.24144607782363892\n",
      "Epoch 1237: \n",
      " mean_squared_error: 0.2414109706878662\n",
      "Epoch 1238: \n",
      " mean_squared_error: 0.24137559533119202\n",
      "Epoch 1239: \n",
      " mean_squared_error: 0.24134010076522827\n",
      "Epoch 1240: \n",
      " mean_squared_error: 0.24130432307720184\n",
      "Epoch 1241: \n",
      " mean_squared_error: 0.24126845598220825\n",
      "Epoch 1242: \n",
      " mean_squared_error: 0.24123241007328033\n",
      "Epoch 1243: \n",
      " mean_squared_error: 0.2411961406469345\n",
      "Epoch 1244: \n",
      " mean_squared_error: 0.24115979671478271\n",
      "Epoch 1245: \n",
      " mean_squared_error: 0.24112315475940704\n",
      "Epoch 1246: \n",
      " mean_squared_error: 0.2410864233970642\n",
      "Epoch 1247: \n",
      " mean_squared_error: 0.2410494089126587\n",
      "Epoch 1248: \n",
      " mean_squared_error: 0.241012305021286\n",
      "Epoch 1249: \n",
      " mean_squared_error: 0.240975022315979\n",
      "Epoch 1250: \n",
      " mean_squared_error: 0.24093745648860931\n",
      "Epoch 1251: \n",
      " mean_squared_error: 0.24089981615543365\n",
      "Epoch 1252: \n",
      " mean_squared_error: 0.2408619225025177\n",
      "Epoch 1253: \n",
      " mean_squared_error: 0.2408238649368286\n",
      "Epoch 1254: \n",
      " mean_squared_error: 0.24078555405139923\n",
      "Epoch 1255: \n",
      " mean_squared_error: 0.2407470941543579\n",
      "Epoch 1256: \n",
      " mean_squared_error: 0.24070852994918823\n",
      "Epoch 1257: \n",
      " mean_squared_error: 0.24066965281963348\n",
      "Epoch 1258: \n",
      " mean_squared_error: 0.24063067138195038\n",
      "Epoch 1259: \n",
      " mean_squared_error: 0.24059143662452698\n",
      "Epoch 1260: \n",
      " mean_squared_error: 0.24055199325084686\n",
      "Epoch 1261: \n",
      " mean_squared_error: 0.240512415766716\n",
      "Epoch 1262: \n",
      " mean_squared_error: 0.24047259986400604\n",
      "Epoch 1263: \n",
      " mean_squared_error: 0.24043264985084534\n",
      "Epoch 1264: \n",
      " mean_squared_error: 0.24039241671562195\n",
      "Epoch 1265: \n",
      " mean_squared_error: 0.24035203456878662\n",
      "Epoch 1266: \n",
      " mean_squared_error: 0.2403114140033722\n",
      "Epoch 1267: \n",
      " mean_squared_error: 0.24027056992053986\n",
      "Epoch 1268: \n",
      " mean_squared_error: 0.24022960662841797\n",
      "Epoch 1269: \n",
      " mean_squared_error: 0.240188330411911\n",
      "Epoch 1270: \n",
      " mean_squared_error: 0.2401469647884369\n",
      "Epoch 1271: \n",
      " mean_squared_error: 0.24010531604290009\n",
      "Epoch 1272: \n",
      " mean_squared_error: 0.24006347358226776\n",
      "Epoch 1273: \n",
      " mean_squared_error: 0.2400214821100235\n",
      "Epoch 1274: \n",
      " mean_squared_error: 0.23997923731803894\n",
      "Epoch 1275: \n",
      " mean_squared_error: 0.23993675410747528\n",
      "Epoch 1276: \n",
      " mean_squared_error: 0.2398940920829773\n",
      "Epoch 1277: \n",
      " mean_squared_error: 0.2398512214422226\n",
      "Epoch 1278: \n",
      " mean_squared_error: 0.23980817198753357\n",
      "Epoch 1279: \n",
      " mean_squared_error: 0.23976482450962067\n",
      "Epoch 1280: \n",
      " mean_squared_error: 0.23972126841545105\n",
      "Epoch 1281: \n",
      " mean_squared_error: 0.23967744410037994\n",
      "Epoch 1282: \n",
      " mean_squared_error: 0.23963351547718048\n",
      "Epoch 1283: \n",
      " mean_squared_error: 0.23958933353424072\n",
      "Epoch 1284: \n",
      " mean_squared_error: 0.23954492807388306\n",
      "Epoch 1285: \n",
      " mean_squared_error: 0.23950031399726868\n",
      "Epoch 1286: \n",
      " mean_squared_error: 0.23945550620555878\n",
      "Epoch 1287: \n",
      " mean_squared_error: 0.2394103705883026\n",
      "Epoch 1288: \n",
      " mean_squared_error: 0.2393651306629181\n",
      "Epoch 1289: \n",
      " mean_squared_error: 0.2393195927143097\n",
      "Epoch 1290: \n",
      " mean_squared_error: 0.23927384614944458\n",
      "Epoch 1291: \n",
      " mean_squared_error: 0.23922781646251678\n",
      "Epoch 1292: \n",
      " mean_squared_error: 0.23918163776397705\n",
      "Epoch 1293: \n",
      " mean_squared_error: 0.23913519084453583\n",
      "Epoch 1294: \n",
      " mean_squared_error: 0.2390885204076767\n",
      "Epoch 1295: \n",
      " mean_squared_error: 0.23904156684875488\n",
      "Epoch 1296: \n",
      " mean_squared_error: 0.23899446427822113\n",
      "Epoch 1297: \n",
      " mean_squared_error: 0.2389470785856247\n",
      "Epoch 1298: \n",
      " mean_squared_error: 0.23889943957328796\n",
      "Epoch 1299: \n",
      " mean_squared_error: 0.23885159194469452\n",
      "Epoch 1300: \n",
      " mean_squared_error: 0.23880350589752197\n",
      "Epoch 1301: \n",
      " mean_squared_error: 0.2387552112340927\n",
      "Epoch 1302: \n",
      " mean_squared_error: 0.23870663344860077\n",
      "Epoch 1303: \n",
      " mean_squared_error: 0.23865778744220734\n",
      "Epoch 1304: \n",
      " mean_squared_error: 0.2386087328195572\n",
      "Epoch 1305: \n",
      " mean_squared_error: 0.23855943977832794\n",
      "Epoch 1306: \n",
      " mean_squared_error: 0.238509863615036\n",
      "Epoch 1307: \n",
      " mean_squared_error: 0.23846010863780975\n",
      "Epoch 1308: \n",
      " mean_squared_error: 0.23841001093387604\n",
      "Epoch 1309: \n",
      " mean_squared_error: 0.238359734416008\n",
      "Epoch 1310: \n",
      " mean_squared_error: 0.23830921947956085\n",
      "Epoch 1311: \n",
      " mean_squared_error: 0.23825842142105103\n",
      "Epoch 1312: \n",
      " mean_squared_error: 0.23820729553699493\n",
      "Epoch 1313: \n",
      " mean_squared_error: 0.2381560057401657\n",
      "Epoch 1314: \n",
      " mean_squared_error: 0.23810438811779022\n",
      "Epoch 1315: \n",
      " mean_squared_error: 0.2380526065826416\n",
      "Epoch 1316: \n",
      " mean_squared_error: 0.23800049722194672\n",
      "Epoch 1317: \n",
      " mean_squared_error: 0.23794811964035034\n",
      "Epoch 1318: \n",
      " mean_squared_error: 0.23789557814598083\n",
      "Epoch 1319: \n",
      " mean_squared_error: 0.23784273862838745\n",
      "Epoch 1320: \n",
      " mean_squared_error: 0.23778961598873138\n",
      "Epoch 1321: \n",
      " mean_squared_error: 0.23773616552352905\n",
      "Epoch 1322: \n",
      " mean_squared_error: 0.23768246173858643\n",
      "Epoch 1323: \n",
      " mean_squared_error: 0.2376285046339035\n",
      "Epoch 1324: \n",
      " mean_squared_error: 0.23757432401180267\n",
      "Epoch 1325: \n",
      " mean_squared_error: 0.23751984536647797\n",
      "Epoch 1326: \n",
      " mean_squared_error: 0.2374650537967682\n",
      "Epoch 1327: \n",
      " mean_squared_error: 0.2374100387096405\n",
      "Epoch 1328: \n",
      " mean_squared_error: 0.2373548150062561\n",
      "Epoch 1329: \n",
      " mean_squared_error: 0.23729921877384186\n",
      "Epoch 1330: \n",
      " mean_squared_error: 0.23724335432052612\n",
      "Epoch 1331: \n",
      " mean_squared_error: 0.2371872067451477\n",
      "Epoch 1332: \n",
      " mean_squared_error: 0.23713086545467377\n",
      "Epoch 1333: \n",
      " mean_squared_error: 0.2370741069316864\n",
      "Epoch 1334: \n",
      " mean_squared_error: 0.23701715469360352\n",
      "Epoch 1335: \n",
      " mean_squared_error: 0.23695990443229675\n",
      "Epoch 1336: \n",
      " mean_squared_error: 0.23690231144428253\n",
      "Epoch 1337: \n",
      " mean_squared_error: 0.2368444949388504\n",
      "Epoch 1338: \n",
      " mean_squared_error: 0.23678644001483917\n",
      "Epoch 1339: \n",
      " mean_squared_error: 0.23672790825366974\n",
      "Epoch 1340: \n",
      " mean_squared_error: 0.23666927218437195\n",
      "Epoch 1341: \n",
      " mean_squared_error: 0.2366102933883667\n",
      "Epoch 1342: \n",
      " mean_squared_error: 0.236550971865654\n",
      "Epoch 1343: \n",
      " mean_squared_error: 0.2364913821220398\n",
      "Epoch 1344: \n",
      " mean_squared_error: 0.2364315688610077\n",
      "Epoch 1345: \n",
      " mean_squared_error: 0.23637129366397858\n",
      "Epoch 1346: \n",
      " mean_squared_error: 0.23631085455417633\n",
      "Epoch 1347: \n",
      " mean_squared_error: 0.2362501323223114\n",
      "Epoch 1348: \n",
      " mean_squared_error: 0.23618900775909424\n",
      "Epoch 1349: \n",
      " mean_squared_error: 0.2361276000738144\n",
      "Epoch 1350: \n",
      " mean_squared_error: 0.23606590926647186\n",
      "Epoch 1351: \n",
      " mean_squared_error: 0.23600396513938904\n",
      "Epoch 1352: \n",
      " mean_squared_error: 0.23594163358211517\n",
      "Epoch 1353: \n",
      " mean_squared_error: 0.23587894439697266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1354: \n",
      " mean_squared_error: 0.2358160763978958\n",
      "Epoch 1355: \n",
      " mean_squared_error: 0.23575280606746674\n",
      "Epoch 1356: \n",
      " mean_squared_error: 0.23568934202194214\n",
      "Epoch 1357: \n",
      " mean_squared_error: 0.23562538623809814\n",
      "Epoch 1358: \n",
      " mean_squared_error: 0.23556119203567505\n",
      "Epoch 1359: \n",
      " mean_squared_error: 0.23549672961235046\n",
      "Epoch 1360: \n",
      " mean_squared_error: 0.23543187975883484\n",
      "Epoch 1361: \n",
      " mean_squared_error: 0.23536676168441772\n",
      "Epoch 1362: \n",
      " mean_squared_error: 0.23530128598213196\n",
      "Epoch 1363: \n",
      " mean_squared_error: 0.2352355271577835\n",
      "Epoch 1364: \n",
      " mean_squared_error: 0.2351694256067276\n",
      "Epoch 1365: \n",
      " mean_squared_error: 0.23510292172431946\n",
      "Epoch 1366: \n",
      " mean_squared_error: 0.23503613471984863\n",
      "Epoch 1367: \n",
      " mean_squared_error: 0.23496904969215393\n",
      "Epoch 1368: \n",
      " mean_squared_error: 0.2349015325307846\n",
      "Epoch 1369: \n",
      " mean_squared_error: 0.23483388125896454\n",
      "Epoch 1370: \n",
      " mean_squared_error: 0.23476570844650269\n",
      "Epoch 1371: \n",
      " mean_squared_error: 0.23469728231430054\n",
      "Epoch 1372: \n",
      " mean_squared_error: 0.23462849855422974\n",
      "Epoch 1373: \n",
      " mean_squared_error: 0.23455935716629028\n",
      "Epoch 1374: \n",
      " mean_squared_error: 0.23448991775512695\n",
      "Epoch 1375: \n",
      " mean_squared_error: 0.23442015051841736\n",
      "Epoch 1376: \n",
      " mean_squared_error: 0.23434995114803314\n",
      "Epoch 1377: \n",
      " mean_squared_error: 0.23427946865558624\n",
      "Epoch 1378: \n",
      " mean_squared_error: 0.23420867323875427\n",
      "Epoch 1379: \n",
      " mean_squared_error: 0.2341374307870865\n",
      "Epoch 1380: \n",
      " mean_squared_error: 0.2340659499168396\n",
      "Epoch 1381: \n",
      " mean_squared_error: 0.2339940220117569\n",
      "Epoch 1382: \n",
      " mean_squared_error: 0.2339218258857727\n",
      "Epoch 1383: \n",
      " mean_squared_error: 0.2338491976261139\n",
      "Epoch 1384: \n",
      " mean_squared_error: 0.2337762713432312\n",
      "Epoch 1385: \n",
      " mean_squared_error: 0.2337028980255127\n",
      "Epoch 1386: \n",
      " mean_squared_error: 0.23362919688224792\n",
      "Epoch 1387: \n",
      " mean_squared_error: 0.23355522751808167\n",
      "Epoch 1388: \n",
      " mean_squared_error: 0.2334808111190796\n",
      "Epoch 1389: \n",
      " mean_squared_error: 0.23340608179569244\n",
      "Epoch 1390: \n",
      " mean_squared_error: 0.23333095014095306\n",
      "Epoch 1391: \n",
      " mean_squared_error: 0.23325544595718384\n",
      "Epoch 1392: \n",
      " mean_squared_error: 0.23317956924438477\n",
      "Epoch 1393: \n",
      " mean_squared_error: 0.23310333490371704\n",
      "Epoch 1394: \n",
      " mean_squared_error: 0.23302677273750305\n",
      "Epoch 1395: \n",
      " mean_squared_error: 0.23294976353645325\n",
      "Epoch 1396: \n",
      " mean_squared_error: 0.23287242650985718\n",
      "Epoch 1397: \n",
      " mean_squared_error: 0.23279467225074768\n",
      "Epoch 1398: \n",
      " mean_squared_error: 0.23271654546260834\n",
      "Epoch 1399: \n",
      " mean_squared_error: 0.23263804614543915\n",
      "Epoch 1400: \n",
      " mean_squared_error: 0.2325592041015625\n",
      "Epoch 1401: \n",
      " mean_squared_error: 0.23247988522052765\n",
      "Epoch 1402: \n",
      " mean_squared_error: 0.23240025341510773\n",
      "Epoch 1403: \n",
      " mean_squared_error: 0.23232021927833557\n",
      "Epoch 1404: \n",
      " mean_squared_error: 0.2322397530078888\n",
      "Epoch 1405: \n",
      " mean_squared_error: 0.23215898871421814\n",
      "Epoch 1406: \n",
      " mean_squared_error: 0.23207782208919525\n",
      "Epoch 1407: \n",
      " mean_squared_error: 0.23199620842933655\n",
      "Epoch 1408: \n",
      " mean_squared_error: 0.2319141924381256\n",
      "Epoch 1409: \n",
      " mean_squared_error: 0.23183183372020721\n",
      "Epoch 1410: \n",
      " mean_squared_error: 0.231749027967453\n",
      "Epoch 1411: \n",
      " mean_squared_error: 0.23166581988334656\n",
      "Epoch 1412: \n",
      " mean_squared_error: 0.23158222436904907\n",
      "Epoch 1413: \n",
      " mean_squared_error: 0.23149822652339935\n",
      "Epoch 1414: \n",
      " mean_squared_error: 0.23141387104988098\n",
      "Epoch 1415: \n",
      " mean_squared_error: 0.2313290387392044\n",
      "Epoch 1416: \n",
      " mean_squared_error: 0.23124384880065918\n",
      "Epoch 1417: \n",
      " mean_squared_error: 0.23115824162960052\n",
      "Epoch 1418: \n",
      " mean_squared_error: 0.23107218742370605\n",
      "Epoch 1419: \n",
      " mean_squared_error: 0.23098568618297577\n",
      "Epoch 1420: \n",
      " mean_squared_error: 0.23089879751205444\n",
      "Epoch 1421: \n",
      " mean_squared_error: 0.23081153631210327\n",
      "Epoch 1422: \n",
      " mean_squared_error: 0.23072382807731628\n",
      "Epoch 1423: \n",
      " mean_squared_error: 0.23063570261001587\n",
      "Epoch 1424: \n",
      " mean_squared_error: 0.23054715991020203\n",
      "Epoch 1425: \n",
      " mean_squared_error: 0.23045819997787476\n",
      "Epoch 1426: \n",
      " mean_squared_error: 0.23036879301071167\n",
      "Epoch 1427: \n",
      " mean_squared_error: 0.23027901351451874\n",
      "Epoch 1428: \n",
      " mean_squared_error: 0.2301887571811676\n",
      "Epoch 1429: \n",
      " mean_squared_error: 0.23009803891181946\n",
      "Epoch 1430: \n",
      " mean_squared_error: 0.23000697791576385\n",
      "Epoch 1431: \n",
      " mean_squared_error: 0.22991538047790527\n",
      "Epoch 1432: \n",
      " mean_squared_error: 0.22982342541217804\n",
      "Epoch 1433: \n",
      " mean_squared_error: 0.2297309935092926\n",
      "Epoch 1434: \n",
      " mean_squared_error: 0.22963811457157135\n",
      "Epoch 1435: \n",
      " mean_squared_error: 0.22954484820365906\n",
      "Epoch 1436: \n",
      " mean_squared_error: 0.22945109009742737\n",
      "Epoch 1437: \n",
      " mean_squared_error: 0.22935691475868225\n",
      "Epoch 1438: \n",
      " mean_squared_error: 0.22926229238510132\n",
      "Epoch 1439: \n",
      " mean_squared_error: 0.2291671633720398\n",
      "Epoch 1440: \n",
      " mean_squared_error: 0.22907167673110962\n",
      "Epoch 1441: \n",
      " mean_squared_error: 0.22897568345069885\n",
      "Epoch 1442: \n",
      " mean_squared_error: 0.2288791835308075\n",
      "Epoch 1443: \n",
      " mean_squared_error: 0.2287822961807251\n",
      "Epoch 1444: \n",
      " mean_squared_error: 0.22868497669696808\n",
      "Epoch 1445: \n",
      " mean_squared_error: 0.22858718037605286\n",
      "Epoch 1446: \n",
      " mean_squared_error: 0.22848892211914062\n",
      "Epoch 1447: \n",
      " mean_squared_error: 0.2283901423215866\n",
      "Epoch 1448: \n",
      " mean_squared_error: 0.22829101979732513\n",
      "Epoch 1449: \n",
      " mean_squared_error: 0.2281913161277771\n",
      "Epoch 1450: \n",
      " mean_squared_error: 0.2280912697315216\n",
      "Epoch 1451: \n",
      " mean_squared_error: 0.22799059748649597\n",
      "Epoch 1452: \n",
      " mean_squared_error: 0.22788959741592407\n",
      "Epoch 1453: \n",
      " mean_squared_error: 0.2277880758047104\n",
      "Epoch 1454: \n",
      " mean_squared_error: 0.22768603265285492\n",
      "Epoch 1455: \n",
      " mean_squared_error: 0.22758351266384125\n",
      "Epoch 1456: \n",
      " mean_squared_error: 0.22748060524463654\n",
      "Epoch 1457: \n",
      " mean_squared_error: 0.22737716138362885\n",
      "Epoch 1458: \n",
      " mean_squared_error: 0.22727318108081818\n",
      "Epoch 1459: \n",
      " mean_squared_error: 0.22716882824897766\n",
      "Epoch 1460: \n",
      " mean_squared_error: 0.22706395387649536\n",
      "Epoch 1461: \n",
      " mean_squared_error: 0.22695861756801605\n",
      "Epoch 1462: \n",
      " mean_squared_error: 0.22685271501541138\n",
      "Epoch 1463: \n",
      " mean_squared_error: 0.2267463207244873\n",
      "Epoch 1464: \n",
      " mean_squared_error: 0.2266395092010498\n",
      "Epoch 1465: \n",
      " mean_squared_error: 0.2265321910381317\n",
      "Epoch 1466: \n",
      " mean_squared_error: 0.22642436623573303\n",
      "Epoch 1467: \n",
      " mean_squared_error: 0.22631600499153137\n",
      "Epoch 1468: \n",
      " mean_squared_error: 0.2262071669101715\n",
      "Epoch 1469: \n",
      " mean_squared_error: 0.22609785199165344\n",
      "Epoch 1470: \n",
      " mean_squared_error: 0.22598806023597717\n",
      "Epoch 1471: \n",
      " mean_squared_error: 0.22587774693965912\n",
      "Epoch 1472: \n",
      " mean_squared_error: 0.2257668823003769\n",
      "Epoch 1473: \n",
      " mean_squared_error: 0.22565552592277527\n",
      "Epoch 1474: \n",
      " mean_squared_error: 0.22554367780685425\n",
      "Epoch 1475: \n",
      " mean_squared_error: 0.22543130815029144\n",
      "Epoch 1476: \n",
      " mean_squared_error: 0.22531843185424805\n",
      "Epoch 1477: \n",
      " mean_squared_error: 0.22520503401756287\n",
      "Epoch 1478: \n",
      " mean_squared_error: 0.2250911444425583\n",
      "Epoch 1479: \n",
      " mean_squared_error: 0.22497670352458954\n",
      "Epoch 1480: \n",
      " mean_squared_error: 0.224861741065979\n",
      "Epoch 1481: \n",
      " mean_squared_error: 0.22474631667137146\n",
      "Epoch 1482: \n",
      " mean_squared_error: 0.22463028132915497\n",
      "Epoch 1483: \n",
      " mean_squared_error: 0.22451378405094147\n",
      "Epoch 1484: \n",
      " mean_squared_error: 0.2243967354297638\n",
      "Epoch 1485: \n",
      " mean_squared_error: 0.22427918016910553\n",
      "Epoch 1486: \n",
      " mean_squared_error: 0.2241610437631607\n",
      "Epoch 1487: \n",
      " mean_squared_error: 0.22404243052005768\n",
      "Epoch 1488: \n",
      " mean_squared_error: 0.22392329573631287\n",
      "Epoch 1489: \n",
      " mean_squared_error: 0.22380350530147552\n",
      "Epoch 1490: \n",
      " mean_squared_error: 0.22368329763412476\n",
      "Epoch 1491: \n",
      " mean_squared_error: 0.22356250882148743\n",
      "Epoch 1492: \n",
      " mean_squared_error: 0.2234412282705307\n",
      "Epoch 1493: \n",
      " mean_squared_error: 0.2233193963766098\n",
      "Epoch 1494: \n",
      " mean_squared_error: 0.22319698333740234\n",
      "Epoch 1495: \n",
      " mean_squared_error: 0.2230740487575531\n",
      "Epoch 1496: \n",
      " mean_squared_error: 0.2229505330324173\n",
      "Epoch 1497: \n",
      " mean_squared_error: 0.22282648086547852\n",
      "Epoch 1498: \n",
      " mean_squared_error: 0.22270183265209198\n",
      "Epoch 1499: \n",
      " mean_squared_error: 0.22257669270038605\n",
      "Epoch 1500: \n",
      " mean_squared_error: 0.22245098650455475\n",
      "Epoch 1501: \n",
      " mean_squared_error: 0.22232472896575928\n",
      "Epoch 1502: \n",
      " mean_squared_error: 0.22219787538051605\n",
      "Epoch 1503: \n",
      " mean_squared_error: 0.22207055985927582\n",
      "Epoch 1504: \n",
      " mean_squared_error: 0.22194257378578186\n",
      "Epoch 1505: \n",
      " mean_squared_error: 0.22181403636932373\n",
      "Epoch 1506: \n",
      " mean_squared_error: 0.22168490290641785\n",
      "Epoch 1507: \n",
      " mean_squared_error: 0.22155538201332092\n",
      "Epoch 1508: \n",
      " mean_squared_error: 0.2214251309633255\n",
      "Epoch 1509: \n",
      " mean_squared_error: 0.2212943136692047\n",
      "Epoch 1510: \n",
      " mean_squared_error: 0.22116303443908691\n",
      "Epoch 1511: \n",
      " mean_squared_error: 0.221031054854393\n",
      "Epoch 1512: \n",
      " mean_squared_error: 0.2208986133337021\n",
      "Epoch 1513: \n",
      " mean_squared_error: 0.22076547145843506\n",
      "Epoch 1514: \n",
      " mean_squared_error: 0.22063183784484863\n",
      "Epoch 1515: \n",
      " mean_squared_error: 0.22049754858016968\n",
      "Epoch 1516: \n",
      " mean_squared_error: 0.22036272287368774\n",
      "Epoch 1517: \n",
      " mean_squared_error: 0.22022736072540283\n",
      "Epoch 1518: \n",
      " mean_squared_error: 0.22009137272834778\n",
      "Epoch 1519: \n",
      " mean_squared_error: 0.21995478868484497\n",
      "Epoch 1520: \n",
      " mean_squared_error: 0.21981759369373322\n",
      "Epoch 1521: \n",
      " mean_squared_error: 0.2196798026561737\n",
      "Epoch 1522: \n",
      " mean_squared_error: 0.21954147517681122\n",
      "Epoch 1523: \n",
      " mean_squared_error: 0.2194024920463562\n",
      "Epoch 1524: \n",
      " mean_squared_error: 0.2192629724740982\n",
      "Epoch 1525: \n",
      " mean_squared_error: 0.21912284195423126\n",
      "Epoch 1526: \n",
      " mean_squared_error: 0.21898207068443298\n",
      "Epoch 1527: \n",
      " mean_squared_error: 0.21884074807167053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1528: \n",
      " mean_squared_error: 0.21869874000549316\n",
      "Epoch 1529: \n",
      " mean_squared_error: 0.21855619549751282\n",
      "Epoch 1530: \n",
      " mean_squared_error: 0.2184130847454071\n",
      "Epoch 1531: \n",
      " mean_squared_error: 0.21826928853988647\n",
      "Epoch 1532: \n",
      " mean_squared_error: 0.21812492609024048\n",
      "Epoch 1533: \n",
      " mean_squared_error: 0.21797987818717957\n",
      "Epoch 1534: \n",
      " mean_squared_error: 0.21783430874347687\n",
      "Epoch 1535: \n",
      " mean_squared_error: 0.21768806874752045\n",
      "Epoch 1536: \n",
      " mean_squared_error: 0.21754127740859985\n",
      "Epoch 1537: \n",
      " mean_squared_error: 0.21739375591278076\n",
      "Epoch 1538: \n",
      " mean_squared_error: 0.2172456979751587\n",
      "Epoch 1539: \n",
      " mean_squared_error: 0.2170969843864441\n",
      "Epoch 1540: \n",
      " mean_squared_error: 0.21694764494895935\n",
      "Epoch 1541: \n",
      " mean_squared_error: 0.21679772436618805\n",
      "Epoch 1542: \n",
      " mean_squared_error: 0.21664711833000183\n",
      "Epoch 1543: \n",
      " mean_squared_error: 0.21649590134620667\n",
      "Epoch 1544: \n",
      " mean_squared_error: 0.21634407341480255\n",
      "Epoch 1545: \n",
      " mean_squared_error: 0.2161916047334671\n",
      "Epoch 1546: \n",
      " mean_squared_error: 0.21603849530220032\n",
      "Epoch 1547: \n",
      " mean_squared_error: 0.21588478982448578\n",
      "Epoch 1548: \n",
      " mean_squared_error: 0.21573036909103394\n",
      "Epoch 1549: \n",
      " mean_squared_error: 0.21557536721229553\n",
      "Epoch 1550: \n",
      " mean_squared_error: 0.21541966497898102\n",
      "Epoch 1551: \n",
      " mean_squared_error: 0.21526342630386353\n",
      "Epoch 1552: \n",
      " mean_squared_error: 0.21510642766952515\n",
      "Epoch 1553: \n",
      " mean_squared_error: 0.2149488925933838\n",
      "Epoch 1554: \n",
      " mean_squared_error: 0.21479067206382751\n",
      "Epoch 1555: \n",
      " mean_squared_error: 0.21463178098201752\n",
      "Epoch 1556: \n",
      " mean_squared_error: 0.21447226405143738\n",
      "Epoch 1557: \n",
      " mean_squared_error: 0.21431200206279755\n",
      "Epoch 1558: \n",
      " mean_squared_error: 0.21415124833583832\n",
      "Epoch 1559: \n",
      " mean_squared_error: 0.2139897495508194\n",
      "Epoch 1560: \n",
      " mean_squared_error: 0.21382758021354675\n",
      "Epoch 1561: \n",
      " mean_squared_error: 0.21366474032402039\n",
      "Epoch 1562: \n",
      " mean_squared_error: 0.21350130438804626\n",
      "Epoch 1563: \n",
      " mean_squared_error: 0.21333718299865723\n",
      "Epoch 1564: \n",
      " mean_squared_error: 0.21317237615585327\n",
      "Epoch 1565: \n",
      " mean_squared_error: 0.2130068838596344\n",
      "Epoch 1566: \n",
      " mean_squared_error: 0.21284082531929016\n",
      "Epoch 1567: \n",
      " mean_squared_error: 0.21267400681972504\n",
      "Epoch 1568: \n",
      " mean_squared_error: 0.21250654757022858\n",
      "Epoch 1569: \n",
      " mean_squared_error: 0.212338387966156\n",
      "Epoch 1570: \n",
      " mean_squared_error: 0.21216963231563568\n",
      "Epoch 1571: \n",
      " mean_squared_error: 0.21200013160705566\n",
      "Epoch 1572: \n",
      " mean_squared_error: 0.2118299901485443\n",
      "Epoch 1573: \n",
      " mean_squared_error: 0.21165911853313446\n",
      "Epoch 1574: \n",
      " mean_squared_error: 0.2114875614643097\n",
      "Epoch 1575: \n",
      " mean_squared_error: 0.21131546795368195\n",
      "Epoch 1576: \n",
      " mean_squared_error: 0.21114255487918854\n",
      "Epoch 1577: \n",
      " mean_squared_error: 0.2109689712524414\n",
      "Epoch 1578: \n",
      " mean_squared_error: 0.21079474687576294\n",
      "Epoch 1579: \n",
      " mean_squared_error: 0.21061977744102478\n",
      "Epoch 1580: \n",
      " mean_squared_error: 0.21044421195983887\n",
      "Epoch 1581: \n",
      " mean_squared_error: 0.2102678418159485\n",
      "Epoch 1582: \n",
      " mean_squared_error: 0.21009087562561035\n",
      "Epoch 1583: \n",
      " mean_squared_error: 0.2099132239818573\n",
      "Epoch 1584: \n",
      " mean_squared_error: 0.20973485708236694\n",
      "Epoch 1585: \n",
      " mean_squared_error: 0.20955568552017212\n",
      "Epoch 1586: \n",
      " mean_squared_error: 0.20937597751617432\n",
      "Epoch 1587: \n",
      " mean_squared_error: 0.20919546484947205\n",
      "Epoch 1588: \n",
      " mean_squared_error: 0.20901426672935486\n",
      "Epoch 1589: \n",
      " mean_squared_error: 0.20883236825466156\n",
      "Epoch 1590: \n",
      " mean_squared_error: 0.20864979922771454\n",
      "Epoch 1591: \n",
      " mean_squared_error: 0.2084665298461914\n",
      "Epoch 1592: \n",
      " mean_squared_error: 0.2082825005054474\n",
      "Epoch 1593: \n",
      " mean_squared_error: 0.20809787511825562\n",
      "Epoch 1594: \n",
      " mean_squared_error: 0.20791244506835938\n",
      "Epoch 1595: \n",
      " mean_squared_error: 0.2077263742685318\n",
      "Epoch 1596: \n",
      " mean_squared_error: 0.20753945410251617\n",
      "Epoch 1597: \n",
      " mean_squared_error: 0.2073519080877304\n",
      "Epoch 1598: \n",
      " mean_squared_error: 0.20716366171836853\n",
      "Epoch 1599: \n",
      " mean_squared_error: 0.20697468519210815\n",
      "Epoch 1600: \n",
      " mean_squared_error: 0.20678503811359406\n",
      "Epoch 1601: \n",
      " mean_squared_error: 0.2065945565700531\n",
      "Epoch 1602: \n",
      " mean_squared_error: 0.2064034640789032\n",
      "Epoch 1603: \n",
      " mean_squared_error: 0.2062116265296936\n",
      "Epoch 1604: \n",
      " mean_squared_error: 0.20601904392242432\n",
      "Epoch 1605: \n",
      " mean_squared_error: 0.2058257758617401\n",
      "Epoch 1606: \n",
      " mean_squared_error: 0.20563170313835144\n",
      "Epoch 1607: \n",
      " mean_squared_error: 0.20543693006038666\n",
      "Epoch 1608: \n",
      " mean_squared_error: 0.20524142682552338\n",
      "Epoch 1609: \n",
      " mean_squared_error: 0.20504523813724518\n",
      "Epoch 1610: \n",
      " mean_squared_error: 0.2048482447862625\n",
      "Epoch 1611: \n",
      " mean_squared_error: 0.2046506404876709\n",
      "Epoch 1612: \n",
      " mean_squared_error: 0.20445217192173004\n",
      "Epoch 1613: \n",
      " mean_squared_error: 0.20425306260585785\n",
      "Epoch 1614: \n",
      " mean_squared_error: 0.20405313372612\n",
      "Epoch 1615: \n",
      " mean_squared_error: 0.20385251939296722\n",
      "Epoch 1616: \n",
      " mean_squared_error: 0.20365118980407715\n",
      "Epoch 1617: \n",
      " mean_squared_error: 0.20344913005828857\n",
      "Epoch 1618: \n",
      " mean_squared_error: 0.20324629545211792\n",
      "Epoch 1619: \n",
      " mean_squared_error: 0.203042671084404\n",
      "Epoch 1620: \n",
      " mean_squared_error: 0.20283836126327515\n",
      "Epoch 1621: \n",
      " mean_squared_error: 0.2026333063840866\n",
      "Epoch 1622: \n",
      " mean_squared_error: 0.2024274468421936\n",
      "Epoch 1623: \n",
      " mean_squared_error: 0.20222090184688568\n",
      "Epoch 1624: \n",
      " mean_squared_error: 0.20201361179351807\n",
      "Epoch 1625: \n",
      " mean_squared_error: 0.20180553197860718\n",
      "Epoch 1626: \n",
      " mean_squared_error: 0.2015967071056366\n",
      "Epoch 1627: \n",
      " mean_squared_error: 0.20138715207576752\n",
      "Epoch 1628: \n",
      " mean_squared_error: 0.20117680728435516\n",
      "Epoch 1629: \n",
      " mean_squared_error: 0.20096567273139954\n",
      "Epoch 1630: \n",
      " mean_squared_error: 0.20075386762619019\n",
      "Epoch 1631: \n",
      " mean_squared_error: 0.20054131746292114\n",
      "Epoch 1632: \n",
      " mean_squared_error: 0.20032790303230286\n",
      "Epoch 1633: \n",
      " mean_squared_error: 0.20011383295059204\n",
      "Epoch 1634: \n",
      " mean_squared_error: 0.19989892840385437\n",
      "Epoch 1635: \n",
      " mean_squared_error: 0.19968333840370178\n",
      "Epoch 1636: \n",
      " mean_squared_error: 0.19946689903736115\n",
      "Epoch 1637: \n",
      " mean_squared_error: 0.19924980401992798\n",
      "Epoch 1638: \n",
      " mean_squared_error: 0.19903188943862915\n",
      "Epoch 1639: \n",
      " mean_squared_error: 0.19881324470043182\n",
      "Epoch 1640: \n",
      " mean_squared_error: 0.19859367609024048\n",
      "Epoch 1641: \n",
      " mean_squared_error: 0.19837351143360138\n",
      "Epoch 1642: \n",
      " mean_squared_error: 0.19815251231193542\n",
      "Epoch 1643: \n",
      " mean_squared_error: 0.19793076813220978\n",
      "Epoch 1644: \n",
      " mean_squared_error: 0.19770818948745728\n",
      "Epoch 1645: \n",
      " mean_squared_error: 0.19748491048812866\n",
      "Epoch 1646: \n",
      " mean_squared_error: 0.19726082682609558\n",
      "Epoch 1647: \n",
      " mean_squared_error: 0.1970359832048416\n",
      "Epoch 1648: \n",
      " mean_squared_error: 0.19681033492088318\n",
      "Epoch 1649: \n",
      " mean_squared_error: 0.19658389687538147\n",
      "Epoch 1650: \n",
      " mean_squared_error: 0.19635671377182007\n",
      "Epoch 1651: \n",
      " mean_squared_error: 0.1961287558078766\n",
      "Epoch 1652: \n",
      " mean_squared_error: 0.19589999318122864\n",
      "Epoch 1653: \n",
      " mean_squared_error: 0.195670485496521\n",
      "Epoch 1654: \n",
      " mean_squared_error: 0.19544020295143127\n",
      "Epoch 1655: \n",
      " mean_squared_error: 0.19520913064479828\n",
      "Epoch 1656: \n",
      " mean_squared_error: 0.194977268576622\n",
      "Epoch 1657: \n",
      " mean_squared_error: 0.19474461674690247\n",
      "Epoch 1658: \n",
      " mean_squared_error: 0.19451114535331726\n",
      "Epoch 1659: \n",
      " mean_squared_error: 0.19427698850631714\n",
      "Epoch 1660: \n",
      " mean_squared_error: 0.19404196739196777\n",
      "Epoch 1661: \n",
      " mean_squared_error: 0.19380617141723633\n",
      "Epoch 1662: \n",
      " mean_squared_error: 0.19356957077980042\n",
      "Epoch 1663: \n",
      " mean_squared_error: 0.19333219528198242\n",
      "Epoch 1664: \n",
      " mean_squared_error: 0.19309401512145996\n",
      "Epoch 1665: \n",
      " mean_squared_error: 0.1928551197052002\n",
      "Epoch 1666: \n",
      " mean_squared_error: 0.1926153600215912\n",
      "Epoch 1667: \n",
      " mean_squared_error: 0.19237487018108368\n",
      "Epoch 1668: \n",
      " mean_squared_error: 0.1921335607767105\n",
      "Epoch 1669: \n",
      " mean_squared_error: 0.19189134240150452\n",
      "Epoch 1670: \n",
      " mean_squared_error: 0.1916484385728836\n",
      "Epoch 1671: \n",
      " mean_squared_error: 0.1914048194885254\n",
      "Epoch 1672: \n",
      " mean_squared_error: 0.19116029143333435\n",
      "Epoch 1673: \n",
      " mean_squared_error: 0.190915048122406\n",
      "Epoch 1674: \n",
      " mean_squared_error: 0.19066894054412842\n",
      "Epoch 1675: \n",
      " mean_squared_error: 0.19042202830314636\n",
      "Epoch 1676: \n",
      " mean_squared_error: 0.19017434120178223\n",
      "Epoch 1677: \n",
      " mean_squared_error: 0.189925879240036\n",
      "Epoch 1678: \n",
      " mean_squared_error: 0.18967659771442413\n",
      "Epoch 1679: \n",
      " mean_squared_error: 0.18942654132843018\n",
      "Epoch 1680: \n",
      " mean_squared_error: 0.18917566537857056\n",
      "Epoch 1681: \n",
      " mean_squared_error: 0.18892398476600647\n",
      "Epoch 1682: \n",
      " mean_squared_error: 0.1886715143918991\n",
      "Epoch 1683: \n",
      " mean_squared_error: 0.18841823935508728\n",
      "Epoch 1684: \n",
      " mean_squared_error: 0.18816420435905457\n",
      "Epoch 1685: \n",
      " mean_squared_error: 0.187909334897995\n",
      "Epoch 1686: \n",
      " mean_squared_error: 0.18765361607074738\n",
      "Epoch 1687: \n",
      " mean_squared_error: 0.18739718198776245\n",
      "Epoch 1688: \n",
      " mean_squared_error: 0.18713991343975067\n",
      "Epoch 1689: \n",
      " mean_squared_error: 0.18688185513019562\n",
      "Epoch 1690: \n",
      " mean_squared_error: 0.1866229921579361\n",
      "Epoch 1691: \n",
      " mean_squared_error: 0.18636323511600494\n",
      "Epoch 1692: \n",
      " mean_squared_error: 0.1861027330160141\n",
      "Epoch 1693: \n",
      " mean_squared_error: 0.18584144115447998\n",
      "Epoch 1694: \n",
      " mean_squared_error: 0.18557941913604736\n",
      "Epoch 1695: \n",
      " mean_squared_error: 0.1853165626525879\n",
      "Epoch 1696: \n",
      " mean_squared_error: 0.1850527822971344\n",
      "Epoch 1697: \n",
      " mean_squared_error: 0.18478822708129883\n",
      "Epoch 1698: \n",
      " mean_squared_error: 0.18452295660972595\n",
      "Epoch 1699: \n",
      " mean_squared_error: 0.1842568814754486\n",
      "Epoch 1700: \n",
      " mean_squared_error: 0.18398985266685486\n",
      "Epoch 1701: \n",
      " mean_squared_error: 0.18372216820716858\n",
      "Epoch 1702: \n",
      " mean_squared_error: 0.18345361948013306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1703: \n",
      " mean_squared_error: 0.18318432569503784\n",
      "Epoch 1704: \n",
      " mean_squared_error: 0.182914137840271\n",
      "Epoch 1705: \n",
      " mean_squared_error: 0.18264317512512207\n",
      "Epoch 1706: \n",
      " mean_squared_error: 0.18237146735191345\n",
      "Epoch 1707: \n",
      " mean_squared_error: 0.18209895491600037\n",
      "Epoch 1708: \n",
      " mean_squared_error: 0.18182554841041565\n",
      "Epoch 1709: \n",
      " mean_squared_error: 0.18155136704444885\n",
      "Epoch 1710: \n",
      " mean_squared_error: 0.1812763810157776\n",
      "Epoch 1711: \n",
      " mean_squared_error: 0.18100063502788544\n",
      "Epoch 1712: \n",
      " mean_squared_error: 0.18072403967380524\n",
      "Epoch 1713: \n",
      " mean_squared_error: 0.180446594953537\n",
      "Epoch 1714: \n",
      " mean_squared_error: 0.18016842007637024\n",
      "Epoch 1715: \n",
      " mean_squared_error: 0.17988941073417664\n",
      "Epoch 1716: \n",
      " mean_squared_error: 0.17960967123508453\n",
      "Epoch 1717: \n",
      " mean_squared_error: 0.1793290376663208\n",
      "Epoch 1718: \n",
      " mean_squared_error: 0.17904767394065857\n",
      "Epoch 1719: \n",
      " mean_squared_error: 0.1787654459476471\n",
      "Epoch 1720: \n",
      " mean_squared_error: 0.17848242819309235\n",
      "Epoch 1721: \n",
      " mean_squared_error: 0.17819863557815552\n",
      "Epoch 1722: \n",
      " mean_squared_error: 0.17791397869586945\n",
      "Epoch 1723: \n",
      " mean_squared_error: 0.17762863636016846\n",
      "Epoch 1724: \n",
      " mean_squared_error: 0.17734237015247345\n",
      "Epoch 1725: \n",
      " mean_squared_error: 0.17705541849136353\n",
      "Epoch 1726: \n",
      " mean_squared_error: 0.17676754295825958\n",
      "Epoch 1727: \n",
      " mean_squared_error: 0.17647896707057953\n",
      "Epoch 1728: \n",
      " mean_squared_error: 0.1761896163225174\n",
      "Epoch 1729: \n",
      " mean_squared_error: 0.17589934170246124\n",
      "Epoch 1730: \n",
      " mean_squared_error: 0.17560827732086182\n",
      "Epoch 1731: \n",
      " mean_squared_error: 0.17531658709049225\n",
      "Epoch 1732: \n",
      " mean_squared_error: 0.17502397298812866\n",
      "Epoch 1733: \n",
      " mean_squared_error: 0.1747305691242218\n",
      "Epoch 1734: \n",
      " mean_squared_error: 0.17443639039993286\n",
      "Epoch 1735: \n",
      " mean_squared_error: 0.17414143681526184\n",
      "Epoch 1736: \n",
      " mean_squared_error: 0.17384567856788635\n",
      "Epoch 1737: \n",
      " mean_squared_error: 0.1735491156578064\n",
      "Epoch 1738: \n",
      " mean_squared_error: 0.17325171828269958\n",
      "Epoch 1739: \n",
      " mean_squared_error: 0.17295362055301666\n",
      "Epoch 1740: \n",
      " mean_squared_error: 0.1726546585559845\n",
      "Epoch 1741: \n",
      " mean_squared_error: 0.17235496640205383\n",
      "Epoch 1742: \n",
      " mean_squared_error: 0.1720544546842575\n",
      "Epoch 1743: \n",
      " mean_squared_error: 0.1717531979084015\n",
      "Epoch 1744: \n",
      " mean_squared_error: 0.17145110666751862\n",
      "Epoch 1745: \n",
      " mean_squared_error: 0.17114832997322083\n",
      "Epoch 1746: \n",
      " mean_squared_error: 0.17084462940692902\n",
      "Epoch 1747: \n",
      " mean_squared_error: 0.1705402135848999\n",
      "Epoch 1748: \n",
      " mean_squared_error: 0.17023508250713348\n",
      "Epoch 1749: \n",
      " mean_squared_error: 0.16992908716201782\n",
      "Epoch 1750: \n",
      " mean_squared_error: 0.16962233185768127\n",
      "Epoch 1751: \n",
      " mean_squared_error: 0.16931477189064026\n",
      "Epoch 1752: \n",
      " mean_squared_error: 0.16900646686553955\n",
      "Epoch 1753: \n",
      " mean_squared_error: 0.16869735717773438\n",
      "Epoch 1754: \n",
      " mean_squared_error: 0.1683875471353531\n",
      "Epoch 1755: \n",
      " mean_squared_error: 0.16807696223258972\n",
      "Epoch 1756: \n",
      " mean_squared_error: 0.1677655428647995\n",
      "Epoch 1757: \n",
      " mean_squared_error: 0.16745343804359436\n",
      "Epoch 1758: \n",
      " mean_squared_error: 0.16714051365852356\n",
      "Epoch 1759: \n",
      " mean_squared_error: 0.1668267846107483\n",
      "Epoch 1760: \n",
      " mean_squared_error: 0.1665124148130417\n",
      "Epoch 1761: \n",
      " mean_squared_error: 0.16619721055030823\n",
      "Epoch 1762: \n",
      " mean_squared_error: 0.1658811867237091\n",
      "Epoch 1763: \n",
      " mean_squared_error: 0.16556450724601746\n",
      "Epoch 1764: \n",
      " mean_squared_error: 0.16524702310562134\n",
      "Epoch 1765: \n",
      " mean_squared_error: 0.1649288535118103\n",
      "Epoch 1766: \n",
      " mean_squared_error: 0.1646098494529724\n",
      "Epoch 1767: \n",
      " mean_squared_error: 0.16429007053375244\n",
      "Epoch 1768: \n",
      " mean_squared_error: 0.16396962106227875\n",
      "Epoch 1769: \n",
      " mean_squared_error: 0.16364842653274536\n",
      "Epoch 1770: \n",
      " mean_squared_error: 0.1633264422416687\n",
      "Epoch 1771: \n",
      " mean_squared_error: 0.16300374269485474\n",
      "Epoch 1772: \n",
      " mean_squared_error: 0.1626802384853363\n",
      "Epoch 1773: \n",
      " mean_squared_error: 0.16235606372356415\n",
      "Epoch 1774: \n",
      " mean_squared_error: 0.1620311439037323\n",
      "Epoch 1775: \n",
      " mean_squared_error: 0.16170553863048553\n",
      "Epoch 1776: \n",
      " mean_squared_error: 0.1613791286945343\n",
      "Epoch 1777: \n",
      " mean_squared_error: 0.16105207800865173\n",
      "Epoch 1778: \n",
      " mean_squared_error: 0.1607241928577423\n",
      "Epoch 1779: \n",
      " mean_squared_error: 0.16039559245109558\n",
      "Epoch 1780: \n",
      " mean_squared_error: 0.1600663810968399\n",
      "Epoch 1781: \n",
      " mean_squared_error: 0.15973633527755737\n",
      "Epoch 1782: \n",
      " mean_squared_error: 0.15940561890602112\n",
      "Epoch 1783: \n",
      " mean_squared_error: 0.15907415747642517\n",
      "Epoch 1784: \n",
      " mean_squared_error: 0.1587420403957367\n",
      "Epoch 1785: \n",
      " mean_squared_error: 0.1584092080593109\n",
      "Epoch 1786: \n",
      " mean_squared_error: 0.15807564556598663\n",
      "Epoch 1787: \n",
      " mean_squared_error: 0.15774136781692505\n",
      "Epoch 1788: \n",
      " mean_squared_error: 0.15740637481212616\n",
      "Epoch 1789: \n",
      " mean_squared_error: 0.15707075595855713\n",
      "Epoch 1790: \n",
      " mean_squared_error: 0.156734436750412\n",
      "Epoch 1791: \n",
      " mean_squared_error: 0.15639734268188477\n",
      "Epoch 1792: \n",
      " mean_squared_error: 0.1560596078634262\n",
      "Epoch 1793: \n",
      " mean_squared_error: 0.15572115778923035\n",
      "Epoch 1794: \n",
      " mean_squared_error: 0.15538200736045837\n",
      "Epoch 1795: \n",
      " mean_squared_error: 0.15504227578639984\n",
      "Epoch 1796: \n",
      " mean_squared_error: 0.154701828956604\n",
      "Epoch 1797: \n",
      " mean_squared_error: 0.15436065196990967\n",
      "Epoch 1798: \n",
      " mean_squared_error: 0.1540188491344452\n",
      "Epoch 1799: \n",
      " mean_squared_error: 0.15367640554904938\n",
      "Epoch 1800: \n",
      " mean_squared_error: 0.15333320200443268\n",
      "Epoch 1801: \n",
      " mean_squared_error: 0.1529894471168518\n",
      "Epoch 1802: \n",
      " mean_squared_error: 0.15264494717121124\n",
      "Epoch 1803: \n",
      " mean_squared_error: 0.15229982137680054\n",
      "Epoch 1804: \n",
      " mean_squared_error: 0.15195399522781372\n",
      "Epoch 1805: \n",
      " mean_squared_error: 0.15160763263702393\n",
      "Epoch 1806: \n",
      " mean_squared_error: 0.15126055479049683\n",
      "Epoch 1807: \n",
      " mean_squared_error: 0.15091292560100555\n",
      "Epoch 1808: \n",
      " mean_squared_error: 0.15056449174880981\n",
      "Epoch 1809: \n",
      " mean_squared_error: 0.15021547675132751\n",
      "Epoch 1810: \n",
      " mean_squared_error: 0.14986589550971985\n",
      "Epoch 1811: \n",
      " mean_squared_error: 0.14951568841934204\n",
      "Epoch 1812: \n",
      " mean_squared_error: 0.1491648554801941\n",
      "Epoch 1813: \n",
      " mean_squared_error: 0.14881333708763123\n",
      "Epoch 1814: \n",
      " mean_squared_error: 0.14846129715442657\n",
      "Epoch 1815: \n",
      " mean_squared_error: 0.148108571767807\n",
      "Epoch 1816: \n",
      " mean_squared_error: 0.14775526523590088\n",
      "Epoch 1817: \n",
      " mean_squared_error: 0.14740139245986938\n",
      "Epoch 1818: \n",
      " mean_squared_error: 0.14704689383506775\n",
      "Epoch 1819: \n",
      " mean_squared_error: 0.14669176936149597\n",
      "Epoch 1820: \n",
      " mean_squared_error: 0.14633606374263763\n",
      "Epoch 1821: \n",
      " mean_squared_error: 0.14597979187965393\n",
      "Epoch 1822: \n",
      " mean_squared_error: 0.1456228792667389\n",
      "Epoch 1823: \n",
      " mean_squared_error: 0.14526546001434326\n",
      "Epoch 1824: \n",
      " mean_squared_error: 0.14490744471549988\n",
      "Epoch 1825: \n",
      " mean_squared_error: 0.14454886317253113\n",
      "Epoch 1826: \n",
      " mean_squared_error: 0.1441897302865982\n",
      "Epoch 1827: \n",
      " mean_squared_error: 0.14382997155189514\n",
      "Epoch 1828: \n",
      " mean_squared_error: 0.1434696912765503\n",
      "Epoch 1829: \n",
      " mean_squared_error: 0.14310887455940247\n",
      "Epoch 1830: \n",
      " mean_squared_error: 0.14274746179580688\n",
      "Epoch 1831: \n",
      " mean_squared_error: 0.14238561689853668\n",
      "Epoch 1832: \n",
      " mean_squared_error: 0.14202314615249634\n",
      "Epoch 1833: \n",
      " mean_squared_error: 0.1416601687669754\n",
      "Epoch 1834: \n",
      " mean_squared_error: 0.1412966251373291\n",
      "Epoch 1835: \n",
      " mean_squared_error: 0.1409325748682022\n",
      "Epoch 1836: \n",
      " mean_squared_error: 0.14056800305843353\n",
      "Epoch 1837: \n",
      " mean_squared_error: 0.14020289480686188\n",
      "Epoch 1838: \n",
      " mean_squared_error: 0.13983741402626038\n",
      "Epoch 1839: \n",
      " mean_squared_error: 0.13947129249572754\n",
      "Epoch 1840: \n",
      " mean_squared_error: 0.1391047090291977\n",
      "Epoch 1841: \n",
      " mean_squared_error: 0.13873764872550964\n",
      "Epoch 1842: \n",
      " mean_squared_error: 0.13837003707885742\n",
      "Epoch 1843: \n",
      " mean_squared_error: 0.13800202310085297\n",
      "Epoch 1844: \n",
      " mean_squared_error: 0.13763347268104553\n",
      "Epoch 1845: \n",
      " mean_squared_error: 0.1372644603252411\n",
      "Epoch 1846: \n",
      " mean_squared_error: 0.13689503073692322\n",
      "Epoch 1847: \n",
      " mean_squared_error: 0.13652506470680237\n",
      "Epoch 1848: \n",
      " mean_squared_error: 0.1361546516418457\n",
      "Epoch 1849: \n",
      " mean_squared_error: 0.13578379154205322\n",
      "Epoch 1850: \n",
      " mean_squared_error: 0.13541249930858612\n",
      "Epoch 1851: \n",
      " mean_squared_error: 0.1350407600402832\n",
      "Epoch 1852: \n",
      " mean_squared_error: 0.13466858863830566\n",
      "Epoch 1853: \n",
      " mean_squared_error: 0.1342959851026535\n",
      "Epoch 1854: \n",
      " mean_squared_error: 0.13392291963100433\n",
      "Epoch 1855: \n",
      " mean_squared_error: 0.13354945182800293\n",
      "Epoch 1856: \n",
      " mean_squared_error: 0.13317561149597168\n",
      "Epoch 1857: \n",
      " mean_squared_error: 0.1328013390302658\n",
      "Epoch 1858: \n",
      " mean_squared_error: 0.13242663443088531\n",
      "Epoch 1859: \n",
      " mean_squared_error: 0.13205160200595856\n",
      "Epoch 1860: \n",
      " mean_squared_error: 0.13167616724967957\n",
      "Epoch 1861: \n",
      " mean_squared_error: 0.13130022585391998\n",
      "Epoch 1862: \n",
      " mean_squared_error: 0.1309240460395813\n",
      "Epoch 1863: \n",
      " mean_squared_error: 0.1305473893880844\n",
      "Epoch 1864: \n",
      " mean_squared_error: 0.13017043471336365\n",
      "Epoch 1865: \n",
      " mean_squared_error: 0.12979306280612946\n",
      "Epoch 1866: \n",
      " mean_squared_error: 0.1294153928756714\n",
      "Epoch 1867: \n",
      " mean_squared_error: 0.12903736531734467\n",
      "Epoch 1868: \n",
      " mean_squared_error: 0.1286589801311493\n",
      "Epoch 1869: \n",
      " mean_squared_error: 0.12828023731708527\n",
      "Epoch 1870: \n",
      " mean_squared_error: 0.12790118157863617\n",
      "Epoch 1871: \n",
      " mean_squared_error: 0.12752178311347961\n",
      "Epoch 1872: \n",
      " mean_squared_error: 0.12714211642742157\n",
      "Epoch 1873: \n",
      " mean_squared_error: 0.12676209211349487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1874: \n",
      " mean_squared_error: 0.12638181447982788\n",
      "Epoch 1875: \n",
      " mean_squared_error: 0.12600117921829224\n",
      "Epoch 1876: \n",
      " mean_squared_error: 0.12562021613121033\n",
      "Epoch 1877: \n",
      " mean_squared_error: 0.12523901462554932\n",
      "Epoch 1878: \n",
      " mean_squared_error: 0.1248575821518898\n",
      "Epoch 1879: \n",
      " mean_squared_error: 0.12447580695152283\n",
      "Epoch 1880: \n",
      " mean_squared_error: 0.12409378588199615\n",
      "Epoch 1881: \n",
      " mean_squared_error: 0.12371152639389038\n",
      "Epoch 1882: \n",
      " mean_squared_error: 0.12332897633314133\n",
      "Epoch 1883: \n",
      " mean_squared_error: 0.12294620275497437\n",
      "Epoch 1884: \n",
      " mean_squared_error: 0.12256310880184174\n",
      "Epoch 1885: \n",
      " mean_squared_error: 0.12217988073825836\n",
      "Epoch 1886: \n",
      " mean_squared_error: 0.12179639935493469\n",
      "Epoch 1887: \n",
      " mean_squared_error: 0.12141270190477371\n",
      "Epoch 1888: \n",
      " mean_squared_error: 0.12102875858545303\n",
      "Epoch 1889: \n",
      " mean_squared_error: 0.12064463645219803\n",
      "Epoch 1890: \n",
      " mean_squared_error: 0.12026027590036392\n",
      "Epoch 1891: \n",
      " mean_squared_error: 0.11987572908401489\n",
      "Epoch 1892: \n",
      " mean_squared_error: 0.11949104070663452\n",
      "Epoch 1893: \n",
      " mean_squared_error: 0.11910610646009445\n",
      "Epoch 1894: \n",
      " mean_squared_error: 0.11872106790542603\n",
      "Epoch 1895: \n",
      " mean_squared_error: 0.11833585798740387\n",
      "Epoch 1896: \n",
      " mean_squared_error: 0.117950439453125\n",
      "Epoch 1897: \n",
      " mean_squared_error: 0.11756492406129837\n",
      "Epoch 1898: \n",
      " mean_squared_error: 0.11717920005321503\n",
      "Epoch 1899: \n",
      " mean_squared_error: 0.11679336428642273\n",
      "Epoch 1900: \n",
      " mean_squared_error: 0.1164073720574379\n",
      "Epoch 1901: \n",
      " mean_squared_error: 0.11602135002613068\n",
      "Epoch 1902: \n",
      " mean_squared_error: 0.11563506722450256\n",
      "Epoch 1903: \n",
      " mean_squared_error: 0.11524879187345505\n",
      "Epoch 1904: \n",
      " mean_squared_error: 0.11486237496137619\n",
      "Epoch 1905: \n",
      " mean_squared_error: 0.11447585374116898\n",
      "Epoch 1906: \n",
      " mean_squared_error: 0.11408919841051102\n",
      "Epoch 1907: \n",
      " mean_squared_error: 0.11370257288217545\n",
      "Epoch 1908: \n",
      " mean_squared_error: 0.11331579089164734\n",
      "Epoch 1909: \n",
      " mean_squared_error: 0.11292898654937744\n",
      "Epoch 1910: \n",
      " mean_squared_error: 0.11254209280014038\n",
      "Epoch 1911: \n",
      " mean_squared_error: 0.11215519905090332\n",
      "Epoch 1912: \n",
      " mean_squared_error: 0.11176817119121552\n",
      "Epoch 1913: \n",
      " mean_squared_error: 0.1113811656832695\n",
      "Epoch 1914: \n",
      " mean_squared_error: 0.1109941378235817\n",
      "Epoch 1915: \n",
      " mean_squared_error: 0.11060705780982971\n",
      "Epoch 1916: \n",
      " mean_squared_error: 0.11021999269723892\n",
      "Epoch 1917: \n",
      " mean_squared_error: 0.10983286052942276\n",
      "Epoch 1918: \n",
      " mean_squared_error: 0.10944576561450958\n",
      "Epoch 1919: \n",
      " mean_squared_error: 0.109058678150177\n",
      "Epoch 1920: \n",
      " mean_squared_error: 0.1086716279387474\n",
      "Epoch 1921: \n",
      " mean_squared_error: 0.10828458517789841\n",
      "Epoch 1922: \n",
      " mean_squared_error: 0.10789758712053299\n",
      "Epoch 1923: \n",
      " mean_squared_error: 0.10751055181026459\n",
      "Epoch 1924: \n",
      " mean_squared_error: 0.10712361335754395\n",
      "Epoch 1925: \n",
      " mean_squared_error: 0.10673671215772629\n",
      "Epoch 1926: \n",
      " mean_squared_error: 0.106349878013134\n",
      "Epoch 1927: \n",
      " mean_squared_error: 0.10596311092376709\n",
      "Epoch 1928: \n",
      " mean_squared_error: 0.10557644069194794\n",
      "Epoch 1929: \n",
      " mean_squared_error: 0.10518981516361237\n",
      "Epoch 1930: \n",
      " mean_squared_error: 0.10480328649282455\n",
      "Epoch 1931: \n",
      " mean_squared_error: 0.10441690683364868\n",
      "Epoch 1932: \n",
      " mean_squared_error: 0.10403062403202057\n",
      "Epoch 1933: \n",
      " mean_squared_error: 0.10364434868097305\n",
      "Epoch 1934: \n",
      " mean_squared_error: 0.10325828939676285\n",
      "Epoch 1935: \n",
      " mean_squared_error: 0.1028723195195198\n",
      "Epoch 1936: \n",
      " mean_squared_error: 0.1024865061044693\n",
      "Epoch 1937: \n",
      " mean_squared_error: 0.10210081189870834\n",
      "Epoch 1938: \n",
      " mean_squared_error: 0.10171525925397873\n",
      "Epoch 1939: \n",
      " mean_squared_error: 0.10132992267608643\n",
      "Epoch 1940: \n",
      " mean_squared_error: 0.10094468295574188\n",
      "Epoch 1941: \n",
      " mean_squared_error: 0.10055965185165405\n",
      "Epoch 1942: \n",
      " mean_squared_error: 0.10017479956150055\n",
      "Epoch 1943: \n",
      " mean_squared_error: 0.09979017078876495\n",
      "Epoch 1944: \n",
      " mean_squared_error: 0.09940560907125473\n",
      "Epoch 1945: \n",
      " mean_squared_error: 0.09902135282754898\n",
      "Epoch 1946: \n",
      " mean_squared_error: 0.09863729029893875\n",
      "Epoch 1947: \n",
      " mean_squared_error: 0.09825344383716583\n",
      "Epoch 1948: \n",
      " mean_squared_error: 0.0978698581457138\n",
      "Epoch 1949: \n",
      " mean_squared_error: 0.09748642891645432\n",
      "Epoch 1950: \n",
      " mean_squared_error: 0.09710325300693512\n",
      "Epoch 1951: \n",
      " mean_squared_error: 0.0967203825712204\n",
      "Epoch 1952: \n",
      " mean_squared_error: 0.09633769094944\n",
      "Epoch 1953: \n",
      " mean_squared_error: 0.09595533460378647\n",
      "Epoch 1954: \n",
      " mean_squared_error: 0.09557322412729263\n",
      "Epoch 1955: \n",
      " mean_squared_error: 0.09519137442111969\n",
      "Epoch 1956: \n",
      " mean_squared_error: 0.0948098674416542\n",
      "Epoch 1957: \n",
      " mean_squared_error: 0.09442859888076782\n",
      "Epoch 1958: \n",
      " mean_squared_error: 0.09404763579368591\n",
      "Epoch 1959: \n",
      " mean_squared_error: 0.09366701543331146\n",
      "Epoch 1960: \n",
      " mean_squared_error: 0.0932866781949997\n",
      "Epoch 1961: \n",
      " mean_squared_error: 0.092906653881073\n",
      "Epoch 1962: \n",
      " mean_squared_error: 0.09252698719501495\n",
      "Epoch 1963: \n",
      " mean_squared_error: 0.09214761853218079\n",
      "Epoch 1964: \n",
      " mean_squared_error: 0.09176865220069885\n",
      "Epoch 1965: \n",
      " mean_squared_error: 0.09138999879360199\n",
      "Epoch 1966: \n",
      " mean_squared_error: 0.09101173281669617\n",
      "Epoch 1967: \n",
      " mean_squared_error: 0.09063379466533661\n",
      "Epoch 1968: \n",
      " mean_squared_error: 0.09025624394416809\n",
      "Epoch 1969: \n",
      " mean_squared_error: 0.089879110455513\n",
      "Epoch 1970: \n",
      " mean_squared_error: 0.08950231969356537\n",
      "Epoch 1971: \n",
      " mean_squared_error: 0.08912596106529236\n",
      "Epoch 1972: \n",
      " mean_squared_error: 0.08874999731779099\n",
      "Epoch 1973: \n",
      " mean_squared_error: 0.08837442100048065\n",
      "Epoch 1974: \n",
      " mean_squared_error: 0.08799928426742554\n",
      "Epoch 1975: \n",
      " mean_squared_error: 0.08762455731630325\n",
      "Epoch 1976: \n",
      " mean_squared_error: 0.08725027740001678\n",
      "Epoch 1977: \n",
      " mean_squared_error: 0.08687646687030792\n",
      "Epoch 1978: \n",
      " mean_squared_error: 0.08650307357311249\n",
      "Epoch 1979: \n",
      " mean_squared_error: 0.08613014221191406\n",
      "Epoch 1980: \n",
      " mean_squared_error: 0.08575762808322906\n",
      "Epoch 1981: \n",
      " mean_squared_error: 0.08538562059402466\n",
      "Epoch 1982: \n",
      " mean_squared_error: 0.08501409739255905\n",
      "Epoch 1983: \n",
      " mean_squared_error: 0.08464302122592926\n",
      "Epoch 1984: \n",
      " mean_squared_error: 0.08427251875400543\n",
      "Epoch 1985: \n",
      " mean_squared_error: 0.08390241116285324\n",
      "Epoch 1986: \n",
      " mean_squared_error: 0.08353287726640701\n",
      "Epoch 1987: \n",
      " mean_squared_error: 0.0831637978553772\n",
      "Epoch 1988: \n",
      " mean_squared_error: 0.08279526233673096\n",
      "Epoch 1989: \n",
      " mean_squared_error: 0.08242729306221008\n",
      "Epoch 1990: \n",
      " mean_squared_error: 0.08205980062484741\n",
      "Epoch 1991: \n",
      " mean_squared_error: 0.08169285953044891\n",
      "Epoch 1992: \n",
      " mean_squared_error: 0.08132648468017578\n",
      "Epoch 1993: \n",
      " mean_squared_error: 0.08096059411764145\n",
      "Epoch 1994: \n",
      " mean_squared_error: 0.08059532195329666\n",
      "Epoch 1995: \n",
      " mean_squared_error: 0.08023062348365784\n",
      "Epoch 1996: \n",
      " mean_squared_error: 0.0798664391040802\n",
      "Epoch 1997: \n",
      " mean_squared_error: 0.0795028954744339\n",
      "Epoch 1998: \n",
      " mean_squared_error: 0.07913989573717117\n",
      "Epoch 1999: \n",
      " mean_squared_error: 0.07877752184867859\n",
      "Epoch 2000: \n",
      " mean_squared_error: 0.07841572165489197\n"
     ]
    }
   ],
   "source": [
    "## Trainign Loop\n",
    "\n",
    "epochs = 2000\n",
    "# Instantiate an optimizer to train the model.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-1)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model1(X)\n",
    "        loss_value = loss_fn(Y, preds)\n",
    "    grads = tape.gradient(loss_value, model1.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model1.trainable_variables))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: \\n mean_squared_error: {loss_value}\")\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "83cc72ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       "array([[0.21441436],\n",
       "       [0.7191172 ],\n",
       "       [0.7199412 ],\n",
       "       [0.33002514]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75521db",
   "metadata": {},
   "source": [
    "### Collect the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f0cd52f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = []\n",
    "B = []\n",
    "deltas_w = []\n",
    "deltas_b = []\n",
    "\n",
    "for layer in model1.layers:\n",
    "    W.append(layer.w)\n",
    "    B.append(layer.b)\n",
    "    deltas_w.append(tf.random.normal(shape=layer.w.shape))\n",
    "    deltas_b.append(tf.random.normal(shape=layer.b.shape))\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3d653eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 10\n",
    "step = 0.01\n",
    "alphas = list(np.arange(-limit,0, step)) + list(np.arange(0, limit, step))\n",
    "losses = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    \n",
    "    W_m = []\n",
    "    B_m = []\n",
    "\n",
    "    for l in range(len(W)):\n",
    "        w_m = W[l] + alpha * deltas_w[l]\n",
    "        b_m = B[l] + alpha * deltas_b[l]\n",
    "        W_m.append(w_m)\n",
    "        B_m.append(b_m)\n",
    "        \n",
    "    predicted = model1(X, W_m, B_m)\n",
    "    loss_value = loss_fn(Y, predicted)\n",
    "    losses.append(loss_value.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d7bf9945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       "array([[0.21441436],\n",
       "       [0.7191172 ],\n",
       "       [0.7199412 ],\n",
       "       [0.33002514]], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f5708d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.lineplot(x=alphas, y=losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe348bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07785252"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "635426fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets as ds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b807c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = ds.make_classification(n_samples=2000, n_classes=2, n_features=2, n_informative=2, n_redundant=0, \n",
    "                             n_clusters_per_class=1,class_sep=2,flip_y=0, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e2cd20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b1c3ec2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAC5zklEQVR4nOydZ3RbVdaGH3XJsiX33rudxI7TeyONkgCh997rDG1geqHODDAMDBB67z2EACEkJKT3Yse9927Z6tL9fhxbtiInJCR8kKBnrawZH997dSWZfc7d593vlkmShB8/fvz4OX6R/9w34MePHz9+jg5/IPfjx4+f4xx/IPfjx4+f4xx/IPfjx4+f4xx/IPfjx4+f4xzlz/Gi4eHhUnJy8s/x0n78+PFz3LJt27Y2SZIiDhz/WQJ5cnIyW7du/Tle2o8fP36OW2QyWfVw4/7Uih8/fvwc5/gDuR8/fvwc5/gDuR8/fvwc5/wsOXI/fvz4+TlwOBzU1dVhtVp/7ls5JFqtlvj4eFQq1WEd7w/kfvz4+dVQV1dHUFAQycnJyGSyn/t2hkWSJNrb26mrqyMlJeWwzvEH8iOktNlEYUMPMpmMEbEG0iIDf+5b8uPHz2FitVp/0UEcQCaTERYWRmtr62Gf4w/kR8De+i4uWLoJk80JQHCAijevmUhujPFnvrMfh83pos/mJCRA/Yv+w/bj51hyPPytH+k9+gP5EfDe1jpPEAfoMjv4fHfjTxLI6zrNfFfSytrSNqakhTErK4KEUP0xu/7uui6eXFXGvoYeFufHcv6EBJLCjt31/fjx8/+HX7VymEiSRGlLr894eWvfMX8tk9XB3z4r5L6P9vLF3ib++Mk+7vlgD11m+zG5fkVrLxc/v4mvCpup77Lw9JpyHl6xH4vddUyu78ePn0OzYsUKsrKySE9P56GHHjrq6/kD+WEik8k4b3yCz/jpo2OP+WtVtvXxVWGz5+cYo5aCxBA2V3ZQ0dqL2310zUDKW3rpsTq9xr7Y20Rdl/moruvHj58fxuVycdNNN/HFF19QWFjIW2+9RWFh4VFd059aOQKmZYRz3yk5PLmqFLlcxu0nZTA5NeyYv87QQB1r1HLxpCSeWFWK1eFGq5Lz2HmjWTgi+kfn+jQqhe+YUo5a4Z/X/fgZysc76vnnl8U0dFmIDdZx14IsziiIO6prbt68mfT0dFJTUwE4//zz+eSTT8jNzf3R1/QH8iMgTK/h2hmpLM6PRSaTiDLofpLXSQnXMyk1lI0VHSwZG+8J4gBWh5vfvrOLrFuDSI34cYqZ7OggChKD2VHT5Rm7fW4mCSEBx+L2/fg5Ifh4Rz33frgHi0OkHOu7LNz74R6Aowrm9fX1JCQMPt3Hx8ezadOmo7pXfyD/EUQbtT/p9Y0Bah4+K49luxtRymWeID6AxeGixWT70YE80qDliQsK2FbVSWVbLwWJIRQkBiOX//J38/34+f/in18We4L4ABaHi39+WXzUq/JjjT+Q/0JJCtNz0+x0yptNPLayxCuY61QKIoM0R3X9hJCAE34FLkkSTT1WVHI54Uf5efn59dHQZTmi8cMlLi6O2tpaz891dXXExR3dxOBPiv7CSYkI5NFzR6NVia9Kq5Lz73PzSQk/tlLBhi4Lq/Y3s2JvIxWtvuqc443mbgv/+aaU+Y9+x6In1/HJznrMducPn+jHTz+xwcOnTg82friMHz+e0tJSKisrsdvtvP322yxevPiorulfkf/CkctlLBwRTfat02nusRKoVdLea+OTnQ1kRgWSE2M46gKH6vY+rn11K8XNIoAHaZS8cc1E8uKDj8E7+Hn4bHcjj68sBcBkc3Lb2zt54+qJTE0P/5nvzM/xwl0Lsrxy5CCehu9akHVU11UqlTz55JMsWLAAl8vFlVdeyYgRI47umkd1tp//F+RyGakRgSgVcq59dQv7m0TAVSvkvHbVBCYeoXKmrtPM7rou2nvt5MYaKGk2eYI4iMD37JpyHjtvNGqlr8Lll063xc6bm2p8xjeUt/sDuZ/DZiAPfqxVKwCnnHIKp5xyylFfZwB/ID+O2FHT6QniAHaXm39+VcwrV0xArzm8r7Kh08J1r25jX2MPIDTqC0dG+xxX1GjC6nAfl4Fcq1SQEBpARZt3sVbMT7xJ7efE44yCuF/cxuZw+HPkxxEtJl/rzeo28xHlfvc2dHuCOEBTj5Uog4ZxSSEsHBlNqF4NwJIxcRh0h2eh+UtDo1Jw85x0L118jFHLpJ9A8+/Hzy8B/4r8OGJUXLDP2Nnj4gkPHF6R4XC6qWjrxWR1khgaQKRBi/mAMvwwvZpwvYYgrYryll7OGhNPQoiOOTmRP8Vb+H9jXFIIH900heImE2qFnJFxRpKP8QaxHz+/FPyB/GfC7ZYobjZR1tqLQaMkJ8ZApOHQj/758UYeOy+ffywrotvi4LzxCVw4IXHYzc5eq4NXN1Tz769LcLkl4oJ1PHvJWNIjA1HKZTj7q0cvnZzM7z/ei80p5I2lLb3celI6cUe5M/9jsDlcqJXyY+JOJ2yGjYyIPT6dKf34ORKOWSCXyWQKYCtQL0nSacfquicqGyraufylzThcIqBOSQvj0XNHH7LYSKdWcmZBPFPTwrE53UQbtagOUla/r6GHR74s9vxc32XhL5/u48XLx/PqVRN4cHkRNR0W9BqFJ4gP8PzaSi6YkEi0QUtdpwWb001csA6d+qfJl1e39/HZrga+3NfM1PQwzh4TT3pU0E/yWn78nIgcyxX5bUARYDiG1zwh6TLb+fuyQk8QB1hf3s6e+u7Dqhr9oZU7QF2nb9HC1upOuswOpqSF88bVk7A4XGyt6vA5Tq9W4nJLvLahmodX7KfP7uLkkdHcszDbJz3R3mujrKUXCUiLCCTiCAtvTFYHf/xkL9+VtAGwp76brwtbeOuaiYf1Pv348XOMNjtlMlk8cCrw/LG43olOn91FZZuv/W1n3w/b1JrtTvpsTkwWByaL46DHDTchjIozYAwQG5gGnYoog5YRsUZiDgiYv5mXQVWbmT99uo++/pz6F3ubeHVDFa4hhl5VbX1c+cpWzlu6kfOXbuSKlzYfcTFRVVufJ4gPUN7aS1lrL06Xm9JmE5sr26kfZmLy4+d45corryQyMpKRI0cek+sdK9XK48DdgPtgB8hksmtlMtlWmUy29UhaGJ2IRASqOS0vxmc8NeLgm3EWu5OvC5u5YOlGznlmPW9sruavy/bx6c56eq2+AX1krJHrZqR6fg4JUPG300diPECJEqBWcNnUZK6dkcrZY+O5Z2EWa0ta2V3X5XPNT3c10N5n8/z8dWEzu2oHj9vb0MMXexoP9dZ9UMiH/xPUKuW8tbmGU55Yy7nPbmTxk+vYMszTgx8/xyOXX345K1asOGbXO+rUikwmOw1okSRpm0wmm3Ww4yRJWgosBRg3btzRGWof56iVCm6ek0GfzcWXhU0E61T8aVEuI+MOvjG3rbqTa17d6vm5sLGYuxZkccd7u/jfRWOYl+utBTcGqLhtbgaL8mPptjhICgsgfhhvlbpOCw99sZ9AjRKDVsn72+qQy2B2TpTPsemRgby5qYaUcD1T0sJYX9Huc8zasjZumpNx2J9FSries8fG8/62Os/YhORQ3BL88ZN9nrH2Pjt3vLuTD2+YOqxvSqvJyvdl7aza30xefDBzsiN/tKmYHz8edr8L3/wNuuvAGA8n/Qnyzj3qy86YMYOqqqqjv79+jkWOfCqwWCaTnQJoAYNMJntdkqSLj8G1T1hSwvU8dt5oGrst6NQKYoyHVol8sqvBZ2xtaSsFiSG8uanWJ5ADBKiV5EQHoTiEz3iQVolSLqPX5qS3v42dW4KMyEDGJYWwtbqz/1oKFoyI5u/LCnFLcP3MVM4YHcu3+1u8rjd/mPs4FDq1gjvnZzElLYx1pW2MTQphRmYEe+q7fY6t6bDQ1mfzCeQOl5vn11by7HcVAHy6q5G3Ntfw+lUTifkZ1Dd+ThB2vwuf3QqO/rRed634GY5JMD+WHHUglyTpXuBegP4V+Z3+IH546NSKw141GrS+X1WgRklTj5Wk0AB213WhUylIDtejUsjZW9/N21tqKG4ycd74BGZlRg67kk0O13Pngiwe+mK/Z+zq6SlkRQXxv4vHsL/RREuPldpOYUI1kCJ/YV0lH984hZNHRvPF3iYA5uVEMm+E70r+h4g2alkyJp4lY+I9Y+29Np/j4oJ1hPUXLA2ltsPMC+sqvcbKW/sobjb5A7mfH883fxsM4gM4LGL8RAvkfn56Cht7iDHq0CjlHqmgUi5jcloYj6wo5qwx8Sx+8ntUChl/WpTLhORQLnxuo6ed25aqTu6cn8lNs9N9NNoqhZyLJyYxJjGEuk4z0UYtuTEGAjRKAjRKIoO0rCxs5s73d3ud55aEHPJf5+Rz8+x0JCA5LIBA7bGpBs2MDuLeU7J5+Iv9uCVh5PWvc/KICPLdxHVLEm7JN1t3JB3xJEliT303W6s6UchlTEgOJSfWL8D6VdNdd2TjPyPHNJBLkrQaWH0sr+kHtlR28PTqcm6fm0Fbrx2NUk52dBA9Fgd3L8zif6vLAXC4JP748T7+dXaeT0/O/60uZ8mY+GEtOAO1SiakhDIhJRQQlraf767mq8ImJqWGMz0jnGijhqbuwVXyhRMSiA/RoVYqGHGI3P5QGrst1HSYCdKoSI3Qox2m5dwAAWoll09OZkZGBB19duJDdCSFDb8ZnBAawDnj4nlnSx2jE4KJMmip6egjM+rwc+Tbazq5YOkm7C53/+sreOfaSYw6jh0g/RwlxniRThlu/BeGf0X+C2Rgdbi6uBW3JKGUy2nvs/PwimKMOhVyGcSH6Pj3OfnMf3ytz/muYVanCpmMw6mX7Oi1cf/nRXzerz5ZU9LGpzuDePGy8Xy0o4HtNZ2cURDL3OyoIzLU2lPXzdWvbqG5x4ZMBjfMTOPaGakEB/imSgbQqBTkxPzwqlijVHD73Ezm5kTx7pY6Klp7OaMgDvlhVohKksQr66s8QRzAbHfxxd4mfyD/NXPSn7xz5AAqnRg/Si644AJWr15NW1sb8fHx/PWvf+Wqq6760dfzB/JfIHvqujnn2Q2eNMrvFmZ7yuq7LQ60Kjm/nZdFcXMvd87PxOJw8+K6So9vcnpEIGF6Ne1DdOm3z8v4wXyxJElsquzwBPEBippMdFsc/P7UHFwu9yE3T4ej1+rgH58X0txj638d8YQwNT38mNnK9tmc/OadXZ4N239+WUxrj43fn5Zz0OrXAdxuiRaTb06+pcfXpMzPr4iBPPhPoFp56623jvoaQ/EH8l8gXxY2eZXNv7qhigeWjGLV/mZaTTZunZPBb9/d5QnUIQEqbj0pnX99VcIfTs0hN87Am9dMZMXeJspaezllZAyT037Y+a+2w0xpi2nY3zlcErUdZkID1OiPMJB3WRzDasB/qGVWW6+VzZWdrClpJS/OyPSMCBLDhm9PV9zU6wniA7y+qZorpiUfNCUzgEIh55JJSWys8L7HRfmxhzzPz6+AvHN/cRubw+EP5P8POF1u6vqDVnywDuUPBMI+q7dDYUO3lfe31fHqFeORy2X855tSr9V2p9lBq8nGV7dPJzFUj0opJyvaQFb04W3WSZJEdbuZFpOVTZUdzMmOZNUQWWFmVCDbqzu59MXNTEkL44+n5ZITY6CyrY99Dd24XBLZMQayoof3RwkOUDEuKZTNBwTzg7XMMtud7KjpYmVRMxqlnCiDhr9+VkhOTBAvXDZ+WPWNWumbRtGqFNgOaJ57MKZlhPPvc/J56tsyVEoZt52Uybjk0MM614+fn5vjPpB3WxyUtfRic7hIidD/oB77/5sWk5WXvq/khbVVAFw1PYUrpiYTOYz6YoAFI6N4eUOV19iVU5PRqsXXtb/Rd9Vc0txLWuSRG005XG6W72nk3g/3UJAYjEYh5+SR0UxICWVNSSs50UHEh+hwS5AVFcT68nZueWs7T144houf30Rbr5hQAtQK3rp2EvnD5JQDNSr+uCiHq1/Z6smRXz8zjZEHcSb8pqiZW97a6fk52qDl8fNH89S3ZZS0mIYN5DkxBsYkBlPfZfGkcC6cmMjWmk4yD2NCM+rUnDU2nrk5kchksuPWi93PDyNJ0jFx2PwpkYbZ5zoUx3Ugb+q28JdPC1mxT+iY44K1PH/Z+MPaIDsURQ09fFnYRF2nhVNGRTMhOfRHy+q+K2nj6dUVnp+fXl1OekQgZ42Np7HbQn2nBWOAipQwvWelPiYxhFevHM8zqyswO5xcOz2NaUNyyYtHx/LNAYU4S8YMdjFp7Lawr6GHbrOD9MhAcmMNB80T17SbeWB5EWa7i+/L2nnywgL+s7KU00fHYnO4+Wx3I639+ePfnZzNQ1/sp6ylj+JGE229dlQKGeOSQrE53by2voqRZ+ejkPv+RzIqLpiPb5pKTbuZQK2StAg9WpXvn197r40Hl+/3GmvqsVLabGL+iGjcw2gKJUmivdfGhBRxHyNiDfTZnKza38rq4hZOz49Frzm87894iM1XP8c/Wq2W9vZ2wsLCfrHBXJIk2tvb0WoP3zTuuA7k26q7PEEcoL7LytI15Tx8dt6PblFW2mzi/Oc20t1vSPX+tjoePTffq1jlSPh0Z73P2Bd7G0iJ0HP9a9toMdlQK+T84bQczhkbj06tRKNSMCMzkkmpYbglfGR609LDuWtBFk99W4YkwQ2z0piREQGIIH7Lm9vZWt0FgFwGz106jpMOKLnvsznZWt3B8t1NzMuNJsao5d2ttWyq6CAlXM/nexopOmDlX9nWR5RBQ5fZgcPtZnxyCHOyI1ld3IpRp2RaRgRWh/OgQTPGqPN5YpIkkXu3uyTijMI298BcN4DTLfHaxiqmZ4z3+d3O2i7Oe3ajR3WikMu49+Rs1pS0sjg/Fs1x2K7Oz09DfHw8dXV1/NL9nrRaLfHxhx9zjutAXtLsm2LYVNmByeokLPDg//G63BK76rpYV9qGWiFnWkYYI/u77+yu6/YE8QH+/VUJszIjCD1IJ55DkZ8QzHel3u5+p4yK5a73dnmUEnaXmz99so+8uGBGJwZ7jjtwMrI7XThcbsICNdw4K42TciKo77TyXXErXxc1MyMjgsLGbk8QB1EU85fP9lGQEOx1/6v2e6cvDDol9y7M5svCZhwuN4HD9AANUCuwOtzcvSCLlLAAziyI476P9np+v6aklRcuG8+srAiq28009VgID9SSEq4fdpXeY7Hz7tY6/v1VCVani4eXjOLp1eUsHh3H6xurBz8HhRyNUkGX2YHF7mJHTSdhejWJ/ZuYn+xs8JIOutxCfTM+OYSrp6egVMi9Gk5nxxgYFWc8pI7dz4mJSqUiJSXl576NY85xHchHDFN5d1JOpI/D34Fsrergwuc3eSxZtd/Iefe6yeTFB3vZtA5gd7mH1WYfDovyYnl3ay3NPTa0Kjk3z04nWKeivNXXxra+y+wVyAeQJIltNZ08u7qcmg4LF09KYkZmOH9fVsT3ZYPGVQtGRHHuuASf8xu7rB5pIgg/9H9/VeJ1TI/FSbPJRn68kZe+r+J3J2ezrbrTUx1p0CqZlh7OwpHRhAdqWLO/hWUHyBTdEqzY24RMBje+sR2z3YVGKeehs0axKC/WZ5N3R003//i8CBCVm/ubTFS2mxmX7OI3czP4eGcDUQYNC0ZE8+yaCqakhbFsVwMpEYE89W0p/zonn5OyozAN4/5od7p59Nx8EkL1NHRZuP71beytH+xV+t8LCvyqFD8nDMd1IB+TGMKVU5N5aX0VkiRaoV02JfmQqhCnS2iuhwZsq8PNV/uEa97IOCNalRyrY3CFd/Ps9GFLww+HzOgg3rt+CvsbewhQK7j9nZ3MyY4iPkTn0/wh6iBNJfbW93DRc5s8ksQ/frKX2+dmkBASwOxsOevL2gAZRp0apVzGNdNT+HhHA639fiVnFsR5Gj7sb+qhscuC3enrOGzUKslPCEEpl7Onrpt/nZNPp9lOr9XJzMwIRieG4HS5+ceyIoqbTcPm3fUaBX/7rNDTG9TmdHP3+7sZEWMk8wBVy64hVrkSeHKW722rIzfGwN0LslhZ1MyDy4uYnhlBfnwwj35dwoSUUEYnhHDzmztYfut0ziyI44Pt3imsyyYnkRAqVuz7Grq9gjjA3z4rZGJKqL95hZ8TguM6kIcHabh7YTbnjEvA5nSRFKbHoFWxq7aLnbVdaFVyxiaFkD5EzSEh5HoH0mUW6ovcWANvXTOJVzdUU9Nh5uKJiczMijiq+0wMDSAxNIDHvi6hrdfOZ7sauGtBFo99XYLJ5kQmg9/OzSR7GHWFyeJgc2W7Tzu2D7fXc8/CLCra+pieHkFSWACPfl3Cu1trMepU3DQ7jbc31zA2KZSbZqejVirYU9/F+c9uRKtScO64BJ5eU06AWsFZY+IJ0asYGWfkgc8L2VrTBcBbW2q5Z2GWJ7ACtJhsvLO1FrvLze9OzmZT5aCkUKOUU5AYwovfV3ndq8Ml0dRjJTZEx46aTr4vayMuREd+vBGVQobDJdFrcxKmV3sm0cLGHm5/ZydPnF9AZJCWTZXtPPq1eIrYXNnBzXPSWVPSSkO3hXHJIbx0+XieWVOO0y1x3YxUJqYO6ub7bL4SxA6z3ecz9ePneOW4DuQgNgKHqlQ2VrRz8fObPM2FQwJUvH3tJI+mWqWQc/nUJB9N8ymjBhs9FCSGkB8fjFNyo1Ycfh61vc/GutI23t9WR1ZUEGeOifNq/lvan9O3OFz8d1UpF09KIiRABNDUCP2week9Dd2Yhtn8u2paMne9v9uz8g3SKLlpTrpQq1gcPLyimPeun8zIWIMn1/7xjnr67C767C7KW3v57bxMogxaHvu6hKYeK8+uqeCaGalYnG72NYgV7IvfV7EgNwpzf2pGq1IQG6ylvLWP97bW8vtTc9hT102oXk2MUYtWKSNIo/S6Z5VCRrRBwwfb6vjzp4Me4/HBWu5akMUD/SqV97bW8u61k2jssVLfaSU8SENwgIpnvyv3MsBKi9BT12FBIZcREaRBp1IyOzuSKWlhSBJYnS6auq0EB6gIC9SQERXomTAGOHtsHNH+1bifE4Rj1SHoF4Hd6eLp1WWeIA5i9b3ugM3GaekRPHH+aHJjhfb4xcvGMSYpxOsYuVx2REEc4P2tddz29k7Wlrbx/LpKLnxuE+Utg63PTssfnCw6zQ6eXlNOj83J1a9u5aEv9nueCoZS22HG4ZK8emGmRQSyr8HkCeIAJpuT8tZe4kOEKsTllug222nstvJ9WRtFjT1eK9CvCpup7zKzdE05Tf2l6DanmydXlbFw5KCneJ/NiV6jJCsqkI0V7Xy4vY6rp6dy1bQUSlt6uf/zIvrsDhaOjGJsUghT0iJ47PzRBPQ3atYo5Tx5YQGlLSae+KbU673VdVmJNmh55YoJvHrFeO45OZtnv6tgZWELDpebP32ylz99spcHl4zynKNVybloYhJfFTbxjzNGkDbEBlijUlDcbOKC5zZy0qNrWPL0ejZWtJMTbeCVKyeQF2fEqFNx1bRkbpqdgUp5Qv35+/kVc9yvyIficLm9HPoGaDvA29qgU7F4dBwn5UQhkwmnvaOlscvCf1eVeY11WxwUNvaQFimCTUq4nlvmpPPy91W4JIlzxiVQ027GbHfx8c4GLpqUxPgDqgmjjVr+9Mk+bpyVhsnmpMvsYE52BG9sqvF9nyY7wQEq6jot6NUKJAlOe2IdJpsTuQxunZPB6IRgdva3Z4sI0lI+TO/QofsDF05MZHF+NLvrerj7g0Er25zoIF64dBx2l5tRcUbihnQfOik7kuW3TveoVtQKGVurO+iz+z5ZuCSYmRXBpzvrufXtnZ5xnUrBjbPT+PdXJXSZHTx5QQE9VgdRBi0GrZKPb5xKcniAV56+ucfKDa9vo6FbTEzV7WaufmUry26Z1t9weiJ9DicRgdphVTR+/ByvnFCBXK9RcdmUJC9JHMCMzOFz3PphUhlHw3ChYWCspcfK9a9tw+GSeHDJSHbX97BibxM1HWbPsb1W30A3MtbIGaPjeGxlKQatkhijjlNHRTMxJcxLsQIwLimEx1aKPPL9Z47iDx/v9aQ43BI8/k0pT5w/modXFCNJEukRemKNWk/gGyDKoCEtIpDT82PIig6ipLkPk9VBVJCG5n7JZFGTCbcEC0d69x612F302hzEh+hIDhebjRWtJtaWtnFmQRxvbR60BR2w4+022/nPAat1i8NFr9WJViWnpNnEl/ua2N6fuw9QK3jzmkk+8sz6TovPe+m1OantNJMcridIpyLIX7Hp5wTkhArkAPNHRGN3uln6XQV6rZI752VRMIyk71gTE6zj1pMyuH95kWcsOEDlyd9XtPVR3SFUKl8VtlDe2usVxE8eGY1cBp/taiA5LICs6CDUSgVhgRr+cFoO501IoKvPTmlLL4+sKOaaGancOT+L1zZWIZfJuPWkDEYnGMmMDiQ8UINSIfcJagBlrb1MSQsjOECJxe7ij6flcsd7uzDbXchkcNGEREqaTFw8KRG7083W6k4koKixhwsnJWKxuXh2bQUXTUyi2+Lgk531ZEQGkhiio7bTwpeFTbyxsZaFI6O4YmoKqRGBtPc5+GhHA+eOS+Dq6Sl8u7+V2GAt10xPJS5YS1lL37CyTwmQISMvPphPdg62ujPbXbz0fSX/PiffS6Fk1KlQK+RemnKAYH/w9nOCc8IF8vBADZdPTWFxfiwKhZDkHUvcbonq9j66rU5ijVov+dpZY+OINmr5eEc9GVGBLM6P9aRV1EMCzud7GrlrfhbhgRo2VrRz/vgE7C43l720BQCZDB47dzRnFMRR2dZHUWMPMsRK+bGVJVgdbn777i7SI/QsHBnN4rxYksP0ONwS2dEGZDIZbSYbCaE6aju8JY55cUaCtEpCdGru+2gvQVolV0xNIcaoJdqgYfmeRkpb+hiXHMoXexvptjg8roDfl7UzLimYB88cxcvrqzxFO2qFnIfPGsX/VpeTF2/kr6eP4Na3dlDVZubpS8bg6A+s726tJUyvZkJKKG29NsL0Kp5bW8kr66u4YmqK16pco5QTrFNx3cxUwgPVXD8rDbVCzteFzeyp76a8tRenW2Loojw5XM8fTsvhT0OaNt8yO530yME8us3poqbDjBwZiaEB/jy5nxMC2ZGasxwLxo0bJ23duvWHD/yFYXO4+HRXA3/8ZC9Wh5tYo5b/XTyG0QkhP3huj8XB3e/v9rIUuHtBJqfmxdLYbeH8pZu8jjdolbx21USueHkLHf1Oh2F6Nb8/NYe3t9SyuV/2Nz45hCVj4vnPytJ+X5ZUzh2XQKRBy5bKDq59bSudZgcqhYy7F2azvqyV00fHU9Xeh83h5v3tdbSahJHVUxcWsKGsndouC7OzIuk023l8pXfKA+CZi8cSpFWwr6GHFpONtzfXkhKuJ9qo5evCZhJDA7hwQgIPrSjmi9umExKg4pxnNlA7RDc/JjGYvywewRlPfY9bgukZ4UxMCWN9eRsxRi1nj40nyqDh+/IO/vzJXo9q5erpKawva+e88QlcNiXZ594sdif7m0zUdlqINmjJiQ7ypFMauiz8Z2UJ726rQyGTcdmUJK6bmXZIA7P/D+wusWl9pJvrfn59yGSybZIkjTtw/IRbkf+UlDSbuGtI78qGbit3vreLd6+bTFO3lS1VndicLiamhDEqzoh8yIaaQafiz4tzOTUvhsKGbvLigxmbHIJepWTvMB3je6xChdIxxK62vc/O7rpu5uZEsnBENI+vLGFJQRz3frjHc8y/virBqFNzyeQkxqeE8tkt02josqBTKXhmdRkTUsK476M9mO0u9GoFt83N4Pm1lbSYbHT2OQgP0rClupOeYaolB9jf1MNHO+q5bHIyn+5s4I75mTz1bRn58UJqWdNhJlSvRqOUo1HKiTbqeP6y8by4roINFR3MzYniokmJdPTaPQF6bWkbmyo6yIs3cunkZPQaBS09dh74vMhLevjiukoeO280Yw6SLtOplRQkhlCQ6Du57qrtJMKgZX5uNN8UNfPCuipGxQVzRkHcMFf66bE5XGyq7GDp2grcbjdXTUtlclrYMdl89/Prwv8XcwTUdvo2Qihr6aOspZcrXtpCX78cUKWQ8ebVkxif4q1AiTHqWJSv85SG76jp5MHl+5mWEe6jc86JCaKu08yBlLX0EqBWUNps4qXLx7N8b6PPMW9sqmbJGOH4Fx8SQHxIAOUtvSRHBPGfb0o9qpQ+u4vHV5Zy98Is/rGsiLZeG//5ppSrpqXS1G0hO8rA+OQQtlR1eq6dF2+kqs1MdbuZd7bUMjEllHe21HL9zDSvjUy5XMZtJ2V4mjpkRQfxjzNHYbY5CdKqkMtlBGqsXputdpeb6g4zbkliydPruWpaipe1AIhNW6VcRmlzL1qV4gcrbpt6rBQ19CAh8cyaCnbVdTMi1sDvT83hn18Ws7Kw+WcL5Nv6Pd4HWF/ewUuXj2d2duTPcj9+jl+Om0Be12lmX30PZoeLrKhAcmIM/+82lFHDFJBEG7TUd1o8QRxEJeOL31dSkBiMUiGnttPM6v0trClpZXpGBHOyI3FLEpe9tJkei1BV3L0wmxfXVdLYbSU/wcgfT81lXZmvQ9uYpGC2V3dy1tgESlt6CR/GyCsxNMCnfD48SE2QVuklLQSxcRioUXLH/Eze2lyLW4Ln1lbwh1NzcEkSN85MZ2daF5sq28mONqBVyXlmjbDlLW42MW9EFJ/tbiTKoKW8VWjmZ2SEkxquZ25OlJfMT6WQe9nERhm0/PfCAh7+ophtNZ3kxxu5eU46y3c30mMRUsvwQLXH8xyEjryp28rfPy9icX4sfz99JMaA4TczW3qs/PadnWRFB7FsiB2vSAmVc974BGJ/Rv/6D7b7dmN/bWM1s7IifrEWq35+mRwXgby6vY+rX9lKaX9xjVoh59WrJjAp9Yfblx1LsqKCuPWkdJ74RujFtSo5N85OY315m8+xLSYrbkmix+LgTx/v5dtiEZRXFrXwVWETN8xMo8cipIGN3VaeWFnKovxYJqeFYXUI3XdZSx/Xz0zl5fVVyJBxzrh4zDYXaZFB/OadnQD8Zm4GEUEaT5DSKOVcNzPVR5pn1KmZkByKRin3KgzSquT0Wp3srOnylkLanARqlKzc34xOJeem2en85p2dXkE1xqilo9dOXn+p/YUTEsmICiQ/3siYpMGnkaq2PvbUdyNJEmmRgZQ3myhsNJEdHcTW6k4CNAqunZ5KSYuJm97Yzn2n5gCiwOqRs/P462eFNPVYCdWruWFmGur+Dcq1pa00dpvRqQPZU99DSXMPRp2aUfFGEkICKGzsYX15O2OTQjyfzwCtJhsRgRpOyhlc/UqSRFuvHbVCRne/9PGnzJ8PFE0NRa9W+IO4nyPmuAjk22u6PEEcxCP4v78q4eUrxh+VFtztlqju6KPX6iQ2WEfYD9jUBqgVnD46lvFJIXRbnVS09rL0uwruWpBFR38F6UCQvGxyMgq5nJ21HZ4gPsD3Ze2cPdbbpdBkc/L+tjpC9Gqq2vqYkRnB92VtnDsunltmp9NtdbJibxNnFsTx5LeDhUf/W13OVdNSSI3QI0NGToyB3GFcIUFY6t53cg73Ly/C7nKjUcq5ZU4GRY09nlZ0IDzMc2IMRASpeWtzLU63m7TIIE4dFcMrG4RSRaOUc9W0FN7cVM2V01J5+Iv9XDAhkW6LA5dbwuZwoVEp2FPXxTWvbqOpx4pcBnfMz6Kzz87mqg4kxN7B6k01bKvqZFF+LFdNTyVcr0Epl5EQGsDyPY2cPDKa3Fghxyxr6UUmU/G/i8ZQ3GTigeX7OSUvhns/3MPAvn1ujIGnLizwBG+FXIZMBkP39WUymJQaRmp/ZWhDl4X3ttYiAaXNvazY10RogJo/L85lXk4UmkNY3rrcErvruli1vwWZDOZkR5IXF+y1R3IgbSYb545L4IPt9Z4KXbkMLp6cdNBz/Pg5GMdFIG81+eqhazr6sNhdPzqQWxxOPt7ewF+X7cPqcJMSHsB/LxjDyLjh2485XG6W7Wrgdx/uweZ0Y9Sp+ONpOVw8MYnn1lYgA+5akMX26k5mZ0cyIzOCbdUdbKvpHPZ6JquD2VmRfFs82OnnokmJrNjbxF0Lsogy6Hju0nE8+nUJi/Jj2VjZQXOPlUCN0ktzbXO6+d/qct66ZtIPNlhWyGWMSw7hptlpONwSMuCdLTX88bRcvi4S96FRyrnvlBze3lzNlLQI/nvBaHbUdtHZZ+ek7EgWjIymx+IgKkiL5JYYEWvgy71N3D4vkz98JAqQnvimlLsWZHHp5GRW7GvyWACcMy6Bj3bUU9Y/Ke+u62ZsUgjnjktgVJyB4iYT+xt7WFvaytJLx7K1qoMwvdDE76rrJtqgo6zVxLT0CFYWNvPhjnrOGRfPk6vKvIJ0YWMPq4pbCNIoUcplfFPUwgXjE3lz82A17C2z0z0Tntst8frGar4paiErOojP++15W3tt3PzmDt6/fvIh+3fuqOnk/KUbPdYQT68u551rJ/vYPgA0dVv5YHstL6+vJiJIw6Pn5lPdZqatz8aCEdGMTgg+5Hfox89wHBeBPG+YPpDnjUsgLPDHa8SLG03c+9Gg2qOyzcwfP97LK1dO8PRrrG7vo7bDTIhejVIm4873d3uCaK/NSWefg4dWDLYl21Pfw3OXjmNebhRut8TL31chk8kYkxjsqUoEGJ0QTJBWyeysCOblRNLdrxDZWdvFuePiyY8XASZQq2RMYjCripq5ckoyf12ci1Iu57m1FZ6mFCA82C0OJ099W0ZcsI6xScEeC1cAq8NFSZOJ+i4L8SE6ZmVHsqWyg/ZeOxdOSOKTHfX8/fQRmO0uQgJUbCxv59viNqIMOs6fkECoXo1Rp0I3RE1R0mziq31N1HZaGJsYwsc76r2qSB9eUcz83Civ5h/RBq0niA+wrbqTm2alsq26i+/L29FrFCzOj+O1jdWckR/Lqxuq2Tbks7t8SjIvrqtk8WixQRkaoPZJm4AoJFq2u4F7T8nmzU011HX28cCZI1HIZCSGBTAi1uBpLNFssvLqhmrOGRfPe1t989ZFjT2HDORvbq7x8vdxuCQ+2F43bCB/f1st/+r3gm812bjhje28f/0Uxg5zrB8/h8txEcjz44385/zR/OPzIrrNDi6cmMh54xOOKpdY3eGrCNlR20Vbrw2DTgSza17d6rGZvWV2OgUJwWytFivskbEGvh8mN/7h9jrm5UYhSRJdFgfry9u5bkYqefHB7GvoJjfGgF6j5Dfv7CItIpA752fyv9VlzM2NJjJIy/NrK4kI0jA2SfJqbvx1UQt3L8zihplpPH/ZOP74yV521XYzMyOc6enhXPnyoC5/RKyBFy4bR7RRR4/Zzkc7G7xcB+89JZvLJyezuaqDS14Qqolle4S+/c75Wby6UaxcJ6eFceVLW5iWGU6wTrgb5sUH02tzcMHSjbT3SyPf2VLLQ0tG0dRtpardzLzcKHRqBW29NqakhfN1oVjtD/d1GbRKajosPLW63DO2r6GHexZmo1MrvYI4wFuba3jorFHIZUIV09RtZeHIaK/KT4VchlwG35W2s6myk5NHxhBj1DIuKWTYRswapZzgABUtPTbignUUH9B5Sik/dNGQyeIr1RxurNVk9aSmBpAk2FPf7Q/kfo6K4yKQ69RKTh8dx+S0MOxON9EG7SGbRxwOkcN0Yk8KC8CoU9FqsnHn+7s8K0xJgidWlXHn/ExPIDfbXSSE+H58oXrxlKBQyLl0cjLry9t59rsKFuUJ35Lle5s8K8jy1l7quyw09dh4eX2V5xrPrCnnL4tGeG0sAjy5qozT82PJiw/m1Ssn0tVnxy1JnP7U917H7WvoYWtVJ9FGC3vqu32aGT/8xX5mZEQQolPxt8UjsDnd2F1u0iMDWb67AY1Szp3zMylp6uGq6Sk8vaaMXbXC1nZUnIELJyR6gvgAz62t4O4F2bSarLy0vgqT1UliaABTUkO5Ymoyb2+upbqtz0fOeP3MNB8DMEkSWvTU8AAOxOZ0Y7I6ae6x8dS3ZczMjGBRfgxapZwv9jYRF6zj5jkZPNz/pGRzuvm4v29qbmzQsIE8VK/hvlOyuf3tXdxzchYPLt/vWWHnxhjotvq6Ug7lwolJntTUAEvGxrOrtgsJSAkPwKhTI5fLCBvmCSLA33LOz1FyXATyAY6lgiA3xsgVU5N5qb8Jgk6l4KElowgL1FDSbPLp3gMQHCA68DjdEnWdFu47JYcvC5s8+m+1Qs7ZQ5o0T04L5fHz8nlubSVpEXre3lLn8x9xl9lBgFpBzxDDLINWyXD1tm5J8owbdSqMOhWVbX3DNitu77Nz30d7uHRKspf3yJS0MMYnh4p8u1qJ3eXmn18WY+/v0/nQWaO47aRMqtr7eHpNOe9srWN6RgTT0iN56tsyipt6h23M0Wtzsr2mk/Y+u6eN3T+/LOZ3C7OYlxPB1PRw1Ao5NoeLWVm97KrtIj0ykMzoQIKHkQ9GBmmoabdg1Km8eqjOyAjnq33NRPYbe60paaUgMZjcWAM6tZKFI6IICVBj7ndaVMplXDktBb1aQafZwZ76bkbEGHw2IkfFGbl7YRYul5vHzsun1WSn1+akpceK6wf6T0xICeW5S8fy7JoKZDK4aloqq/a38Gr/6ntaehj3nzkKt1virHHxPLC8yJPTjzVqiQ32+6L7OTqOq0B+LDEGqLhjXhaL8mPpNjtICgvwKBjC9GrSIvQ+fTVHxBr4/NbptJmsxATrSAoN4IPrp7C2tA1kort9XryRLrOd3XVdfF/Wzr76bi6amEi0QUuQTs3flxV6XbMgMZiX13vf281zMogxagkJUHkFzetmpGHUen9lscFaloyJ5/1tg7ldnUpBQqiOHqsTi91FmF5Ne5+diycl0dht8XiaLMqLwaBTeQJ9r83JHz/ey5MXjuHmt3Z41BQf7ahnVmYEk9PC2FDeTqRB65nQBliUH8tnuxs4Pd+7uOa9bfVkRRuoae9DJpPhdksEqOVEBKl56fsqIoIyOW9cgnd/UJ0Sg1bFo1+XcOf8TNaWtlLc3Mvk1DAigjT8b3U5kUEaZmZFUN7ay4bydmQy2FjRwbjkEEYnhnDXgizu+2gv10xP5bPdDZ6JWaWQ8dqVE5l0wMZwtEFHeWsf4YEqlq2tZHedqLYdFWfgqumpw/0JedBrlMzLjWZ6RgQy4L1ttZ4gDrCurJ2v9jUzf0QUH2yt5Z4F2XSY7WhVcpwuydO0w4+fH8tRe63IZLIE4FUgCmFYt1SSpP8c6pzjwWtle3Un172+jVaTDbVCzh9Oy+GcsfFeG34H49X1lXRanDR0WbDYXXy+pxEZcOGERNIiA/n7skICtUqunZ5KUWMP80dEUd1uxmR1Mic7ktEJwWhUCgobuvlwez37GrqZkh5OabNIxfxlUS6jhmwA13aYeXl9JZ/vbiIxLICTR0bjcEk8sLyIII2S387P5N2ttUzPiGDpdxVe9/qbeZmoFXLMdidKuYw3NtVw85x0L+MpEPntm2en899VZfzptBziQnS8tqGa5h4bF05MJD1Cj9PtZk1JKy+vH0yVTEoJZU52JGa7C4dbYldtF9+Xt/HbuZnkxRn5fG8T5S0mzhobT0OXFZ1ajssNz64pp8/uQiGX8Y/TR7C5qpMdNZ1UtYu9jXk5kUxJD8NkFa6NOpWClYVN/P2MUaRFBPLKhioiAjV0Wx2099r5ZGe9Z2KekBLKS5ePx+l2U9XWh1wuJzVMT3ufjefXVWJ3usmLNxIZpCUv3oDdJbG/yYRcBplRQcSH+KZ8hnLFy1v4dr93qmVSaihvXD2Jx1eW8N9VZWiUcpxuiYQQHbfNzWBxfpzfI93PD/JTeq04gTskSdouk8mCgG0ymexrSZIKf+jEXzJjkkL49Kap1HdZMAaoSAnTH1Zevqnbyvvb6j12svsbe7h9bgY2p9BtRxs0fHLTFD7a0cCL31eKHp67G7lkYiJ/WJSLZkghT06MgUX5EpEGjadZstPl5q73d/HSFROI6a9KDNWr6OqzMz0jnMZuK39bVsjsrEjOLIglVK+hy2znrvlZfFvcym/mZuB0S/TZnLy9pZatVR2YrE721Hdz2eQkfndyNsPldQJUChwuN1dOTcbplnhjUw0ut/B6D1AruPejvXSbHSwZE8eTFxTw23d3ifz96DgCtUoeX1lKeWsvk9PC+N3CbP67qozb56bz7lZR1r+tpovksAAunZxEVbvZUynrcksoFTJq2vto67Vz14JMQvt15gBmu5vn11bQaXbwwJkjyYgKwupw0Wdz8tfPxJ+gXAa3zc3knc01NHRbqesw09Rl4Q+f7GNDhfB0P2VUDL8/JYc/nprD5qpO/rOylMr2Pv6yKJe/LyukqUekxOKDtbx0xQQyooIO/Ig8TE8P9wnkMzMjUchljE4I5jfzMilpMhEbrEOtlPP7j/YyITnUqzmHHz9HwlEHckmSGoHG/v9vkslkRUAccFwHchAe4zHBR1bCLaoDbZwdH8/Wqg4mp4Xx7365GcDFExM5PT+O59dVep33VWEzp4+Jo6HTQoBaSW6sgfLWXq56easn9bFwRBQzsyLotjip6zB7AnmPxYHVKfH5nsH0ytbqDu4/YxR/+mQvnWYHZ4+NR6OU81i/m2FEoIa7FmRR3W5m2e4Gbp6dzsc763nx+yrOGRdPXpyR3UPMvG49KQO3281Xhc2clBPFdyVCsbN4dCz3fDAo43xlQzVyuYynLy6gotVMt9XBXz7b5ymU2lDejsnqYEZmON0W79x+VbuZUL2oUv3DqTl0mh1EGTRkRgXx2HkFVLb3cstbOzwVsfnxRsYkhnDdzDQe+mI/j3xZzKysSDr67Pz768HP3C2JFf5lk5N5ek05F05MZG1ZmyeIAyzf08jMzAjy4o1c+fIWbE438SE6vitt8wRxEO3pvtjbeMhAflJOJF/ta2Jjv0PlmMRgTu5vn2d3uvnvN6UkhgawtrSVHqtoOn2gpYIfP0fCMc2Ry2SyZKAA2DTM764FrgVITEw8li/7iyLaqOXSyclYHS5mZEbw+wO6Fb2+qYZ5uVFeYwq5jBtnp3HRc5s8AS8nJogFudFeG5Ur9jUzPzeaB1fsZ1NFO69eOYFIgxadWsm0jHC+KmxCAm6alcbohGDufG+3J8eeFBbgNaG09tr4dGcD501I4PM9Mjr67FT3py3e21rHJZOSOHNMHC0mG2kResL1Guq7LVw9PZVlu0XBjEGnpG4YGedX+5qZlRXBh9vrmJsb5dOtfm99D2eNiWd9mbd8My0iEKVChs3pptVkIzs6iORwPZlRQVS3m3llfZUniAPsqutmVlYk1e19xBq1NPZYaTFZaeq2cmDG0Gx3oVbKuHFWGmeMjuWmN3f43Pf3Za3oVIMWBjFGLdXtvq3wdtX6ulUOJSlMz9OXjKWitRdJgtSIQI+aaUSskdhgLRVDWuzde3K2l6+9Hz9HyjEL5DKZLBD4ALhdkqSeA38vSdJSYCmIHPmxet3/D2xOFzX9QS4xNOCQ5doymYyzx8XzXXErgVqFTxADcLolRsUZ2dO/4p2REcFnuxq9ji1qNDE/NxqFXOZVyVnV0cdVU1N4dUMVpS29RBq0BAeoyY4O4vlLx9Fnd1HbaabP5vKSCA53H7vqupiUGkZcsI7KA3p3vraxmslpoSSFBhAYb+Sz3Q2olXJSwvWMijXwxd4mrHa3lwnWAJFBGlp7bJw1Nt6rQfQAerWCpLAAypq1GHUqFufHEqJXMSE5hC1VXQRpVWyr7uS1jdW8e91kvtzXzLqyNgobTD7Xau+14XS5CdAoWZAbxfI9TWj77XOHvueIIA2L8mNJDQ9ELpcxIzOCXXXeAXlCShi6If4nRY0mLp2c5GmsMcDJo6LZVNHOir1NBGqVzMuN8ilaCwlQMzYplM4+m6exBkBiWAAvXzGBjRXtNHZbmZgSOqzlrh8/R8IxCeQymUyFCOJvSJL04bG45i+Fpm4rT6wq5e3NNUjAuWPjuW1uJrGHSLmEB2pYMjae5m4rccE66of4mARqlKRFBPK/i8awrbqT+i4LE1NCueH17T7XsTldaJRyr2CoVih4bGUJ187wVlIkhAbw50/28nl/Yc9dCzIxaJUeWaNW6Tv5TEwJIzUigI921LFkTDzrDlghz0yPICZExw1vbPescDVKOQ+fnce09HDWlbWhkEF8iM6jClHKZZw3PqHfO72LOdlRnDwymi/2DjbUuGl2OuvLWlk8OoYxSSE89MV+WnttTEwNZXZmJA9/uZ+ZmRGcOy6BVftbeHdrLWqFnCnpYXy4vd7rHqONOjRKGS63WAnvqusi1qjljvlZPLumnPY+OznRQdx7Sg7GfvtcgDML4li1v4V9DT2MTw5hUX4siaE6Yo068uIM7K7vodfmpLXXxkUTE3lnSy0yGVw+JYX4EB3nLd3ouYfn1lbw3tVjGZU0aMBV0mzis10NbKxoZ2SckQnJoUxICSUsUENqRKBHIeXHz7HgqAO5TJRXvgAUSZL06NHf0i+LNSUtvDmkYOWdrXXkxQdz0aQfNjeKMmp5+uIx/O7DPRQ29JAaHsCDS/I8TYkTQsXmltstcfbYeJ5eU+51/ohYI9nRQWyv6cKgU3LVtFSW72n0bJwObWFW2NDjCeIAn+5s5N5TcvjLpyI/vaWqnaumpfDS95W4JaFfPmVUNHKZjLPGxpMarmdJQZyneObkkTFIMlhf1saE5FD21HdjtruwOd1sLG/nnLGiQCvKoOGfZ+d59OxJoXrMdgdvbKohOSyAbouDK6YkMz0jnI4+OzKZjBX7mthd1020MYAHlg82jthU0QGSeEJZXdzKVdMCcbvdOF0SdZ19nDwqhukZ4awtbUOjlHPp5CTSIvTIZGB1uOmyOJiQHEqARsGjX5fwzMUFtJjs7KvvYV1ZG5VtvZyUHUV8qJCavnLlBKrbzHy0s86j0okP1vHPc/Jo6LLS1msjLz6YkbEGrpqWgkwmIypIzZWveCuurA43a3aXMyqgCyIy6eyzc++Hu9lW3QXAlqpOdtV2oVHKmZ0d6Xc39HPMORYr8qnAJcAemUy2s3/sPkmSlh+Dax8z6jst7G/qoaHLQkywjrw442HlJVfsa/YZW7a74bACucnioKTJRF6ckfm5UaRH6EkbZiUml8u4cGIiXRYH726txahTcdnkJNxuN5dPSWZGZh8mq5M3NlbTYrKhkMuYlBrm5Y/e1utdaFTcbMLmcHHznHRsTjcquYzyFhOvXjkBtVJOR5+dVftbsDvdTEkPx+6SOH9CAumRgVidLrZXdxGqV1PW0osEXDUthcq2PpbtbsTucmOyOXl8ZQmPnJVHYUMPwToVlSYre+q7+WyXyKHXdJjZXtPFnxfl0mV2eDxGBuiyOLy6/wBsquzg5jnprClpZUdNF39ZlMvHu0T5/UAl5x3zMpmRGUFEoJp3ttTx/vY6r6eeB5eMoiDeSFWbhfs+2uOlT08ICaCyow/cEsEBahq7Lby+cXCiruuy8PTqchJDA7hpdrpnsztIp6LbYuf7sjb6bL7pIovDBbvegjl/oKKtzxPEB9he00V1h5m3t9QwLSOCBL9Cxc8x5Ki3yiVJWidJkkySpDxJkkb3//tFBfEdNR28uqGKq17Zyh8/2cfVr2zlz5/uo7Pv0KXXAOOG8cCYkHJ4Puhbqju58/3dvL2llsdXlnLzWzvZUdNJSbOJqrY+3EOimFop59LJiSy7ZSr/vWA0Rp2a7TXdON1uYoxaXt1QRYvJhlwGfzt9hCcnu7e+m4e+KBrW2/q7kjZGxwcToFbgcEucOz6Jqenh5MYY+PdXJcwfEUWvzcXd7+/m3g/3cNMbO1Ar5TzxTRljk0K4//MiPthez+bKDv67qozwQA3xITrm50bTZ3Nx1/wslAoZGpWCO97fjUal5PPd3h2Lem1OzHYXccOkooZTakQZNJ7vZWxSMBJuHjkrn+xooRIpauxhVLyRUXFGwgI1BGqVXkEchMXBxZOTeXdrnddE0WNxsrehhw1lbbT32rnutW1eypwBdtR0MSEllD0N3r/bVNHBLW/vZP4I781quQxmR5ig6BOwmTjYelujlPPiuiqeWV3ulTf34+doOeErO2s6zKwpafPyMgH4Ym8Tl09JZuIPNKdYOCKaD7fVUd6/GZgUFsCi/JjDeu2vC71X87fMSefVDVWsLWtHq5Lz23lZnD8+nqJGE7e+vYPmHhuhehUPnDmKvy3bJ4LQBsiI1PPUhWNQyGXEGHWkR+pRK+Xsb+rh/KUb6bU5+dOiHH47L5Pn11bQY3UyOkFYEBh1KhaOiMaoU+GSJIoaewjRqzl3rHjdlUWD99jaa2NtaRvjk8XkNdQ2AOC9rbW8fMV4cmMMZEbpkctk9FqdvNhvc2B3utGqFD4bnFqVnBaTlTML4vhox2CO2+ZwsSA3ii/7Pye5DK6cmsJT35aRGBrA2KQQTn9qAwatkqWXjMOgUyGXC3sCuVyGRq5Ao/SdDLrMDpLDAjAN03e0s8/OurI2ylr6uHRKMs5hAmp+QjDFTSamZ4Z7jX+2qwGrw82G8nbunJ/Fqv3NBGqUXJ8nJ3/9DZC1EDQGUiOcTE4LZUP54CbpxJRQ4kJ0nJYfi8vlZkdNF2MSg+m1OSls7KG5x0pCSAA5/aZqfvwcCSf8X0x9p1k0OhhGtdE3jEfJgaRFBvL61RMpbelFkiQyooIOudE5lMT+HPgFExJI7i8oKkgKYVd9Nz0WJw8sLyItQs89H+z2GGSlRwbx2sZqr5VkaUsfu+u6uXNBltf1d9Z00WtzMirOSGSgluLGVs4fn0CwXk1Dl4VrX9vK57dOJzUikK1VHdz29k7quyyEB6r559n5bK5s50AKG3q4YVYqdqevsGhSaigymYxluxt5bl0FFrubexZmkREl0kXL9zRyUb8/+wAZkaJ7T1p4AOeOi2dErIF9DT3kxxtJDNWh1ygZFW/EqFMRoFbSbbZzxVSxofhCv9a+x+pke20n26o6+GZ/K0adij+dlsuk1DAkJKFIyYshQKPEYnMyJimYjRXt3HpShqcQCUR1apRRS2lLL6UtvZQ0m7h4UiLnj0/g7S2iMCk+RMfMrAgeXF5EoFZJZJDWszE5sLdR32XB5nRx7vgEgtUwZeMlEGCEcZeDXE5wgJqHz8rny71NrC9vY0xiCHnxRh5ZUcy+BiHoemp1Oc9fOo4NFe1e1bZ/XpTLpZOT/VWefo6I4z6QO1xuatrNON1uEkIDfDqQh+jVVLT2khdv9PhngFCPpBymcuDHFAYBzMmOoMdi57vSNk9j4kCNkt/Oy+TvnxciSbCvoRvbkD6aASoFnWbflI/Z4TvpuCWJ38zNoKjJxD0f7CY1Qs+SMfE89W0Z7X12Hj4rj+QwPY3dFm54Y7vHsKut1871r2/jsfNG+1xzZmYE+QlGHE6JUL2ajv40x3UzUqlo6+XsZzagUco5f0IitR1mbn9nJ09dOAadSkFd/z7EnfOz6DLbUSvlOFwSz6+r4O+nj+CyF7cAQmv/xd5GHlySx4q9Teyp72Z8cjCXTErGGKAmJULP+9vqPS6JefFGdtV28c1+0Wmp2+Lgjvd28dyl4/h8dwN3L8ji/uVFdJkdpIbrSQgN4MEvhIPhPQuz+L6sjS6zg0smJfFsf9DUqRTkxQcTEaQlLFBDtFGLW5Lo6LXzzxXFBAeoaeqxsbq41RPITx4VzebKDsYmhbD0uwpsTjdxwTpiz3mDvJgACBj0LE8MDeCaGamcMTqWG97Yhhs8QRxExeo/Pi9kVFyw1+f/UL8zZVqkX9Xi5/A5rgN5e6/wxnjuuwqcbomFI6O57+QcEsMGN5JSw/UUJIYwItZIZJCG9eXtZEcH8YdTc0kJ1x/i6kdPVrSBlIhunl4zuOLqtTlZWdTMpJQwNlS0C9+OIYuvjZXt3DAr3UfjPD832uf6Y5NC+MunhZ4KxT31PZS27Oe5S8cREqAmI1Joppu6rb7WqWoF0QYN189I5bl1lbjcEqMTgrl+VippEYE0dlt54bJxrC5upaPPhluSPL7iNqebV9ZXcef8LL4tbmF/k4kHzhzJ3vpurE43YXoVDZ19vLaxAZvTTXCAiup2M3aXm9PyYsiMCsLucmO2OThjdCynj45Fp1JQ1W5mQ0U7zd1Wfn9qDnnxRkxWB5EGLQ8uL/J5/3WdZqZmRHLvh3s8Bl4VbX28vL6KxfmxvLetjkdWFPOPM0by5b5majrNlLb0kh0dxBkFcby3tZb15W2cNSYetVLOf1cNttC7fEoyL6+v8ireyo0xcttJGVz4/GC9W32Xhd8tq+TNayYSPMzfQIRBy6PnFbCqyHfTvK7Twkk53vl2m9PtsU/24+dwOa4D+eaqDp4e0pBgxd4mcmMM3HpShmdMrVRw4cREiptMjIwzcsucDBJCdIT+QH/OY0VTt2+busq2Pqamh1OQEEx2dBD3nzGS37y7y5MCSgrV8ei5+Sz9rgK9WsHNczIoGKYFmFwu8yozByGF67O5mJ4x2LIuWKdCp1IIZQVihTs3J4prX9tGrFHLw2flkRCiIzs6CAl4bm0l/1lZgtMt8ZfFI5ifG8kNb/hWQtZ2mgkP1KBSyHh3Wx0quZyixh76bE4q2/q80ll6tZK5OZFYHC4e7S+fl8vgxcvHc8e7uzzFS6flxWDQqnj2uwqCtUpSIwOpaOnlyQvHUNTYg8Ml0Wd38ur6asIDNXRbHF4ujCBK/U/LjwVE8VVdl4VWkxWdMoRp6WGcOy6B/U0mziiIo7S5l2e/q+Cu+Vk8ft5oylt6MQao+GhHPR19dmZnRXhdu7Hb1964sLGHtl47wcMUR4HwqE8IDfDpG3pmQRzbqryLjZLCAoj/EU9/fn7dHNeBfGOFb473s10NXDk1mUDtoMd1gFr5k1bPWR1OqtqEe2Frr40grZKs6CAig7TkJ/j2AJ2XG0VKuB6jTkmn2U52dBDLbp5GQ7eFSIOGjMggtCoF83OjkMtlPukiEJ3p9zea+O28TGxONy+sq8Dan6IJCVDy/rY6Pt/dSF68kYkpodwyJ41/flWCJIkN3Ee+LAZEmuXO93Zx3cxUxieH8mVhEw8sLyJQo+TKqUko5TJ21nWRFR1IzQHl+BFBGpJCdUQbtJw5Oo4/f7oPl1vi4klJKBVyvtjbSK/VyVlj4uixOgkNVNNtcVDdbqaspZeZmZE88U2ZVwXqst2N/GXRCP7++T6um5HG/1aX8/BZo3hkRbGnc0+0QcvfTh+BzeEiaxjPk+AAFZb+DVeNUk6YXs3pBXG0dFsYlxzKrW/v9Bx7Uk4kc7IjeWtLDc9cNIbq9j721vdw6qgYLp+SxMQhCqUeix2DVsXNc9Lp6rPzwfZ6LA4XiaE6gnW+nuoDfFfSymNfl3DPgmxe6VcfnTE6lhtmpdHSY+P3H++hpLmXcUkh/PX0EYQP0/TEj59DcVwH8pxhur2MSQrx9GL8/6DLbOfpNeVEBWl5fGWJR+kxJjGYJy4ooCAhhD+dlsO/virB4nAxOyuSALWCR1YUc9eCLK5+ZRtOt5uXLp/g85g9dDIayv7GHi5+YbANXJheza1zMnjky2IumJDAyqIWnltbSWJoADanixV7G1mUH8tv5mbicku4DzAimZwWBpJoRbaysIlbT0onKyqI+z8voqH/ieL+M0ayubLT0+RhZJyBrKgg2kw27nx/N7eflMF1M1PRKOVEGTQkhOpJCNVR3NjDst2NHmWLTAa/mZvJm5tqSI8M5NUNVT7vr8dq5/4zRrGp33SqtKWX1iE6+aYeK4UNPeys60KnUnDl1GTP9RVyGTfMTOO5tRUEapT8/pQcgvVKbn5zJ38+LZe/f+7t5fZNUQu/mZdJe6+Nph4r/1td7nmS+PvpIwjp90ixOlx8tKOeB5bvx+Z0E2vUcvfCLB5fWcK9J+fQZbEPG4DNdifPrC6jtKWXp74t49S8GEL1om1eUpiepDA971w3mR6zg9BANUEH+c79+DkUx3Ugn5IWTn680ZNPjgjUcPmU5KNuA3ck7K3vZnddNylhDtRDpHDba7rYWtXJGQVxXDE1hbm50ZjtTlxuN6XNvVw1PYX/rS4jPkTH5LQwVuxrZESswRM4DsVnuxq82sC199lpMVlZeslYog0aLnhuE3ctyKKyrY+K1l5mZEYSH6Lj9nd2CUvX/tSTViXnrgVZrCxq4a3NNdR2mrlwQiJPfVtGm8nuCeIADywv4v4zR1HdYSbWqGVrdSe3vDWYbnl9UzWL8mJ5d2sti/JjsTldPLO6nCCtyhNkQaQWln5XwUUTE9lT3824pBC+L/d+spLL5DywvIhL+ouuYoxarpqWgsXhQqtU8G1xC9tqOhmfFMLLG6qJMmj57wUFmKxOeix27C43509IRAbI5GC2ufjb4hGEB6o93ZyG4nK5WTw6lsq2PkIC1DT1iPf9z6+KmZsbRYxRR3GTiT9/OjgJNHRbeWtzDX84NZfaDjP3f17IW9dO9lTrDiCTyTx6eVO/dTDAHfMzPceEBKgJOUhaxo+fw+G4DuSJYQE8d9k4Spp6cbjcZEQF/qDp/7Gm1+ZkQW4U6yvaOWVUDGGBGv73bRk2p5uqfuc8mUzmkSKCMGN6clUZN85MQ6mQsb1GrHT31HczPSP8B0u4Cxt9zaNKmnvZU9/DnKwILp6UxGsbqj0BaXtNF0sK4hiTGMz2mi4Uchk5MUFMTg3j2TUVtPRvhC7f00Rxk4k/nJrDo1+Xel2/z+7ii72NVLf3cf544T0yFL1GSbfVwe1zM0UD4yYTz6+r5KbZ6cN+ZmqlnECtgiunpNLYY6WitQ+FXMYF4xPoNNvIjTWgUsrIjgrCoFXx92W7PedfPT2F1DA9WdGBvLG5hk93NfD5nkaun57CiPhg/v1VMTUdZh44cxR/X1boeUq6d2E2OTFBFA35/Iw6FeNTQvn9R3u5a0GW18rf5nB7DMtqh3F5LGnupcfiYF9jD2aHm6Yeq08g16kU3Dg7nauGlPVrlHJmZkYceDk/fn40x3UgB9HH81j28jwSJEmitKXXyx42MkjDlVNTeHpNOaOH2aAESAkP5PT8GBLDAvhibxNymYxF+XH868v9RATlkxPjmzIayqL8GL4t9m5cMC83ik921vP5nibOn5DgCeIDfLyznptmCzXM6IRglhTEs72202u1DFDe2keX2cG45BCPO+MA+fHBTEoJw+Z0ExGo8Qp6V/Zrv8cmhSCTybA6XUgSKGQy1Aq5lx1vQqiO7KhAUsP13P7ODmZkRrKkII6s6CBMFgfv9retS40I4s+LQrnwhc1e9/HK+iqWXjqOaKOOT26aSmlLL3q1kpyYIOq7LNw0O52OPjuSJBpfDNjuPvJVMS9dPp4X11WyqbKDnJggLpqYxMp9TVwzPZVdtZ1eTpNXTkv2eL5HG33/xuJDdASolYTp1ZxZEMfDX+xnano4i/NjveSDU9PDeP2qCXy8o57gADWn5ccyKs5378SPnx/LcR/If04auiw8s9rb6KrFZEOrkvO7k7MpSAwe9ryRsQZOzYvl2te2eca+K23jvlNyKG3u/cFAHmPUcsPMNF5aLwpmzhmbwPbqTk4eGcNjK0tQDLOil8tkjEkM4eObppIbY0Ahl9HY46vAkMuEPl0GzMmOZNX+FhRyGWePjSfaqOXu93ej1yh4aEkeO2q6sLvc5McHIyEhl8k8VgGJoXpyYwy8s6WWOxdk8dzaClpNNtIj9Tx4Zp7Qoj+3EbPd5ekSFBKgYsmYeI9t7MaKDp44f7TPPTpcEturRYHQHfOzyIwKorHbwt6GbjZVdHhNTqeMimZ2ViTfFrfgckvUdpr5/ak5/S38RNojNyaI9Mgg9jX20Nxjo7Sll/PGJ3DyyBhPYU52dBC3zEn3SBQD1AqumpbC6pIWzHaX6NsKbK3u5Mt9jbx21UQi+hcYWpWSaRkRTMvwr8L9/DT4A/lRIEn4SN9ASMgW58dR1NTDZ7sakcugIDHEE6A1KgWf72n0OW9DeTs3zh6+0W9ps4lV+1uobOtjSloY3WY7l01OBkR3ocq2PpxuibsWZPV3mPduHn3F1GSmpYejGpLHtzrcLBgRzZf7Bl0Tr5qWQkiAmhe/r2JyWhi3npSOJEFMsJa2Xhu/PzWHII0Sq8NFlFHDR9vrPfYHMhm8eNl4ZmdHEqpX85/zR7P0uwre3lzDTbPSyI01kB4ZSKhew7rSVp9S/k6zw8sPHISVwoSUUOGM2E9csI6MyEA2V3ZQ0drHe9tqiQvWEapX43C5CdIoPVrs5Xua+M28TM8TTESghve21aFSyJiXE01urAGb04VKKWd0QjCPnTcam9PtUyYfqFVxw6w05uVG0Wm2ExmoobCxh8mpYfzlM+8N1P1NonI04md6UvTz68MfyI+C2GAd185I9SokMeiUjIoPZnddF+ct3ehRQOjVCt66dpLH7Go4jxCVQkZKmG+RUlVbHxe/sInm/pZju+q6SIsI5M0D8tQS8O6WOspae/nb4hGYbA721vUwNzeSKQcEcafLzdOrywgOUHPH/ExMVicGrYqs6ED+u6qUvy4ewYvfV/L6RhOL8mOZHKbnH8sKKWoyoVbIUSvk/PvcfPYOqVaUJHhkxX7GJIVg1KnIiArigTNH0WVxYNApvfqRhgVqfJpmaJRyAlQKrp6eglaloKnbikou4+bZ6fzm3Z2UNPcyKs7AmQXx3PX+bkbFG/m+rJXIIC1vba6hsNFEjFHLbXMzeH5tpSe95HQJ29+bZqexq66LQI0Sh8tNY7eFL/Y2sGp/KwtHRnP2mHiSwg/emzVArfRqIJETa2TfAekno07FRRMT6eizs7myHRkyXJJEeqTo4XpcYe6EnnrQGiD4xO3qdSLgD+RHgVwu45JJScQF63h3ax25sUFcMCGRtIhAfvfBbq+CmD67i892NXgCwdljE3h/26A7n0wGF09KInyYVVxh/yP/AEWNJs4dl8DyPY2e8+UyUem5u7aLyyYnUdLSy1kFsVw/c3CzsaPPhkouJ0inQi6TEahRsmx3I8t2N3ry2H9dnEuIXs0jK/Yzf0Q0eo2S74pbSAoNYGxSKAtGRNNrcxEcoGJzZTvjk0M8pfQAHWY7zd0WdCo5aqUClVJOxDCyvLQIPfeenM39y4uQJHH/9y8ZSZvJxrtbaumxOkkJ13P/mSMZEWfkmYvHsL/JxCc7G3lgeRFOt4RKLqe9z85nuxo9rdMau63888tirp+Zxn++KSXGqGFKWhgTU0Ipbell6/4WvutPgyjlMn53cjYNXRb+u6qMffXdPHFBwUFln8OREqHnjNGxfLyzAbVCzu1zM3js60EZ6uL8WHptTjr67Dx+/miSh5mof5E07YWPb4Cm3aANhlP/BTmng9Kvrvkl4g/kR0mkQcv5ExI5e2w8CrkMmUyGJEk+1qoADV2DG5BjEoN597rJfLKzwdNt/mA59eEc+t7cVM3/LhrDyqJm1Ao5KRGBVLf3sXBkNO9vq0MulxEXrCMxTI/TJbFsdwPPra3EoFVyx4IspqeHc/nUFL4qbMYtgd3lRq2Qk58QzNT0CP7xeSEf7agnIkjDzbPS0ark7KjtZG/94Ar89rkZnDk6ziuQnzM2nstf3sLsrEhump1+UIMxtyTR0G3hN3MzsbvcqBRybHY3j6wo9kxOlW19/PWzQt65dhKpEUE8vbrCKw3U2G0h2hDr1f8SRJm7W5K4fEoSqRGB/PWzQvQaBZdOTqZxiKTS6ZZ4eX0Vp/bLJlcVt1LdYWZE7OFvRAaoldy9MJuJqWF09tl4Z0uNl2vkp7sa+O28TB79uoTV+1u4fGrKYV/7Z8PSDctuF0EcwNoFH14DV6dDXMHPeWd+DoI/kB8jhj6Oy2QyLpyQ6NkAG2DJmDiv48clhzIuOZQfIifGQKBGSe8QD45TRsUyPzeahSNj6LU6uO71bYxNCuGJbwbTPA8sLyIpNIC2Ppsnj1sPXP3KVt65dhLjkkJ497rJfFPUgkop46TsKPLijchkMv530RiW7Wpkd303j60s4U+Lcr2COMCL31fy7EVjGBlnoKPXzsKR0aRHBtFlFpr6zZXtZEUbSA3X+/Q5be6x8dL3VZ6S9YzIQC6YkOjTaKK4SXi3j4pTcvKoaKKNWlQKOZsrO1hX1kZssBa9WkHfAfn2EbEGatrNns4/ANtrdvK7hdk8+MV+z1hdp6imBfFU8GO62ccG67hgQiI17WYe+bLE5/cDT2ZbqzqPj0De2wx1W7zHJAk6K/yB/BeKP5D/RExJD+ORs/P476pSFDIZt83NYGLKDwft4ciICuLNaybyyvoqDDoVefHBWO0uNla2MzLWiEGn4sElo7jzvd0+5362uwH7MBa+68vbmZgadtDJJECtpKy1l9c3VgN4fFqGYrI66bQ4iDHqyI420Gyy0myy8vh5+eys7ebvy4roNNv57bwMTh4Zw/4mE2a7i+zoIKKNWqKCtDT1WLluRipqpZywQN/H9ohADV8VNlPe2sd9H+3xBMXF+bFcNDGR8tZe7lyQxV+HbDieNy6eXXVdfFfiPZFKkpBXRhu0nvz55NQwdtV2AcIoKynsx9chhOpVTEwJ9VSkDqBViclhRtbwqpWOPhtOl3RYHav+X9AawRAn8uND0UcOf7yfnx1/IP+JMOrUnDsugbk5UchlHNRQ6XDJiw/mz4tG8M8vi/nNOzs943fOz+S6GWkkhuo9So6hpEYEUtrsW0AUehgVpKflxfDahmosDhcKucynM/1J2ZGkRwZyZkEcVocLmQxe31jNtuouQgJUXD09lY931NNnc3PFy1uo6Rhs0PzaVRP47fwM3tpUi4REl9nBO1tqOXtsPO/368hVChnXzEilocvCv78q9nrtT3c18Oi5+dzx3i7OGRPPO9dOorXXRkSQhhiDlpJmE9sPaLcGogORrj+wTkoN5fqZqXxT1MIZo+OICFJT1txLRlSQV5Xu4RKoVfHnRbnc9OZ2KtvMqBVyLp2SxJriVs4eG8/0DO9GFWa7k1VFLTy0Yj9mu4trpqdw1pj4nz+gB0XBov/A2xeAq785x9grIGrkz3tffg6KTJJ85XM/NePGjZO2bt36wwceJWa7ky1VnXyys54wvZrT8mLJP0iRzvHAztpOznhqvdeYUi5j+W3TyYwKYk9dNxc8t9GTggkJUPHmNZPo7LNzyYubPQqRUL2at6+dROYwhlMHsq+hm82VHagVcuJCdPznm1Iq2/pYkBvFeeMTGdPfCq+itZf7PtzDxiETiUwGd83PwuJweSl7QLTQW1IQS0ighrIhRVWTU8OYnBaGS5JICdPzzy+LOXNMHE8ecD7AfSdnMzEllJSIQAxDTKtaTTYufG4DF09K5q+f7fOka/RqBe9eP5mQADV9dicxBi0ymYw3N9XwyJf7cbgkZDJ4/LzRnD46zuf1Dpf2Xhu1nRa0SjkywA0kh+l9pJXfl7Vx0RBLXIC/Lh7BZVOSf/RrHzPcbmjdDx0Vwmc9cgTo/EVMPzcymWybJEnjDhw/oVfk60rbvIpuXttYzfvXT2HkcVpV12v19al2uiXP+Kh4Ix/eOIWihh7kchm5sQbSIgJxuty8f/1kdtR0EaBWMC45hPTIHw7iACNijZ7Nv3c215AcFsDCEdGsKW7hlre28+Y1k0gMDcBsc3kFcRjU2Q/Xiamu00J6lIFluxu8ng42VLR7rHlvnpNOfZeF8pZeT2ehodhdEhVtfeQf4GzZ1multKWPV9ZXcffCbGrazWhVoiz+wI3MnbWd3D/E61yS4Pcf7WV0QjBJB1GYNHRZqGg1oZFsZAT0EWwMhqBBv/iwQA1hhyE1/L6szWfstY3VLCmII+gQbor/L8jlEJUr/vn5xXPCBvI+m5P/rvL2C7E63KwvbztuA3lSmJ6QABWd5sFelCnhAV4+LplRQT4rbaVCTkFiyFFZ+Tb3WHloxf7+127wjO+p7+a7klaKm03EBeuGVesMV6l64cRERsYa6LE4sLtcPpry+BCd5+evC5u575RsbA43Za29BGqUXDM9hWW7GxidEMyZY+K9rh2iVxMZpKGirY+HvthPRKAGm8vFon6P8qF09Pp2Y+q1OT0ujwdS1NjDlS9v8ahf5qbp+XvCcmLyZkPskW0ERhl8g318sO5HpXW8cLvBZQXV/6/vkJ+fj/8/m8D/ZyRJGrbq0jXM2PFCQmgAL10xnnFJISjlMmZkhvPUhWOPyL/a7ZbosTiO+HNwuiVPJea4pBBuOymD207KQKWQCeVHkJbb5qajHNJrckFuFLFGLWtLWvnn2XnEh+gI1Ci5cVYaZ4+NJ0CjZG5uFOOTQ3jk7DwMWrGuiAvW8cQFBVw4IZGll4zl+UvHkRgawF8W53LfKdlcODGRtzbXsr/J5EntOFxuSltM7K7rQqNQ8K9z8tH1K2Xa+mzcMDNt2FRSfGgA6gOUKomhOmKNvrJJu9PF0jXlXhLGleV9bFUWwPJ7hGzvCJiaHu6lsVcr5Nw4O91H4XNENO2F5XfBCwvg+/9AV82Pv5af44YTdkUeqFVx46x0L6tVlULGlLTwQ5z1y2d0QggvXTGebouDEL0a/TBNJw5GeUsvb22u4dviFqZnRHDRxEQyDiNPDhBj0HL19BRaTDb6bE6eWFWKJMGCEVEkhgbw6NclFCQYeerCAgobTYyKN6JRyKls7+PiyUk0dVtZlB/Tb25l8MppRwTpOGtMPBOSQ+ky24k2aj3l7U3dVq5+dSvdFgdymTDn2lHbRVOPlVmZEUxNC6PHYufVDdU8vrIUp1tiyZg4LpqQwKtXjafH4iTaoCUtMnBYn/r0iECevWQsd7+/m9ZeG2kReh49d/Swk2OvzcWW6k6f8ZIeBXSWg7n9iPLI6ZFBvHPtJPbUdWN1uvrTWAfx2ZEkaN4HrcWgCRQbj8YD8vid1fD6mdDbb6jWtFucs+g/oPJ3HTqROaE3O00WB+sr2nltQxVhgRoumZTEmMQQ5L/CDuUdfXaueGmzVy/QjKhA3rx64mF7gjR3W1m2p4G/L/Pun3nVtBQ+3lFPe5+dhFAdSwriuHJaKm63xKe76jDb3Ty8otjrnBcvG8+cHCFnq2ztZW1pG/ubTEzPDGdiSiiheg3tvTaWPL2e6nZvC9nHz8unut3MzMwIRieGeG0anjpKGF19ukukf9Ii9Dx98Rgyow5tRNbYZaHb4iDSoCFU7x3EO/ps6FRK1Eo5f1u2j1fWV3v9ful8LfOL/wyXfQYBP1EnqppNUPY1OG2w+20kQzyyc14Wv1OowBALJV/Cm+d6nyeTwU2bwZgACjXIj7LpSne9mCCsPRCRCdF50FIIu98V/5t/AaTOAv3xvWD6pfKr3OwM0qlYMCLaIwH8IZ/vE5nKtj6fhs6lzb1UtvUddiCPMmqHlfTtqOkkKzqI9eXt1HZYGJ8cilGn4rNdDXy8o5FA7eCfWVqEniCtig+31zInJ5KGLgvXvLqNstZeAN7cXMPtczO4ZU4G7X12nyAOQr/+wrpK0iMDGZ0YQk3/MTIZZEUHeXqCgtCNP726gofPGoVaefAgFhOsI+aAKtT6TjMfbK/n3a21pITruWVOOldOSWFvXTfbarrEE0KBgbFdn9E372H0P1UQL/1aVFZaOkFjgBl3Itv0DFLJl8i++gNo9DD3bxA6TLHR6EugdCXsfhsicmDi9T++qKerDt67DOr7F2FyBVzyMbx7qbg3gLKVMPevMO32H/cafn4UJ2yOfCgDpfO/Zg62gXaklYxjk3yDVUZUkKefZ5heTWqE8OL+cHs9vTYnRp2K8EA1952Sw4hYI0adislp4ZgsDoqbTJ4gPsDTq8up7TQTpleTFuGrHOm1Obl4UhKJoeJ3Uf1e4UEaJW1DPNIHWFfaRrfFVznTbXFQ22Gmbxg1kMPl5rm1lTz6dQl1nRbWlrZxyQubqWzv4z/nF/Dvs0fyygWZnJroYLnuNOa8Y6GsxVevf9R0VsEHVw0GSlsPfPsAjL4QWU8dyABzB3x6M9jNQiY4QHgmqAPgy3uhcZcI5q8uEumZH0PjjsEgDuB2Qe3mwXsb4Lt/Qnfdj3sNPz+KE3pF7meQlHA9Swri+HDHYLXeySOjSYsIPMRZvszJjuTDHXWecv2ksABig3XUdVpQK+Q8cnaex18lPVLPt8UtnDc+gRGxBq+injUlreg1Sgw63z9Bh8uN2y0RFqjhr4tHcNvbO2nvs6OUy7hiagpf7mvmkklJZEWLe8+LN3LWmHg+2llHUpjep2T/nHFx7G/q4ZX1HcQYtUxKDaPH4uDPn+1ld10Pk9NC+eOpueQOkSY29Vh5Y5N3CsXmdLO9ppMei4N7Pyr0apYBYg8iPTKIboudxm4rQRoVcSFHmJu2dImKSnUQhCSCqRGsB2yiOq3C6lIbLFItA9RthvPfgrKvoGkPjDzLN9ViM4m8eUTWkd0XADLIPR1qNgzm4d3DqHt+5YumnwN/IP+VEKhRcvfCLGZnR7Cjppu8eCMTU0K9Nh0Ph+RwPS9dPp7Sll7cbonkMD0dZjt5cUbiQ3ReE8MZBXG8s7WWV9dXc864eK/KTID/rirl+UvHEapX09E3KAM8Z1y8JwDGhehYMiYOjUqBXAZf7GmitKWXe0/O9qRKwgM13LMwi7k5kWyu6uDaGak43BLPrC4nKzqQ5LBALhnSZSjOqOWssfHsrhOT0YbyDm58czvvXzfFs8mpVsgI0qq87gtEx6PXN9YwLT2MVcWt3p+xVsX+xh7u+WA3u+q6CQ5Qcf8ZI5mXG314ksLmvfDxzWLlO+A4GJ0nNiodQ2SdciXumHzk3z/mfb4xEUKTYMI14ufuOpEXd3p3i0L+I/6zr9sKO9+E9lIxQTgssO1lCEkBXYj3qnzG3WCMP+il/Bx7/IH8V0S0Ucei/DgW5R9Z1WK3xUFJs4kei4PkcD1pEYFeefX40OH1yiNijXxw/RRKmk1UD9PzEmSEBqp5/aoJvLqhmt113ZxREMupo2I83uWJoXrCAzVeRlcLR0b5SAlXFjVz30d7PT8nhOh4+9qJhAdqOW/pBq9j67utns4/A1S1mantNHsCeZRBx70nZ3PX+4P+NSnherotDoIDVJw+OtYrkM/MCCclTM8tb+/w7EV0mR3c/NYOPrtxEiMVNSL4haZ6FQ95sPbAsjtFEIdBx8Frv4PFT8LH14tyebmCnjkP0uQIJ7NlyKZzaBokT/W+pjEe5vwBvrh7cMwQB9GjfF//QBxWURSkUItNzFcWgaP/O2wrgdEXwbQ7IGGS2OTd/R60FkHe+ZA684ev7+eY4g/kfg5Je5+Nh77Yz3tbRc5Tp1Lw8hXjmZgadljnZ0QFkREVxN76bp74phSrY3BVfttJ6Rh1aow6NfefOQqb00XAAXJKhVw4SY6MM1Le2kusUUdevJGQIdWgTd1WH1VMbaeF9l4HcSEBw1bEug5Qa6kUwp99KKeMiiEkQM2aklaMASocTjcvrKvguUvHMSEljLevnUhpcy9RBi15CcH0Wp1sO0CeKElQWVXJyG9OEgOhqXDeG74Vk73NUOs94SBJImjmngGhaVibiuhQx7KuRUuKvA/nWS+jdPSCUitW7iHDNH9InQ1nPQ+V30F4FmTMG35TdACbCcq/hQ1PgVoPU28Fm3kwiA+w5z24cTOEJoufD2dy8POTcUwCuUwmWwj8B1AAz0uS9NCxuK6fn5/C+h5PEAfhgvinT/fx9rWTCDkCI7CRcUY+uGEKxU0mLHYXSWF6RicM5qQVcplPEB8gSKdiano4U9OHl7Q53W4sdl93RqvTRVSQlqumpfDEEK8WjVJOaoj3vf9mbibJ4d4bq3qNkoLEYFpMVkqae7E6XNy1IJt/f1XC0xePZVJqOJNSB++pGStRBo1XExCAcOeQtn4dFbDucTj9Se8mDRqjWEEfuEmojwSFEiwdaD+7gVi5knNVOhFwlRq4cRPoQoW23NoN9duhpUhMGAoVvHc52HvFij16lJAhDtBaLI5VaiF6pHj98lVChTJAxSox8RyIWv/TNZlwOaG7BpCJzkRHK5n8FXDUgVwmkymAp4B5QB2wRSaTfSpJUuGhz/RzPNAyjAqkuMmEyeI8okDe0mPl010NvLhONIy+YmoKGVGBR9SN52DEGHVcPjWZpd9VeMZ0KgXZ0QbkchkXTkzCoFPx5qYaEo1ybs61k1b9BK8vmE+jQ0dYeBRfVpqp77T4BPOaDjP3fbSXML0ahVxGi0l8HlXtfSQckFKKMmh5cMkorn11m6eq+LzR4eQ0LvW+4crVInUSOMQWNihSFO68df6g42DBJSLAAjj7c/VupwjiMhlM+w1sXir05amzIWUmvHepUJOMu1Loym39/jTtpaLiM3YMxI8TOe9XTxdBHiAyF859DTb8z/teJQkqVkPiVKj5fnD8pD/7FiQdC0zNsPFp2PiUeI+Tb4EJ1wpHRj8H5VisyCcAZZIkVQDIZLK3gdMBfyD/Ceg226nuEBapKcM0bDjWJA2T/56RGU5Y0JGtxtaWtvHsmsFAu/S7CjIiAzlnXMIhzvphCht72FrZQUFiMHcvyOKD7fVkRAZy3cxUsqJFHj3aqCU3xsC1k6I4vfkpdCtfB0liGi8CsGbWu7yzxUlahJ5rZ6R5XT9Qo0Qpl9F+wKan4SAT0MzMSD67ZRpV7X2EBqjJclcQ/Pr73gelzBKbmQeSOkfkxD2Og7mg6z8uIkuMmfuNyUadA8UroHGn+LmtFMq/EcF/28vi2AP9xAF6GoTSZe2jIl0iV4rJoaUQajaK8w5EroLxV0PiRFG9mnUKJE0Z9v0fNeUrYegm7tp/CRll/nk/fK7TAX3NoNL/dIVZv1CORSCPA4Z2Aa4DJh54kEwmuxa4FiAx0d/I9cdQ3tLLPR/sZmt1JzIZXDY5mZtnpx+R18qRkhtr4B9njOT+z4uwOFyMiDXw+1Nyj8gaAOCzXQ0+Y5/sbDiqQL6nv8H1gAdMjEHL0svGkRUV6FX809Jj5bfv7qLTbCfjlDMYW71KBDmVjrpJf+HRXSrAyfqydp9Anhyu57fzMnnky8Ec/GWTk0iLHF62qZDLyIkxDBqF9bqEl/e2l0TwHn2RCLbDpSUO5TgYlgqXfCJy1w3bIe0kUU05lPZyGHl2/+u2QHASdHlLKDHGC715wgSIHiHSGJpA2PICdFbClFug5As8rZuUWrEa3vMujLlUvEZgpGjIDOJaNRtg11sQECYmmLixP16CuOtd37G9H/xwIG+vgO8fF/cZkgoLH4DkGeIz/RXw/7bZKUnSUmApiBL9/6/XPVFwuSXe3FzD1v7NNEmCl9dXMTktjAUjhlFBHCMC1EoumpjItPRw+mxO4kJ0P6pJRl6CkdUl3nK90UfpDb98T5MniAM09lh5fm0Fj5832uu4HqvT0xHo4i+cXD/2WUboe4iOiubGFV2ehhcn5fg+vqsUci6dnMSYpBBqO8zEGLWMjDP6bIwelMBIWHC/COb1W2HDk1D6Jcy6F9LmQm+T+BcUA2Hph84Hx+TB6U+BvQ+6qoY/Rh0AWSdDSzFMvgnWPCxW0Qo1LHwIInNEkdGGJ6Gv//tQqGDe3yAsA+LGweXLofBTkeIJSRRGXMHx8P7l4LLDiLPgpD9BSBLUb4OqdeKJoPE9MWFd+eURO0F6iCsQqSev9z360Oc4bfDtP0TAB2jZB6+fBdd8Kz6zXwHHIpDXA0OXVfH9Y36OISarg68Lm33Gd9Z0/qSBHIS1wYG54yPltP4Gx03dIsccZdCweBhb2SOhxWT1GWvqttJjdWDUDU42EUEa8hOM7KrtxuJw8djGHmQyeODMCGo6RDPnk0dGMzt7+FZsgVoVk1LDmHSYSh0f1Hqx2v38t4NjH1wFS56DT28ROm+lBs5cKgpuDlzNtlcIVYutB+RqCM+AsDQYfaHQdg8w96/gsIkN05AUkZK47jvhgBgQJjY8FUqR8+4bMqm6HMIGYNT54kkhaYpIubx7iVjZn/IvsHSI1bpSC2XfwK63xcp72W1gaoLs0yBtNqx7TKheDgzkbpfoA7rtFZHjH3sZJE0VE88AkgQ5i8V76u3/Ww+KgZFnHvrz7amHfR8e8HpOaCv2B/IjYAuQIZPJUhAB/HzgwmNwXT9D0GuUTEgJ9ZTCD5A9jNf3L5HMqCDeu24Kxc0mkCAzOsjLR/3HsDg/lg+2e68ZpqSHs7myg3m5g5ObUafiwTNH8dt3d7G/yYRBq+Rvp49kVmY4o+KMyBAdfPTaw/vPoctsZ39jDx1mB8lhejKjAr2abwOiQtPtFOZRHZWw9QXfCxV+LFbhzXvFqvLjG4SrYXj64DEt+0V6ZO2/oXYThCSLDcD0uTDnT+J/azdBWBa07IWtIu9P0x4RsK/+xjefbWryvRdTIyiH5P21RrGST5ouguqahwd/N+FaYZzVsm9QZVP4sSgUih4l3veB1G+Dl08RAT0yR1SX1m0RmvqkqSLttP0Vsdk64RoIThBjMXniPXt9ATXQuFtMCBHZEBgFAeHekxMIX5pfCUcdyCVJcspkspuBLxHywxclSdr3A6f5OUJUCjlXT0thQ3kb9V1iJTonO5LxwzRO/qWSEBrgo/Q4GsYmh/Cn03J4a3MtTrfEovwYtld3UtzY4xXIAXJjjbx1zSQauy0EaVWe+wjWH9n+QmefnfuXF3n6iirkMpZeMnYwLWM3C+Oob+8Xm4mTbhKpE90wm2+6EBFwB3CYoa/FO5D31MOqf4jACSIt8tV9QjGSdbIInrlniLTCjte9r2/rEcE2ItN7PG2OyCcPZdxVoBlSZBWaJiYKh1l4pwxly/Nw2n9g24ve4/s/hwnXiesfSPFyEcSVGrFP8PUfB/Pw+ghR9PTt/eLn7x4R/3v+m75BvLMG3rlw8HOTK+Dij+DkR+D9KwaPS5wstPW/Eo5JjlySpOXA8mNxLT8HJzvGwHvXT6GyrQ+NUk56ZOBRN3U+ngnUqKjrtJAZFYRCLuPl76vosTq5YVbasMeH6NVehUQ/hqLGHk8QB7F3cd9He/gsziiaJtdtESmJAVbcAzPugvT5Qg44UC6vDhRKlKHBVx0IgQekyRyWwSA+gNMmAnrDLojNF8EsIkcESdcBHY/kw6hr4seLtM7qB4X8cOTZosS+q0botkGkYMZdIdIoB66wJbfY7GzY4T1ujIcRZxw6p52xQGyMDi3I6muFpl0ijz/0/ouWQfap3uc3bPee/NwuWHEvXPqpyM23lYg0UsxoMMQc/D5OMPyVnccZscE6jymVH+HncsHSjR6TLINOyen5sfT0t2o7Ui+ZH+JAGSJAc48Nk9VJpAERrA+k5Es2Tn6asHNWkdG+ShTuZJ0MphYRvO29Ig2wZKlQpwwlIEz8bkAP7hkPhdfPgGtWi03HmFFiA/XL+waPCU4UOe/aLf2eLf1PHyqd2JyMHy/awe37UKRbDLFQcPHg+ZogUGjEinlo2kIbLHLwcWNFygTEZLLwIYgbM/wHl3UKrP+vUMjIlUIDL1OA5BKB3eUUm65DA3l4hu91DnRaBOiuBbcdEieJf79C/IHcz3FNXnwwH9w4hX0NPchlMCLWQFGjiVve2oFcDrfOyWBmVuThq0x+gOQwPTLZ4IJSo5Rz9tg4orUOEQyH0WFbdNE8saGTfc0W3p4TR05MsgiCkiQ2I3ubRa7YEC8KYrSGwY4+0aNg3l9g2ZCN0pFniRyzuUOszEOSxPjoi0RKpPQrEWzlcnjrArGivvhDkXeWq4SSpuQL75UtCB350EAOQno4/U7Y8hy0l4kAPv/vYmI54xkxZuuG8OxDl+nHjRVqmPJVorhoxT1iAlMHiieW2ALY9PTg8YGRYrI7kKhcUfiUMr1/k1gnJoTAX3fB0AndIcjPr4+vC5u45tVtXmMvXj6eOdmRBznjyLA73awsaub3H+1hfoqKW5LqiKv5GFlIsgiiLpvolTmwclSo2HPSayz+zI0kwR1TQrgluR7yzhm8aG+L0GdvfVEUxMRPhNn3Qky++L3DCrUboblQrGhrNsHO/pTMNd/6roKr1sLbFw3a306+WWy4liwXK+xZvxOFRp/dLhQ1eeeJMv/EyZAx1/taLifUrBcSw5gCYZG76y2R8kmaCmc+KyaIA3G7h9dwt5fBM9O9vVtUASJHHpkrcvpyhZgUwtJ9zzd3iRz6xqcGx057HMZe/quwz/1Vdgjy8+vjzc21PmMfbKs9ZoFcrZRzyqgYxoTZCSt+B9Wq+wd/qQ2GKTfDxOtxqwJos0CJKpt71siRJCG7rDMrRDB09Il8cV8r7HxDmFq19BdDl3wBDdvg6lUiSKq0IshVfy+aRAww6SZhhGU3C3mj5BYeK6amwSBuTBBBs/hz8bPTCiv/IsrxU2dD5gKhKe+uE5uvi5+ClGlCtQIiV54yQwTW968S1aMgnhiMcWICCooWaREQ1yleAXvfF2qZUedCZLZ4cmjaI6SOBxpwOcwiP5+5AKJyDv0FdFZ4B3EQ6aSUGUKS+SvFH8j9nFBEDVPlerit7I6EaEsFbHrSe9DaJdIYqx9Crgtl/dxvuf09bwHXwmgTrHlPVGVOvF5I6IxxIp+ds0gcVLdFpCAad4lAbu2BVfeLIDbnj+C0QGi6cDK0dYmOQTvfGNRhT78D0ueJ68SPFzLEA6ndBKf8G145VUgPQTxFvH+5KPax9UL++cIpsatGBOK24n6JYZ64r9UPicKh/Atg6m1C8736YdjxqrhezQbY8z6c+yq8c4kwwppxp9CiD/VIV2ohIkM8bfwQfe2+Yw6zb/ONXxm/jvpVP78azhufgGZIEwetSs4ZBT+BuZNaj+izdhA0BqYnB/KX03KIDNIQH6LjsXlGxlc+PZhg3/K8CH7hWSIYrXlY/JMrhRywvUw0O27YDnvfEyX3Dgt0N4CpQRTX7HpXKF8Grln0KRR9BpJT+KNE5Ih/BxIYCc17BoP4AC67mJDWPAQr7hPpnBcWwDd/F3LEliJY+WfY9Kwo6pHcoprzu3+JewoIEcF64vViVW/tFpNSd424/q53RE5c2T/hKtQw7+8QO/bwPvfQpMH9gwGCk8X+wq8Y/4rczwnF6IRg3r9+MpsqO5DLZExICWVknPGHTwThMFi3Reih1YGQffLBS80jcmDSDULCN4AuRARUuQJO/RdhYeFcPi2cU7MNKDrKCP3wPBEkB5DJwRAtVt6V3w2Ol34Fs+4T8r6oEUJhMucPsPEZURw0968ivRAYPbzErnKNyDuv/ZdYKU+4RqRlBl47ZYZQqLidQpliG9JrVCaDwP5rliyHnNNEgJ58Iyy/Y/DY1v2wvVt4q+x8Q1y/bqbI89tMQuky63ew8y2xmh+guxa2vyomhfAMUcgTPerwLXHDMuCCt+GTm0QaJ2qksAQOOjaps+MVfyD3c0Ihk8kYFR/MqPjgIz+5eh28vmRwdbvhCbjii+GDuTZImEgFJ4pinIGmDbYeIQmM6m+C7HIQsa3fzU8TJBQeKbNEkU5oujB22nOr7/UbtovVsuQWq+fPbhMqD7lCpFZ6W0S+OWU6ohZvCJE5okweYNMzYhP27JdEQHZYxATy6S0ipz/tN6IQx93vWTPtDrFanvsX2PqSWFHLZOJYm0mYbWWdIlwUtUYxoe16S2w2fnzDoOa8r1WU65/yz0Fp4baXxOt0VYufMxcc+Xckk0HqLLF/YOnsr+r8dTkdDoc/kPvxA6LIZt1/vAtVHBbhQXKwVbkhVvidjD6EI0VXNWx+Vvz/mfeKnPPWl8RKNXWW+Jc8U0j/hhJbAAFzhYa8pUiscKffIQyzdGEw9XaxSalQi0mjuT8XH5oq2rl192/6Tr5FaNtLlotc9KL/wLLfiPfmsIi0zKx7xXvpaxOl9vXbRXrnjKfFhBGdJ1Iu+nBRtbnyL4P3GZ4lVvwBYb6FQ70tYoPzu3+J+5p1n1CcTLxhcD/gcHC7xepbLh/sBRoU5fcoH4I/kPvxA2LlO9BkYSgHKiyOGJn457KDuQ02PzPYgb7oU9Gl56wXhaqkub/naGyBCNirHxQpkiVLYeJ18NXvB1fOwYnCxOr7x2H0xaI0XmMQ/uQDJe4hKeI6A4oVh0VUPtr7Bm+vo0LIJafcOlgiDyIo73wDxlwudORNe8VEtHrIMSA2QCffIJ5EhgrsQazYnbbB17F0wszfCf8Ww2EapvU0CQ37wKQ1+z6xuTrg0z4Ucwd01Yonn9CUX4UccQD/ZqcfPyA20Cbf7D0mkx368V+SoGGnWGHveF3kjQ8kOGnwuprAwSA+QFuxSJVc8hFc9jmc+7oo3V//hPi9wyyeFDqrB4M4CCWJLhTiJwhpYmclfHSteB9Tb4fcM0V6ZCCID+B292/UDkEXIgyyDsTUKFbo710mrABkcqGgOZCeBpFemX73YPBUqGHab2H3O4PHNWwX3YwOZsE7HMXLRa5fqYWkyULtU73e97jmvfDyIlg6A56ZKppr2I92Ej5+8AdyP34GSD8JznkFEiYK+d4lnxxaTVG7CV6YB8tuF5tvLy6EpgP84hRKoeBYsnRwE3EoMrmwcg2MFPptc5uwiB1Ka5Fv8AWR/rjkExHE1j0mVv2rHxS56LRZQlkSOcL7nF1vwsn/HLyeSidSNsOljzJPFhunklv0GTXECF34UJQaUS3atAcis0SHo3NegTOfEY6PQyeuuHEiTTRQifpDOKyw4zVRsDT2cqGPD4z0fXKymYTCpqX/icZhFt/JwBPOrwB/asWPnwG0BmH6lLlQlH0PtXU9EJcT1j/l7Q1i6RS56Kq1sP8zEQizTxOd5vPOE6vZui0imA4w6UYR3MwdYoU9XJVkzuLB3PAAMpkIvrZuKFnh/Ttzh0jZNO4UlZc16wd11oY4IdU7/SmhFVfrRTA2d4n8+fr/isA48izoqRusUG3YJt5zaJpI6ez9AIyJ4vNa95goboofL1I+lk7x+9iCwVx95smi6nXWvSKv3rRXbIga40UF53BpEIUKkqaB0zzo1jig8IkaOdhJqa9NTDgDqPXiOxzu6eEExR/I/fg5ENVhFBC5HdDjW0VKe7kINlEjRCBc96jQSbvtQnYnuURRj0whUi2lX4n8L4j8b1MhzP2byHPbe0Ufz2m3i5z11NuFZ3dAGMy8R9ynUid8TEq/8r4PXYhI2XRVi/x3aJpQvASEwWunDzZ4BvFUMOse2PisWPmmzYaPrhfploHincyTRarl27+L3PvE60VANjWLySJu7GD7t9AUkdIJSxf3aUwA5KKRdFi6WGWv+J1Y6at0YgU/XApLroBRS+Dl07zHHWax2h4I5BqDaKLRViLsCrIXiVRP3W9gym1istGH//B3ehzjD+R+/PwYVDpRcPPJTd7j8eNFEC/6TKQCwtJFYU9nFXzzN3GMxiC8RZr3iACo1IqNz/X/FS3htjwHF70ngrHLAd/8A9qLYcwVcN4bsO8joTxJmSEC6uz7RBu5gcbMqbPF/z/pL6LbTlsJXPS+qLQMTRGr5/3LBu9ZcovXsXSI1axMAac+KuxzgxNFnt/UJCae+Q+ICaSnHt4+X6zwL/5gMIg7bOK15z8gngL2fiA2bOf/TejFG3cJw6yBTVGHBT6+XqRkhnsaCYoRTwwHplOG2vPqw+C0x+CNcyDndFGwNMDyO8R3VXDRkX7DxxX+QO7nxMZuFitLjQF0h1kYdLhkLhQNDb5/XATjGXeJ17P1is427eWD3ewHNv1kchF4P7t1sEAnddZg2zalRqQjmvYIl7+XFg6qTL78nVBsNO4Sga14ubjeov8I86z2MpAQm49Oq0hxGGJh1NmizVxHhbhOyszBhtAg1CXpCyBqlLhXh1ncS0SmaCqhChDXaCmG1BnCJ1ylFWobuXIw99/X3u/HfvHgin/OH8SEN9BYo6fRW9kCIvB31x4kkEfDSX8Wn9cAgdG+LdySp8EN68VkeCCbl4p2capj19Tkl4Y/kPs5cWneByv/KpQSMaPh5IfERuaxQh8uZIEjl/R7ayNytRufGgya5auENDA8QzRdTp0NhZ94V3hWrBbBPW6cyG2DkO3Vb/WWCoIwo5p8i7fBlvmPouVZSLJY4e5fDpv+J3Lvo86DjqrB+6H/HpOmiEkjeTqMu1Jo3ZVqiB0DJV+Ljcs1jwye07pfuAx+dN3gWOHHcM6rsO1VcJmFNl4fJipPNy8VTyHf3g8Z8wcDuTFeTD6Se/A6gVHinnsaxH7AgVWeI84UAb30K/Ee0+cOb5AVmtKfxjkAQxzIjq0v/S8Nv2rFz4lJXzt8cI0InpJbSN9eP1usko81+gix8taHAm7voAkiVZIyQyguwlJFgD0QpwMKLhEpj5QZInAO9MMciirA23DKEC8KhAborherb6tJTDBps8Rm54GYmkSuPv8CePtCMUHsfFNo1dNm+TbISJkxuIIfwOUQboi6YLD1CQlk3VbRxm3MZeIYSRKbkQMExYgV9oBfSkCY2APY/gp8eLWwse2qhdYS8WTT2yo+z5AU8fQz5RZRuXowMuZ5t9VTqIQj5aE2rk8A/CtyPycmXdUiKAzF1iN8uY/U7tTWK/LMtl6x6hsuBTDAga3WPPdTJwp3jHFiRbn3fe/fx+SJnPnMe0QQ3/kGTL5JBLDOSrF6zlksNvKKPu1Xechg4YMQGDF4nZ4GmHS9CJ6GOLHCT5gg0i5DCYwU6o+hPisgngR66kRJ/oEM17tAkuD7R4X6JnWWeLpwu0R+XKkRTyrBQ+SGpkYhSzz9KWHI5bQIx8SBDkgNO8RegqVTrOzbSmD32yKFM+VWsTo3t0NQrPgeD1S7RI8Utgq1m8V7iR8/6Ot+AuMP5H5OTNSBvj0gQXikHAl97cKRcKDMPjASLnz34GX7cpXYIOyqGRwbeZYIYOse7T//PbHart04WDjTVQNbXvAuzNn0rCgUaisHtU5UYEpuUQQ05lIR3LRGMcFoAsX/7nzduwgnY77otNNcKOSIAHnni/RGzOhBf/GhtJaIdEv1usEipMbdcNIfRbrH816VItXRUSEaTCdOErn7hIkilRQYIzYhh06cmkCwdEHlWpEq6an3fm1zuwjiAWGiEfXON8S42yXy9bpQseJXqOGsFyD7FO/zO6uEyZgmSHxOP+RvfoLg7xDk58TE7YKNT4tUwQAFl8CC+webJhwOZd8II62hJM+AC9707jo/QOk3Qttdu1Hk6OPGCZ8RS5fIX6fNFhuCKj2EJIrNSKUO3vq/9s47PIpy++PfN5veG0lIg5AChA6h9w6CggUBC1LE7tVrV+xdsXv1XnsHUUGKAhq6gPTeS4BAICGk9zq/P747v5ndnVBkYZPl/TxPHt3Zze47m4czZ77v95wzjlLInnkM/FUlDFqJQ2g9/GwAs/Xdc7jZ6erJzoZH/+LmX4/7uNH6zUjbNfV7Esg5CDQfSWmnLJ/2xuoKjnZb8ID2WhcTHTU11dzQzDnMoBkcB7j5ApVFwPYfeKGM6cLv2OTBTU03L1os05azOrX/0/yuynL5Hj5mCWjbTGDRY0Dfx4ClL2gbo62v53e0fyElkuJs7eKj0mYMLxjFp7nWxKFAZHs+d+YQ/1b5x/jYzRu4bT6zcidBTgiSXFm4mNgvO7IDpQm/xrzFVoN4aS6zUqOeHXqMdOoT64GyAuNAHt0ZWPkanR2BMea2roXAkJeB2K7A3x9Rrz2yisHohq8YwMd8zUnyXe6wdGgc+BPoPIXncWQlgzhAnXzlG6ygXPM+W++61uF/V2o54KH19ayW/G60ttlocudUoJ0/Ae5+QPvxDMw7ZvKiMeQ1YNmLXMOe+fy9gc+yJcEf06hXd5xAm2FFodaO9+Q24KdbgVEfU7P3DAD6T6MzpvlwZuyFJ4Hxs5hBVxRyI3Tu3dr3HpZsG8jDWjIzL8rk401fAbfO5RSio6u0IA7QffPXe8CYL7X+506K3OyUOC8efkDTnsw6EwbSZVKWzyD0+UDgi0HmAFRU93vo9V2Vpn3qbp0qFG6wFmawo6Gq/Z7ey+BbksXugq1v4LDkZS/xohLWgg6SZS9avt+RFZQwolOYfVuTc5gdCT0CWaBjXZIfksjsuOu9vDtIW2HpGDm2hrLRVW+y8nLWzcDPt5r7fv/EcvrBL1HqyD9Gm+DvD7NwqM8jDLapzzLA6nuqAzzf8gK2vXUxAXPMm89LXmDQTr6GttB1H7FIyNWD1kj1+4rswM9VCY4HfMK0IA5QslLloTxdEP//72c/L15OjgzkEuejNA/YNYculUVPAie3a8+lLWcRT24aM8FfJrNQpi4i2wO9H2X2DlATHvScce8TgLfzUQa38uGtGMjS1/Gz133MHiteQZQxAKCyzLh5lasHZZawZNvnTO7M8n2CgdmTWcXYdhzlnNbXc1zbnKmAycS1uRt4qaM6cZTcoVReTHo/wrL/VdN51xDczLIAp6KQG8mr3uKFsKaKMo27blSbZyAw9FVuzB5eRt2810O8EOz5VWt8FRTL/i3tbwYWPsr1Xv8FZRnvUODqD1mcdPUH/O/Gz23XrwbwuD62z3WYYP/6gXqIDOQS52P3HOCXSQxM6z+mbnx6D3XzjV/Yvn7nz3W/l1cgC33uXA1M/gOY8icrFOuitoY6uK9uYk1kR3qlq8qsPvcXBjd1uo1/JHVsFRcTH/uGUwfv/ZClnJM4ROu4mHeEF4XyfAbNke8B8QOZAdfWsJti9j46S6wlobY3ahuvra/nxqVfBPur/PYAG3kJF0t5wuTOOwWV3XMsu0d2uZ2zRA8vY9a8bQYrRcOS+T2kr6PjpbwIaNaX31fvh6idL36C5zH3LmDWTZRmFvyLGny78bbfeeJg/jemCwO+VxDX2uNfPB+V03t58Zk9Bdg913j+ZwNFauQS56Ioi/Mm9VQU0nURlkz7nzVGXQn1uHkAEa3O/hqV4iyWz/d9gpWRSg215/J8eqBdPZl1b/yMurH+ouDuBQx+nlnzsb85vcfDDzi6mlLOwkeBoa/xM5Qa6tC7ZvN3vUMZSFe/y8/yj+LnBcdzis+Wb5hdt7gKmLgIyD3MYqOAKJ5/4hC6WI6t4TCNkGbAkFfYQvbISqD1jbQD7vudslFtDTPnxY9T6vAKpgwz8Dm+r1+UrWR1aAkrWKvLuWG57zdgzh3Usq/5CDiymL9TUcSLR7e7eX6egWzJ27gdP6O8gBcmNy9+nlrk5eHHfZHEwdwg9o/ixRCg7fS7a7UZpTt/oWTU436n6FsuA7nkyiLldvYqUQceuPtys9FeePgCzUcwq13xCj8npgvdFbtmM3DX1nC4clwf25auIQlsmnVyC4N98mja7XxC2TTr8FL60P98mjY9IXjc5MrXqQ6QwgwGu+ZXMcB5BvH1JzYxuC15jlY9tQ97p4ms5FSbb2VsYQbb8wFqzDGdAdSwcMk/AghtQW28z+PMpnf+zPFxHScwmzeawenmza6HzQbQkvjlMG1wR0G6pca9/UfeoQx8nueg7km4RdDt0uEW3hEYTQkyGlqRaTBoeuUb9KWfrS6ggSADucS58AtnNvz7Q9oxD3+tKCQ6hfJI+gYGtJiuLCKxF94hQPLVwE8TtGPHN1ASSBhMPT6iNQN0YAx1ev9IS809cztwaisD/ZGV9MIXngT+eIpj1yI7AXesZJZZnAWc2cdgq+9oCPB3vAIZvEd9BPzxJM83e582ELmqjFp4dGfbDopVZQAEs/Vja3gHkTKRDbKy9nCi/a6fuUHpE8qLwfENlFA63MoMX+866f0IpZ0e5hYDahB3MXEDNnm05d1U4Um+r/XGshDGd1ZnQ7/Bq1JbbXy8ASIDucT5aHUdA+q2mcz82o7VyrqFYIBp3P7Sfb7eVQEAyaPYVvX4BiC2OxDRjt7qRY9z0zBpGO2JoYl8ffFpVkQWZNhOucncQcdHz/sZ4H+4ngFpxLu26/AMAKor6VYpOEHXScokWg2tcXE1D4e2kkPCWgLz7tECf6eJtEiu/ZB7EBFt6ZY5tZ0BX92M3Pod+9C0vJrBMiqFm6rqxqNfBDP0qlLuE+z8me6btmOpt7t60q4Y0ZZrMrJ6Xgjhraidq/3VAV5QjHqzNEBkIJc4H95BdG+0Gu2Yz7ceAtGoBQt9ej7AkvPUpynpdL6dPVoOLObj0R9zky64GTPWtBXcaD2wyPL9Ot5q/h9dMd/W79jSdv3/+NjFxM/b/weliJJsyh5BcbRU6v3WAEv6u9xJTVwlOoX6tL5KdfPX7P29fSYfH17Gwqc2N9hWaa7/hAH43vXUq4uygJIqZtnB8ayQXfMBNXXfcMo8JjdKRUFxPPbtNQzqvR4CkobU7RYyIv84C6HcvPk3mDCPDb6ydrBdQtIwDnR2Ai4qkAshpgO4GkAlgMMAJimKkm+HdUkkDZfITtTJ1XmZJncG55IzwH5zUK4o4sbkwGfpD98zlxt6gTGUgXIOU+6oqeY0+w2fAVAY2P0igeWvccNy2BvA3nmah3vwi7wbcfOmJtzrQdr9tn7Pu5DAWPZiWfqSJm20v4nB9Nhqrqe8gAGzuoLvmzRUWzfAuwk9xVm8ELl62g5gbj2G1sW/PwbWvMtio/5P8bWr3+Eg5sbt2Qtm05fcmG03lm0GTG688AHALxOBsd8zwz8fTu3g3Yo6ai55FL+rkW/zOzU5Vw57sWeTCuBJRVGqhRBvAHgSwOMXvyyJpAHjHwFc8yGQfS97j4Qk8rZ+1XTb1xadYtbrF6H5sD18GczVzo1nDrJvSPe7qYV/NUyTCHb+zMZZJg9unPpFAUvNPvfejzCz3/o9X3tmP1B7FfDXO5zKk3OQATxtOTchE4dww1Op5QZm9/u4odnzAS2Qh5hdMCmTWS1bU0FZplFLzgsd+Dw/L7I915w0lNr7H09q5zz3bl60snZxc3fDBq2Hy8ktDN5XfwAsesTyu9o9lxq/3tppRFU5z0M/L3TPPJb3+1/tdEEcuMhAriiKfndkHYAbLm45EomT4BMC+PTk/5cXcsZkaJKtc8IriFr38De1Tb3Te4Ff79A84gmDODghfT0AhUUzGz/XNjfX/gfoPJVtZg8s5qZqRTGD+7KXtM+qKqN0U2suQEpbyYuFSkURs9byfMopS19k5mwy+8d7P8LnljzHwB2aCCz/kB0Mr3qbxTfu3gz8a95jTxlXD14krMncSZ97ZEe6iPRUFvOn1Crz9/Cl77yqjOceGGNcel9eyDYK1pw5ZHvMSbCnQDQZwKK6nhRC3CGE2CSE2JSdnW3Hj5VIHIg6UPlgKjNnIw78AXw1lB5uvcYb2QGI6Q7cvpQOlfJCtnHd8LkWxAH6r0uygfn3cbDD3t+APo9Rdx7wNLVv30YseS86xY6BjdtSmrAmex8wYT6DeVxvy+cKM6gZL3mOrWarSvn+cX2Am2dTC9/4OTdOD6Wy/WyXqeZxdC8AoQmUUebfp423W/AvetJDErSgGxhLfdozQJNkrPEOsSw4cvdh1enBxcB/ewAfdQYWPKhtwurxCgISh9keDz/PWoAGyDkzciHEEgARBk9NUxRlnvk10wBUA/ihrvdRFOVTAJ8C7H74j1YrkdQnSvPojKku1Yp4Egdx+o6K2mlQUehb7vVvBr6AWPZ/8TcXI5XmUrcuy9Gm/6iojpJ+TzC47l3AoNvrIY5/UzPzkCTg5jksYHLzpcNFLSBa9zGrQ7vdwyCZc5jvM+Rlrs3FjefhHQJM/F3r+V2Wx0rIduNsN13L87WCm9Ic2iFzj/Du4/QeSjRtx/KOo2kvDuAozeGdydy76Kc/udXsgvlAe9/kUdwfuPFbtrt1MVF6MrnRgqmyfQY3lvs/ZVnU42oeJnF6N5Cxmb/f4wFu3jop5wzkiqIMOtvzQoiJAEYCGKg4oieuROIosvcCtZXUiYUfb/WzD3BzM7KjpSMiNIlFLIUn6c5w9+L8yuPr6SAJagrkH6WkEZ1imd0Pep5ukex9DGadb+eFYPtMS+94zgEG7eA4NgRTJwn5R3HS/bE1LOUPjmMr2pbXMMuuLDYXxQhg8ZMsa9/5MzPloa9QAqmt5mP9dCKANkmAG5Y+odThA2P5HoUZ3OBNfVZ7fcIgyjJqn/PcNOrjI97RAnbjDqwHSBpO+2NpHgO2UZ+VHbNYAeodbHm8UXPeReQd4fcdHG9cpOQkXKxrZRiAxwD0VRSl9Fyvl0icirICbs6pMyezzFqwyY2ZcbM+LMjp+wRQdJKVl2qu4xNKeWTRY9r7dbuHQT24GdsJnN7DYpvDyzSppaaKPcDHzuAkH2sKM7i5qA+4nv4MxNXlzPpjewC9HwYW/Jsul7Tl7COuKLQ2FhxnxePaD+gXb9KTdxydJmr2RoDSkIc/g3ifR6nrqzNG9y9ki95fJlmu79ASTrrXc2wtdfjhb/LCdmgJENWB30FwM0CN0cFxtucb1sp2qHJtDb+v3DS2Lghx7iAOXLxr5T8APACkCt7arFMU5a6LXpVE0hCoqaAbot+TWhAHGGxTnwYmLGABTFxvYMaNlra8kjPUs/VZ7qYvGcxXvE4po8MtzOR/NGgUlXOAXQP1kgTAzL6mQnvc80G2fs09TNmky1RKHbHdgXEz2SZ33cfa69f9lwMshAt7lsR05V1GUByz44HPc3BGUDOeW/Z+ykVn9tsOitb7z/WY3GwHMKdMAj7rz7sDgPr5bb9R61eJ7cECocwdfOzhB/R5mAMw9Bxawna86t1Kyu2cbnSu3vMA2wTkHeXnhyYZd4ush1ysayXBXguRSBocrp7Ur63lBoDBoKqEwc7F1bKiUEV1kai/X13Ox0ote52Et2E73vA2zPz1+ITRZtduPCshvYIpueSnA8Hmf5aRHdgOYPV7vNAExQFd7+Bm5bbvac8zCrbp66jzN2oJLHtZO+4fCQx+mTbHefdqdwnuvszIrSk6SYlJv/agOMpGQ15mMzClloOaM7ZpQRygl33PfMtAHtyUgyiydtEp06glG5NZfGYmN1j1ktOmz9lPp2lP2zXqOb4emDFW62HT62Fq617+Z/+9eoDzGSolkstFRBuWnXsY/ENvN56SC0D9tuud1J9VhKDuW16gHYvrRxmgz6O0DwbEsPS93xPsEliez9e1vIZBct9v7ILY9S46XtZ+SGkkrBV93jHdaCFUg3XeEQbmaz/lRSSmCwCDzn8h5lYBm7+yPF54ksH21A5LV01lMeUNVw+tGRkABDblBSesBdsTNG7Pgp7ZUyj1NG7HbDmmG3uqW1NgMCgiIJI/dVGWb9siAbD0lBtRmkupSb3gKgqrXOMHnPsCUA+QgVwi+acERHG+5aFUYPAL9HOX5bKasfX1dJioPUJaX8+NwXX/Zfbc73HAJxyIHwRkbmN3xIRBLMs/spLBNyiWmnf2QeC6z6iZC8EZn6e2UXpZ/AR95wAtesEJjM1pK6ivW2fclSUM4pu/ZiY98Blg92zNs+0VREmlpsq2CRfAro4mA7vgxs+AG74Ets9iMIzvzwtV3hG2BIgfyMKnzB28wBVm8CLl6c+hGCmTWFmq4uoBdJxI6cY7hHsK54NfBCtrT27WjglhrK/rKcujy8Ua67YD9RQZyCWSf8qpnZQNPPzYCCu2O/3kh5cCXwzmYIM+jzJY+YYzK28zhq4WD3MV59jvmE3nHKS7o/AE3RqNmgN7f6c9MSASmDnWUlPufi8lm/GzWILvEcDsMaI1g3duGgO/kdOkooCBqyyPWn3Xu5nZA7zY5B4BNn9hu7np4c9s3d2H56qfrBQ/EPjzGTpEPAOo84e1ZGOqTV/zbqGymPr44Bd5rglD+D4AA/+Id5gFewawz/hvD7LKMyQBGPUf7bUqVWW8Myg+zbsXteCq4820Up7ey4vH8DeNpyvp8Q6hW+bUVsvjDaSplnCEYzAlJUXZtGnTZf9cicRuZGwGvh6hTf3x8AP6PWVZig4AkxdbBqDyQmbqPmGaPfHUds4Q1WfAXe5iAcumL7hZuvZDy/f1jwRu/J4Zo28Ei3FUC17uUWrgu2bzwrHyDe33ut1r1p/nAj3/xb4joQlal8WAGF5Uqsq47uPruKEbnADEpHDqT3kB9fiqMlZlthtP+eGXyZZrFAK45mPKQCte1SyHUR2BYW8ySza5MxgXHOf5e4eyBP/7a3mRUfEKAu5Ywc1cgJ+98XP2ZQfMF7UfOfhi2/f0ogc11c7jfHq0nNwK/HgTJSQXV15MUiZdfOdFOyKE2Kwoio0hXmbkEsk/YfM3lqPbKop4ax4YaylnFGXxv7U1bI6V+iyDVsfbOFwiMIYzRa1lDJMJWP4Ss+YEg1IOr2C6XLaZ+6g07cPuiZXFwMzxdGj0f5oZ8LiZzDRdvRg4o1NYZZr6HIM2QBfJjd8xcO/4Ceg8hWPWams5szRzB9vuqmz8nN70hMHsIW40zCGmG7D7FzpB2t9MiyPAjWDfMH5Pu39lc7FGLRhw848zi9YHcYDfQ366Fsiz99POqVJbzfc6tpbf5c5ftOdc3M4vkEd2AG5fRguoZwDvBIyqY+shMpBLJBdKaa5xaXhpLoNQTASDb02VNgEocwfw/XVaVrr6XaC6GkgeSd3Z3YfVj5UlDEaegZQMwlrSueEbzmIfgJlu5ymWm6dHV1HqyNxFXbrFvQyw8QMY1OJ6AcnXMoMtOM4Mt89jAGq5QVhRyPdf/S7loGUvaReXshwOkLCm5AwDcG01ve7d7wM2fMLfC4kHWo7k5ymK5RSmXo9Qgtr/O38PYKXp8fVAh9sYrF1ctZ4wAC80Xrqin+LTlnZOgIVF8QN4F6MnsoPt2uvCv7FWbduAkIFcIrkQsg8Av94FNB/GTUk9bcYwMCm17ASoKMxCx8+ifKAG8Q63cAPQJ5T9SpKGsdx+7wLexg95mdmgVzBL3H+9k1pzTRVHrcV2oe5srX1n7+MFQ7hwI/PMAfZf6X4vNfA/p9F6CDDDTX2GQXvVdF4oBr/E4FlrtdGZtZMl88etGlFVl3MW6C1zeCdQUcrioUrz3M3FT2rB1tWLwbnNjVxLSZYWxFVKzvBOpCSbTh299XHAM5qbBuCdjMmdnniV8gLO7MzYrE0m6jCB80GdHBnIJZILYftMOiJ8QtgNcMeP3CDs9wSzcA8/4AddE9DiLPYH6fsEH7cZY96I3Mug06wvA5u+S+GxNcCtc4ERb/N3q8rYltXVkz+h8WyVa01IAteibkJ2v4++7coSrksN4iq11VrALs5iAHX3sW1idWgpMOx12vryj7GUvuNE+sDTlnOzNP8IMPce7XdiuzEL3/4jXTzxg3iByTsK7FtAKcjkZispuXnzIlBdDlz3OT/LP4r7BW66ToehScBNs4Cja7hBnL4BGP0RLY23zGEBlKsHvxN3H+5DZGzh+0WlAOHn2PxsYMhALpGcL1VldKQALIPP2MTBwBHtOJwB0OQPPcfXsTuh2vo1N43+8/n/oidc1alVlFpu2oW1AEp0/ufqcv7UVlOTbtKTLo1W1zFgFWWaG1T1Zi/wefeYe680YyDscb/tpqm+Deza94FRH7OfeKdJmo9cCBYfDX6J2blwYX9ytcKyooCOFT3p67gJ2up6yjYrX+fFL6INN3v3L+SUHr1XvXF7fpfpf3PohJs3cN9G24lLAPXyPQvYOMs/Chj2Cu8aAHML4RDttSc2Al+P1O5gPPyBib9pc1ydABnIJZLzxc2LMsip7XxcmsugN0rX7dAo6DTpSSlg/I/c8EwaBix/hc9Vl/N9rXExAbt+5aShvfMtj4e3od3QP4bdBFe9yfeJaMOMv/kI3jl4BjArz9xh3uTswtL62ipeDFqOZP9yDz/KOB4BLOhpN5YbhEnDGIRNbiwsCm/NrF5fqanaG0tzDL4wF16k9B0LvYKAMd8CW7/lHcCAp2l3jOrE9S64X7tzcPXQmnLpqa6ilr/lGz7OPQz8eDM3KqOs9HBFYVtgvQxVUUgZy4kCuXMMrJNILhdtx7L/iEriYDpEVAdL4/Z0eQjzPy3/KHYQ9PBjiXlMZwZSlbTlzKj1ePhRPz+6ihl8q+vMkkoi9faTW4F5dzOzXfaiFqQyd7IQKLQZNeJOtwFLnmUnw20/ALMnA8Nf59SeNmMobzQfwey7SQ8OdD6yEph9O/Dzbezx4hXCIB8cz0rSVqNZaCQE13PdZ7Q5xg+wPAcXV0oh1lORyvJ4JxPZAWgxkvsGXe8Bmg0A/phmKf/0n8aNx5IcZvjHN7ATYnEmM3E9Sq1ltalKbQ03d62xlpkaODIjl0guBM9A9g9p1o/B7MRGeo+nLqc/2isQ6PsIA15FITVqvQuiUQsG0PWfsoGVi4lZ8LgZZg3XlZno2vcp2wgXXjg6TmAlqbsfMGcqA1SZQRZ8ZBWLc9qNp7atd3bUVNETfvQvShM9H6RlTx3EvH0mG2D5NaZk03kKffFn9gOjPmJJf2UxrXwdJzCjLs3hxcvNi+s+mErXSa+HgJw0yyImlepyXswqS5hVd5oM+IUBE+ZyCEfOIaDFCNoRcw4Bc+7URsHF9QdGTKd33jpAexq0SjC5sl3BsTWWx1tdW/ffuAEiA7lEciGUnAbW/9f2eN4xBnKA2XNE67rfo0kPlrPPuV0rjffwY7e/wCZsbdvjAQ5yWDWdmu7QVxjQq8v4uCxPG8GmJ7w13SXxA4DqStvnayq1yTtunloQV9n0JT3f6z5mcdCZ/Ty+9kMWJm2bwUEOK16lZRCg9DL0dWbLA55hoc/8BwAPH6DLnZR+VDwDzOuoAqAAw99iEAdotQxrabmeDZ9pQRwAjiwHjq5lteasm7QLVVQnW6mk+DQ3lX0aAVe9xfFzLm5cv374x+Wi+DR/fELZSsCOyEAukVwIXsG2RT/A2Rs5WaPUUgLRz6SsKGL/k+HTaT/87UFKCQAz+/n3c4PT5EZdec5UBqmkocxiAbN18RVg0aO8CAx91bJ/iRAMdjt/1tZhjdqREbDs8529jxuX/abxYqAGccBcgPMTbY6n91KaqakEyvNYMTrkZa7RP5Kbrn+9w43XqJSzB9SaGsuZouo5CkFZacw3tCz6hvOuQL8/kZfO/uiqgyckgYVRAdG2QyguB+nraCPNO0q5bfR/6ViyEzKQSyQXgl84ZYaZ4ykzCAH0ffLcvTz0FBy3daoADJZrP6CN8cBi2+fT/wZWvcWKyXE/AJm7aaPrchelipB4c1+SjzjQIW0lMOq/nAbk6slqUv2UHdVvrm8fmzIFKMnlnYFfY0omVWXmPiYnGbA73ma7NjWz94vgncPRv1i9GdsFCGvNYL9jFqWovo9TcmrSg3cWWbsZmEMT2WNGxWSivHRio3as17/pf1c7QZrc2Pc90GqTOf1vy14wOYe4QXrtJ4Z/kktK/nFg1i2UogC2VZh1M3DnKjqK7IAM5BLJhRLXB7hzJeUU7xAGHyPnSV0UnaYUsN9qBmbTXmwaVZINhDbnKDk9qpRyfB2w4DADgVFpvG8Y0Hw43TLH1nIiT0E6s/hrP6E8Y/Lg2sfNMI+R2wu0HWeWJ1yAPo/wrmPgc9zkjOsH/DWder5vmO1nth0HLHuFcz5jutICGdudU5IAoPv9QPJoDr3w8KfeX3CC+rd61+DuQ/98TBftfZNHc7Pz9C4goAmLftQgDvACsfZDZveuunJ6VRLSc3ILL1qulzkjLzyhBXGViiJz73j7BHLpWpFI/gkhCRyeHNn+7EG84CSQf4I9S1QCYyhB9Po3b/M9AzgZ6MxBZqabvwQGP29ZmNOsPys1VUqybYODSlk+kHOEzZ92zKLUkv43teHdc+lnhwKc2MT1X/spMPJ9djr8bjTw3TXA0heokXsGMoj7R2pOnD3zqIX7RdDW2Hkqh06PeBtQqjmhJzSJ763i6gaENKMGHhDFYyc2WUo/lSW0OVYUU3baNgP46Rb2iUm+FqitYNMxawozAMWqsEj1lOtpdS3tj5cbr2B+T3qECy+kdkJm5BLJ2aitYfDw8KW+eSiVkkbiYPNk+Dr6ZJcXADt+NvcsqWBGmjKFFZkBUayGTH0OuOod4MR6Bke193V1BeDbGLhjJSUYFzdWkKraNkCtVx1cYY3Jg9ZD/WbgiU3c5IzrR8kkcTCDnWcAN+DmTKVTBaBcFJ4MLH4cOLiYMshVb3IDduXrtD/mHuEQiyY9GfQ3fsb1jJ3BQia1Ta8R+enaSDVrTu8BKkqAw6mcQqSSvpZj5oTBIIzOtwOVZZaafkxX9pJZ8y6z9qThdNoY/f6lJiSBm7O/PagdG/Q8EJJU129cMDKQSyR1ceYgXRz7FwFNutP7nPocN/K2fc9ZnX0e09rR6jn2N7DwYe3xqjeZwXaewscxndmLvPQMe47oBxi0G0/nh6c/g2J1JbXkA4upV/s0on/byPlwdDXw0wS2X7VuKpW+jheUvHT+v19jvkdFkaV7JWEQs+pja/k4N417AlOWUcfeNYeunOjO1HrVqUDFWbRNDnwO8Egw/k4zNnN+ackZvs6aVtfTf/73fyyPK4r5AnAEGPQCrZJVpWwVcGgpW/UOe409zt08eKfT93Gg7Y38ewU2OfvF5VLiYuLftHE7ykn+jbmnom85cJHIQC6RGFGax94hJ8zOkbwjwJG/OGxhw6c8tvodFggZTZ9RnSR6tnzLzTvvUEoNain5gKfpPsncBUS0YgWm3hPt6s7PadKDwdI/0riCtPAke4KX5hhbE/0jOe9SuAA7ZgJ75wJTUumiaNqHBUgAA86qtyx/t6YKyEsD2tzAH4AtefWj3QC+/7HV3Hi1zn4rioDFT2ktag8toZd94+fUrpuPALrdxfP1CLBdv08jXlTzTwC3/sr1pj6rSUyzbgEm/6E1yTK58sJTH3DzpD1VtajaGRnIJRIj8tK0IK6itn9Vqa3WOhpaE2KwiRUYSwtaYAynB6kODb9wlsu3HKm9tqaKAcrkwRL7rT8Ann7M7PzqsDoWZWm9XrJ2AYlD2BMGYFbY7V7aAffM5bGqMnO7AXNb3OpynnNNNc/TemC0ZwBQVgCc2QeUF3GivTVNenCyUesbbDPgsnzL7/TYGn6nY75ixhwQzQ1PAOj7GPDD9dpdhYc/9yI6T2aVqXDlBaHjbQz8pbkcQl1yBljwAFCYCXSawE1Xo0IhJ0MGconECJMHM0preULoZJSOkxiAjEgcAvxtno4D0OYX25Vl6AB19lt/BbwNNt9yDtOJsXcBZ3su1E2o3/odMHERpRlrfEK1ALxnHisw+09jtalfYza+Wvk6rXgq7n50c/z5DKf8DHqBXm+vAGDJC9rrmo9gxebixylrAMDoT4Aud7D/d20N9wx8I7gGNSDr8Q5meX/acu1Yfjo3dfW2Q4AWy5Hvc21uXryL+ett+s+ThlJOWfKs9vcJa0kP/ezJ2l3CwcXsoNh2jO1anAwZyCUSI0LigZSpwMZPtWOJQ+niaNweaDeOgVJvedPTqDkw6Xf2PykvoOyhlytObaVcYx3IK0spF+z7jW0Ads22fL6milq5USAPjKG98OfbmG3v+532tr3zuY5xMyyDuFcQuzL+chsD4r7f+ROaCLQZC0xaRO3cO5TZ96ntWhAHKM0kDGF1ZnEmnz+8DLj6feNNRXcfYMhLlEDyjvLCM+glIKK97WtdBC8QRZkMzKrlsDSX39Gf0ywvsvnH+Z7WUs+q6UDSEK2i1EmRgVwiMcLNC+j7KD3jJzez9D22OzPbThOpeZ6L4Gb8SV/Hykw9Libj9yg8wSAOADC4IwAAnGXObuIQYIp5o7Isl5n56T18rroSuOknYM98yjwtRtB9Yv0ZZw7y7qFJD8vKywOZ/L34gXzvA4v5vfhGUEZpMYJ+7rCWdMK4edvKKxFtgCl/cq7oiQ3cNM5PB9pcb6lnu3kz21edK+1v5rQlnzCuz91641KxvFtSEYLfo5MjA7lEUhe+YUDy1fzR43IeQVxPoxYsbFG1aYAaebCBs8PkST24opAacv9plpN5XExsL2tEbQ3L+rf9QHkltptlcAuIYrFN0lDtmL6qU8U3jDq0NaGJnNG5dz5fM/BZykC9HmZlqZs3paTlr1ICCooDBkyjRVGfobv7speL+n0cW8PmXWO+BqAwcw9qwvO8ajqbb53axvMC+F4j3qO0Ul7AY9XltByqlagqfR+7IjRyoRhe8S8tKSkpyqZNm879QonEWSjMBDI20soXlkz3Ql0FIZu/ARb8i/8f1cncyXAJ5YFOkxiMXQz6dKevB74ebrkBO+RlYMnzHMTcZapthlxRxN4nq9/hY5MbMPYHy2APMGtf8RptfirCBbh1nla9WVPFPYANujJ4kzswYZ5lZn9qJ/BJL9v1D3kJOHOIAX7YG+wg6eYF7FvIlrp6/CN5kVv8BOAfzaZicX0p7+yYRU98h5t5EfHws/2sBooQYrOiKCnWx2VGLpFcDvwjAP/zmOQO0PEREg+c3kdHS2RHBuFzsWeerYsmbQVw91puyhpJOR5+QO+HKYuUZFO6MHLFFGex6EePUkvNXQ3kRadYlaqnppLe9uBmmu+9rqKcyhIG6PICYO5dLKSJ6Wx811B0CojtAdyznncC6l5DdCf+XGHIQC6R1Dc8fOgAaWqQtZ4NxcAKqSiUSUxn+adeXmguTFoKbPmOLpIBT7OYRt0kdPVkkNd3bAQsZQuTO1+v+sT/fw21nOKjBvLgZhxsoa9UDUvmhrC+yCn3MAN5aBKzf323xpajGPTPZ69CT0GGeZ6nF9AoyWk2QWWvFYnEWUgebbvh1+2eswfxylLKKkfXsPd3dTkdIgsfsewe6BUIDH7RMpsOampZ4OIXwTJ6PSEJ1Ov15fPu3kD/Zyj3xA8Eut7FJl87Z1uuX23OFd6aY/ICYvh8q2vZ6+VCg3jmLuDLocA3VwNfDAJ+e4iSlxNgl4xcCPEwgLcANFIU5cy5Xi+RSC4B0SkcTrHpK3Y4TJl87gEKuYdZlKNvEaCyey6Lg6I6say8WX9g0h9st+vuCzRuy8BaWaL5xpuPAEYJ2h09/eldLy8AQqwqLIObMCt39wW2fM1sf9CzmgY/4DlaCTd+yQtGdBfgjuX8LL/GlkOjz4fqCl6w9FOFdv1CHf58Ja96zEUHciFEDIAhANLP9VqJRHIJMbmxqKdpz/P/ndpa6t8B0Qy+eryCaP9rM4abiSU5dKWU5TH7/mUSfyd+IDcqw1sBPsG0QPqGA1l7gMYdqFkb9TkJbgp0vZPWQ3cf2hD9o/i7O2YBy3QFSb3+DfR9gmX6/4TyQq13jJ7s/awHOBu1tfT811QAAbGO69lyFuwhrbwL4DGc1dwqkUjqJSHNWPDTtJelN9s/muPietxHS2NuGtvh/jyRTpfZU7TAf3gpMHsqAz1ASSRxMNDrAaDFVVqXxoITwI6fgEWPAzt/AQpPseGYbxgDeVhLBlUXV8sBGADHtOmLmS4Ur0BaJ60Jb3X23ysrBP7+CPhfT+Dj7uxlo5+OVE+4qIxcCDEKQIaiKNvFOdpDCiHuAHAHAMTGxl7Mx0okzkdVOXuUF6SzwCY8+fLY5jz8OM9y/0Lg2v8xQ/UKolPkx5u4gdrhVm5EqoVKQjCY6zm9m2v3MbBUlhcyCK+azs8B2Pu87XhgxFu2GW5lie17KIrx8fPF5MaL0qmtvAAJwclK0TZOPksyNgGpT2uPD/5BqWfYa8YWUAdxzkAuhFgCwGhS6DQAT4GyyjlRFOVTAJ8C9JFfwBolEuemtpYOjvn3acf6PcW+Iu7edf+evQhuCnS/B9j0NYt9gprSyqiy+Wv2MVcxGbQlcPU0qLYEXS7LXzF3Llxo+dyOmex2qB9AAbCbpF8Ey/NVguK4zouhUXP63vOOcL0hCefeMM3cYXtsz69A70e0odH1gHNKK4qiDFIUpbX1D4A0AHEAtgshjgKIBrBFCGHf8dASibOjyhZ6VrxqORHocpB3hD3Xj62xfc7kSv0aYKVpy2ssnx/8gnE1aOYOyiRGg54BFhFZExDNVgLxg+h2SRoOjP2+7kEaF4JPCLPwiNbn53oJMmiKFt623unk/1haURRlJ4D/vySZg3mKdK1IJBdIeb5lWbmKtR/7UtO0J7D6PSC8jWWHQoDulJtm8fn0v9lioN14rj0ojj1UjAZsFJnb6hZnMQPW69yRHW1nVuYeBfb/DuxbBHS4BRjyIhDUDHC/gJmo9iS6s2Wvdg9/jsy7HHdKF4AsCJJIHE1ANLNdvQXQzds4G7yURHcFkkdRj87apQ1saHkNg65/Y2D0x+wD4xl0dn+6inoOW7/jRKUzBzgqLnEom4/pNfWyAk5VOrSEj4/9xUA6/kfHBfKAaOCGL7h/UVnCIqKQOqYfORDZa0UicRQVRSxSKTzJXt0LH+WMTv9IYNRH9G07YsZk/glm2sVZdJM0akHXxz+hsoRDlP98msVGCYPYx72mEojvb9nGN2ML8Fl/2/eYvJidJyWy14pEUq+oruI80NRn+djVExj5LqsYfcLYm8WeFGWxMMcvwrKsvvAUOwuW5bEUPqItEBgNbnm1vvjPdffh0OnQRPZcKcwAZk+kNj7mGxbknBPnb0N7schALpE4gtxDwNIXtcfV5cDcu4E7Vto3iNfW0Oe94AFm/jHdgJFv84JRlMnRc0dW8rVCAGO+BZKvOft7XiguLqw21bfxBYAtVoE8JIEbmwcWacdiuttWhV5Oamvqlc2wLmQgl0gcQXkhZ37aHM+37+dk7wNmjtc+6/g6YO59wIS59FOrQRygNr7oUbbJ9bPzHUFAjO0x6zF5nv7A8DdYKXrwTyC+H3uwGHnTLzUZW2i7zDkMdLqNxVE+oZd/HeeJDOQSiSMIMg8bLjihHfMKogPEnuSm2V4wTm2lxGF00SjOAqpK7bsGAGhzA7D5K60lrZs3C42sCWoCdJ3Kn7qoruCF0Dv40mTLWXuAb0ZqBUjHVvMC0/Uu7TV56UBVMStg68HgChnIJRJH4BdBb/Tvj7B6MKINMOJt+ztVvIINjgXRRheaxNFsiYMoIVQWA4FxzEa3zeBs0pguWhfCiyGyPTAlFcjYTE95VCd6uS+UUzs4hPnERqDFSI6DC7Wzi+TUdtsq0lXT2V3SM5AS0aLHuOcQ3QW4+gMgvKV913CByEAukTiKyA7ALXOA0hwGV+tBzPYgvBXQ8Tbq0QB18Kve5qBmd19O0Fn5BmWVdjcBucstNequdwGDXrjwlrGGa0nmzz8lLx34/jrNFrnhE84jHTfDvlmxkR/exZXfXdZO7iuonNhAR87Yb7UOkA5ABnKJxJF4BfDnkr1/IDDoeUobxdlskhVmbhSVtQtY+7722qAmwPYZlr+/4ROg44RzN5e6HOQc0IK4ytG/gLyjbKlrLxq3Z+atl576PcXK0sMrbF9/eAldQSHNbJ+7TMhALpE0VBSFPvSsnezP3bidcbGKdzAQ18f2eL5V5+m6JgxVl9tnvReLq0FRkIsrJxPZk0bN2dd9z1xWmra+TmsNbNRGNyjO4Tq5DOQSSUPl+Abg26u5+Qdw4MKEeQxE50OgVRfS8gLbCtOoFJbI1wcaNWcr2kOp2rGeDxr3eLlYGrfhj9Hx1jdwKAXAi8jIdx3uaJGBXCJpiFRXsEe3GsQBDiROW3H+gTyiLdDnMeCvt7gBuX8hcP0X1NOPraGnu8vUS6Pd/xN8QoGr32fTrjMHtM1YV4NujJdsDY2Aq6YDKZNYRBUSD4S2uHyfXwcykEskDZGaSnYrtEY/yuxceAUAfR5mf5XyAravDYhiFl5ZxMHE9a0YJiAKCLjOsWvwDr7wwdiXGDl8WSJpiHj4cSanNfEDL+x9XD1pA2zak0ESYIZ7qTzakkuCzMglkoZKy2uAsnzg7//Q+jbweXYLlFxxyEAukdQHSnOpS+/7HQhtztL0sHNor34RQJ9H2bfbxdU+hTuSBokM5BJJfWDbDODPadrjDZ8CkxZy7NnZEIJtbyVXNDKQSySOpuA4sOI1y2NFJ9nU6lyBXKJRcoaWzIxN7KEe250VrFcAMpBLJI6mVjHuhGhUoCMxprqKewWr39WOxfXjdJ963LXQXkjXikTiaAKige73WR7zDNRK6a9EqsuBzN1sjnU+s0vz0oC1H1oeO7ICOL3vkiyvviEzconE0bi4AJ2nMqBv/Y7Dj1MmcT7klUhpDrDmA2DtByxUatQSuOErThmqqTBuTlVdaXxXU1Nhe8wJkYFcIqkP+EcweLe/GTC5OWZWZ33h5FZWrapk7wVWvcEKyn3zgbbj2P8kIFp7TXBToNkAIG2Zdsw3jMH/CkBKKxJJfcLV/coO4gCQfcD2WNoKoDQbyNoNpD4DrH6PuriKhx8w4i2gx/2sUG0zli2CrfvJOCkyI5dIJPULI6dO43ZA9n7t8eavgG53s9eJSkg8MOhFoNdD7LXuaueuiPUYmZFLJJL6RVQnSkwqfhFA4hD2HlcxubMIyhoXF7YXuIKCOCAzcolEUt/wDQOGvcFeMpUlfDz7dsvX9H38ipFNzgcZyCUSSf3D0w+ITtEej/kGSFsOZO/jRPvY7nIvQYcM5BKJpP4TmmD/IctOhNTIJRKJpIEjA7lEIpE0cGQgl0gkkgaODOQSiUTSwJGBXCKRSBo4MpBLJBJJA0coinL5P1SIbADHrA6HAjiPfpUNFmc/P0CeozPg7OcHNOxzbKIoSiPrgw4J5EYIITYpipJy7lc2TJz9/AB5js6As58f4JznKKUViUQiaeDIQC6RSCQNnPoUyD919AIuMc5+foA8R2fA2c8PcMJzrDcauUQikUj+GfUpI5dIJBLJP0AGcolEImng1LtALoS4XwixTwixWwjxpqPXcykQQjwshFCEEKGOXou9EUJMN//9dgghfhVCBDp6TfZACDFMCLFfCHFICPGEo9djb4QQMUKI5UKIPeZ/ew84ek2XAiGESQixVQjxm6PXYk/qVSAXQvQHMApAO0VRWgF4y8FLsjtCiBgAQwCkO3otl4hUAK0VRWkL4ACAJx28notGCGEC8BGA4QCSAYwXQiQ7dlV2pxrAw4qiJAPoBuBeJzxHAHgAwF5HL8Le1KtADuBuAK8rilIBAIqinHbwei4F7wJ4DIBT7jIrivKnoijV5ofrAEQ7cj12oguAQ4qipCmKUgngRzDhcBoURTmlKMoW8/8XgcEuyrGrsi9CiGgAIwB87ui12Jv6FsiTAPQWQqwXQqwUQnR29ILsiRBiFIAMRVG2O3otl4nJABY5ehF2IArAcd3jE3CyIKdHCNEUQAcA6x28FHvzHphE1Tp4HXbnso96E0IsARBh8NQ0cD3B4K1dZwA/CSGaKQ3II3mO83sKlFUaNGc7R0VR5plfMw28Xf/hcq5NcnEIIXwBzAbwoKIohY5ej70QQowEcFpRlM1CiH4OXo7dueyBXFGUQXU9J4S4G8Acc+DeIISoBRvcZF+u9V0sdZ2fEKINgDgA2wWHxkYD2CKE6KIoSuZlXOJFc7a/IQAIISYCGAlgYEO6CJ+FDAAxusfR5mNOhRDCDQziPyiKMsfR67EzPQFcI4S4CoAnAH8hxPeKotzi4HXZhXpVECSEuAtApKIozwohkgAsBRDrJMHAAiHEUQApiqI01C5shgghhgF4B0BfRVEazAX4bAghXMGN24FgAN8I4CZFUXY7dGF2RDC7+AZArqIoDzp4OZcUc0b+iKIoIx28FLtR3zTyLwE0E0LsAjeUbnPGIO7k/AeAH4BUIcQ2IcT/HL2gi8W8eXsfgD/ATcCfnCmIm+kJ4FYAA8x/t23m7FXSAKhXGblEIpFILpz6lpFLJBKJ5AKRgVwikUgaODKQSyQSSQNHBnKJRCJp4MhALpFIJA0cGcglEomkgSMDuUQikTRw/g/cxGsbGNQrUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(x=X_train[:,0], y=X_train[:,1], hue=y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f3591db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = tf.convert_to_tensor(np.float32(X_train), dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "X_test = tf.convert_to_tensor(np.float32(X_test), dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2dacca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Dense(4)\n",
    "dense2 = Dense(1)\n",
    "model1 = Model([dense1, dense2],name='model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cfc0d14c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dense' object has no attribute 'w'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-e934ecf133a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdense1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'w'"
     ]
    }
   ],
   "source": [
    "dense1.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2697cdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: \n",
      " Loss value: 1.0052329301834106, train accuracy: 0.249, test accuracy:0.241\n",
      "Epoch 2: \n",
      " Loss value: 1.0025919675827026, train accuracy: 0.253, test accuracy:0.244\n",
      "Epoch 3: \n",
      " Loss value: 0.9999666810035706, train accuracy: 0.254, test accuracy:0.246\n",
      "Epoch 4: \n",
      " Loss value: 0.997357189655304, train accuracy: 0.255, test accuracy:0.247\n",
      "Epoch 5: \n",
      " Loss value: 0.9947631359100342, train accuracy: 0.256, test accuracy:0.248\n",
      "Epoch 6: \n",
      " Loss value: 0.9921845197677612, train accuracy: 0.256, test accuracy:0.252\n",
      "Epoch 7: \n",
      " Loss value: 0.989621102809906, train accuracy: 0.258, test accuracy:0.257\n",
      "Epoch 8: \n",
      " Loss value: 0.9870727062225342, train accuracy: 0.259, test accuracy:0.257\n",
      "Epoch 9: \n",
      " Loss value: 0.9845392107963562, train accuracy: 0.26, test accuracy:0.26\n",
      "Epoch 10: \n",
      " Loss value: 0.982020378112793, train accuracy: 0.261, test accuracy:0.267\n",
      "Epoch 11: \n",
      " Loss value: 0.9795160889625549, train accuracy: 0.265, test accuracy:0.271\n",
      "Epoch 12: \n",
      " Loss value: 0.9770262241363525, train accuracy: 0.268, test accuracy:0.273\n",
      "Epoch 13: \n",
      " Loss value: 0.974550724029541, train accuracy: 0.271, test accuracy:0.276\n",
      "Epoch 14: \n",
      " Loss value: 0.9720892310142517, train accuracy: 0.272, test accuracy:0.277\n",
      "Epoch 15: \n",
      " Loss value: 0.9696417450904846, train accuracy: 0.278, test accuracy:0.284\n",
      "Epoch 16: \n",
      " Loss value: 0.9672081470489502, train accuracy: 0.281, test accuracy:0.288\n",
      "Epoch 17: \n",
      " Loss value: 0.9647880792617798, train accuracy: 0.283, test accuracy:0.296\n",
      "Epoch 18: \n",
      " Loss value: 0.9623817205429077, train accuracy: 0.288, test accuracy:0.297\n",
      "Epoch 19: \n",
      " Loss value: 0.9599886536598206, train accuracy: 0.291, test accuracy:0.301\n",
      "Epoch 20: \n",
      " Loss value: 0.9576088786125183, train accuracy: 0.294, test accuracy:0.302\n",
      "Epoch 21: \n",
      " Loss value: 0.955242395401001, train accuracy: 0.295, test accuracy:0.304\n",
      "Epoch 22: \n",
      " Loss value: 0.9528887867927551, train accuracy: 0.299, test accuracy:0.305\n",
      "Epoch 23: \n",
      " Loss value: 0.9505480527877808, train accuracy: 0.305, test accuracy:0.308\n",
      "Epoch 24: \n",
      " Loss value: 0.9482200741767883, train accuracy: 0.31, test accuracy:0.312\n",
      "Epoch 25: \n",
      " Loss value: 0.9459047913551331, train accuracy: 0.314, test accuracy:0.319\n",
      "Epoch 26: \n",
      " Loss value: 0.9436019062995911, train accuracy: 0.316, test accuracy:0.324\n",
      "Epoch 27: \n",
      " Loss value: 0.9413116574287415, train accuracy: 0.32, test accuracy:0.328\n",
      "Epoch 28: \n",
      " Loss value: 0.9390335083007812, train accuracy: 0.325, test accuracy:0.33\n",
      "Epoch 29: \n",
      " Loss value: 0.9367674589157104, train accuracy: 0.327, test accuracy:0.334\n",
      "Epoch 30: \n",
      " Loss value: 0.9345135688781738, train accuracy: 0.33, test accuracy:0.336\n",
      "Epoch 31: \n",
      " Loss value: 0.9322715997695923, train accuracy: 0.337, test accuracy:0.339\n",
      "Epoch 32: \n",
      " Loss value: 0.930041491985321, train accuracy: 0.34, test accuracy:0.348\n",
      "Epoch 33: \n",
      " Loss value: 0.9278230667114258, train accuracy: 0.344, test accuracy:0.352\n",
      "Epoch 34: \n",
      " Loss value: 0.9256162047386169, train accuracy: 0.35, test accuracy:0.354\n",
      "Epoch 35: \n",
      " Loss value: 0.9234209060668945, train accuracy: 0.353, test accuracy:0.354\n",
      "Epoch 36: \n",
      " Loss value: 0.9212368726730347, train accuracy: 0.359, test accuracy:0.356\n",
      "Epoch 37: \n",
      " Loss value: 0.9190642237663269, train accuracy: 0.359, test accuracy:0.36\n",
      "Epoch 38: \n",
      " Loss value: 0.9169028401374817, train accuracy: 0.362, test accuracy:0.361\n",
      "Epoch 39: \n",
      " Loss value: 0.9147524237632751, train accuracy: 0.363, test accuracy:0.364\n",
      "Epoch 40: \n",
      " Loss value: 0.912613034248352, train accuracy: 0.367, test accuracy:0.367\n",
      "Epoch 41: \n",
      " Loss value: 0.9104845523834229, train accuracy: 0.37, test accuracy:0.369\n",
      "Epoch 42: \n",
      " Loss value: 0.9083669185638428, train accuracy: 0.376, test accuracy:0.374\n",
      "Epoch 43: \n",
      " Loss value: 0.9062598943710327, train accuracy: 0.377, test accuracy:0.377\n",
      "Epoch 44: \n",
      " Loss value: 0.9041635990142822, train accuracy: 0.382, test accuracy:0.381\n",
      "Epoch 45: \n",
      " Loss value: 0.9020776152610779, train accuracy: 0.387, test accuracy:0.384\n",
      "Epoch 46: \n",
      " Loss value: 0.9000023007392883, train accuracy: 0.39, test accuracy:0.386\n",
      "Epoch 47: \n",
      " Loss value: 0.8979371786117554, train accuracy: 0.393, test accuracy:0.391\n",
      "Epoch 48: \n",
      " Loss value: 0.8958824276924133, train accuracy: 0.396, test accuracy:0.393\n",
      "Epoch 49: \n",
      " Loss value: 0.8938376903533936, train accuracy: 0.397, test accuracy:0.398\n",
      "Epoch 50: \n",
      " Loss value: 0.8918031454086304, train accuracy: 0.399, test accuracy:0.4\n",
      "Epoch 51: \n",
      " Loss value: 0.8897786140441895, train accuracy: 0.402, test accuracy:0.404\n",
      "Epoch 52: \n",
      " Loss value: 0.8877639174461365, train accuracy: 0.406, test accuracy:0.409\n",
      "Epoch 53: \n",
      " Loss value: 0.885759174823761, train accuracy: 0.409, test accuracy:0.413\n",
      "Epoch 54: \n",
      " Loss value: 0.8837641477584839, train accuracy: 0.409, test accuracy:0.416\n",
      "Epoch 55: \n",
      " Loss value: 0.8817788362503052, train accuracy: 0.41, test accuracy:0.417\n",
      "Epoch 56: \n",
      " Loss value: 0.8798030018806458, train accuracy: 0.412, test accuracy:0.421\n",
      "Epoch 57: \n",
      " Loss value: 0.8778367638587952, train accuracy: 0.414, test accuracy:0.422\n",
      "Epoch 58: \n",
      " Loss value: 0.8758800029754639, train accuracy: 0.414, test accuracy:0.427\n",
      "Epoch 59: \n",
      " Loss value: 0.8739326596260071, train accuracy: 0.415, test accuracy:0.43\n",
      "Epoch 60: \n",
      " Loss value: 0.8719944357872009, train accuracy: 0.417, test accuracy:0.432\n",
      "Epoch 61: \n",
      " Loss value: 0.8700656294822693, train accuracy: 0.419, test accuracy:0.433\n",
      "Epoch 62: \n",
      " Loss value: 0.8681459426879883, train accuracy: 0.422, test accuracy:0.434\n",
      "Epoch 63: \n",
      " Loss value: 0.8662353754043579, train accuracy: 0.423, test accuracy:0.437\n",
      "Epoch 64: \n",
      " Loss value: 0.8643336296081543, train accuracy: 0.425, test accuracy:0.439\n",
      "Epoch 65: \n",
      " Loss value: 0.8624410033226013, train accuracy: 0.429, test accuracy:0.445\n",
      "Epoch 66: \n",
      " Loss value: 0.8605573177337646, train accuracy: 0.433, test accuracy:0.447\n",
      "Epoch 67: \n",
      " Loss value: 0.8586823344230652, train accuracy: 0.436, test accuracy:0.45\n",
      "Epoch 68: \n",
      " Loss value: 0.8568161129951477, train accuracy: 0.436, test accuracy:0.452\n",
      "Epoch 69: \n",
      " Loss value: 0.8549585342407227, train accuracy: 0.44, test accuracy:0.454\n",
      "Epoch 70: \n",
      " Loss value: 0.8531096577644348, train accuracy: 0.441, test accuracy:0.454\n",
      "Epoch 71: \n",
      " Loss value: 0.8512693047523499, train accuracy: 0.444, test accuracy:0.456\n",
      "Epoch 72: \n",
      " Loss value: 0.849437415599823, train accuracy: 0.445, test accuracy:0.457\n",
      "Epoch 73: \n",
      " Loss value: 0.8476139903068542, train accuracy: 0.446, test accuracy:0.459\n",
      "Epoch 74: \n",
      " Loss value: 0.8457989692687988, train accuracy: 0.449, test accuracy:0.46\n",
      "Epoch 75: \n",
      " Loss value: 0.8439922332763672, train accuracy: 0.452, test accuracy:0.463\n",
      "Epoch 76: \n",
      " Loss value: 0.8421938419342041, train accuracy: 0.455, test accuracy:0.467\n",
      "Epoch 77: \n",
      " Loss value: 0.8404035568237305, train accuracy: 0.457, test accuracy:0.47\n",
      "Epoch 78: \n",
      " Loss value: 0.8386213183403015, train accuracy: 0.459, test accuracy:0.472\n",
      "Epoch 79: \n",
      " Loss value: 0.8368473649024963, train accuracy: 0.465, test accuracy:0.474\n",
      "Epoch 80: \n",
      " Loss value: 0.8350812792778015, train accuracy: 0.467, test accuracy:0.475\n",
      "Epoch 81: \n",
      " Loss value: 0.8333232402801514, train accuracy: 0.469, test accuracy:0.477\n",
      "Epoch 82: \n",
      " Loss value: 0.8315731287002563, train accuracy: 0.472, test accuracy:0.477\n",
      "Epoch 83: \n",
      " Loss value: 0.8298307657241821, train accuracy: 0.473, test accuracy:0.48\n",
      "Epoch 84: \n",
      " Loss value: 0.828096330165863, train accuracy: 0.474, test accuracy:0.481\n",
      "Epoch 85: \n",
      " Loss value: 0.8263696432113647, train accuracy: 0.476, test accuracy:0.484\n",
      "Epoch 86: \n",
      " Loss value: 0.8246505260467529, train accuracy: 0.476, test accuracy:0.486\n",
      "Epoch 87: \n",
      " Loss value: 0.8229390978813171, train accuracy: 0.477, test accuracy:0.488\n",
      "Epoch 88: \n",
      " Loss value: 0.8212353587150574, train accuracy: 0.477, test accuracy:0.488\n",
      "Epoch 89: \n",
      " Loss value: 0.8195390701293945, train accuracy: 0.477, test accuracy:0.489\n",
      "Epoch 90: \n",
      " Loss value: 0.8178503513336182, train accuracy: 0.479, test accuracy:0.489\n",
      "Epoch 91: \n",
      " Loss value: 0.8161690831184387, train accuracy: 0.479, test accuracy:0.49\n",
      "Epoch 92: \n",
      " Loss value: 0.8144951462745667, train accuracy: 0.482, test accuracy:0.491\n",
      "Epoch 93: \n",
      " Loss value: 0.812828540802002, train accuracy: 0.483, test accuracy:0.493\n",
      "Epoch 94: \n",
      " Loss value: 0.8111693263053894, train accuracy: 0.485, test accuracy:0.493\n",
      "Epoch 95: \n",
      " Loss value: 0.8095172643661499, train accuracy: 0.488, test accuracy:0.495\n",
      "Epoch 96: \n",
      " Loss value: 0.8078725337982178, train accuracy: 0.488, test accuracy:0.497\n",
      "Epoch 97: \n",
      " Loss value: 0.8062348365783691, train accuracy: 0.489, test accuracy:0.497\n",
      "Epoch 98: \n",
      " Loss value: 0.8046042919158936, train accuracy: 0.49, test accuracy:0.499\n",
      "Epoch 99: \n",
      " Loss value: 0.8029808402061462, train accuracy: 0.494, test accuracy:0.499\n",
      "Epoch 100: \n",
      " Loss value: 0.8013644814491272, train accuracy: 0.495, test accuracy:0.501\n",
      "Epoch 101: \n",
      " Loss value: 0.7997549772262573, train accuracy: 0.496, test accuracy:0.502\n",
      "Epoch 102: \n",
      " Loss value: 0.798152506351471, train accuracy: 0.498, test accuracy:0.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103: \n",
      " Loss value: 0.7965568900108337, train accuracy: 0.499, test accuracy:0.503\n",
      "Epoch 104: \n",
      " Loss value: 0.7949681878089905, train accuracy: 0.499, test accuracy:0.506\n",
      "Epoch 105: \n",
      " Loss value: 0.7933861613273621, train accuracy: 0.499, test accuracy:0.508\n",
      "Epoch 106: \n",
      " Loss value: 0.791810929775238, train accuracy: 0.5, test accuracy:0.509\n",
      "Epoch 107: \n",
      " Loss value: 0.7902425527572632, train accuracy: 0.5, test accuracy:0.51\n",
      "Epoch 108: \n",
      " Loss value: 0.7886806726455688, train accuracy: 0.501, test accuracy:0.512\n",
      "Epoch 109: \n",
      " Loss value: 0.7871255874633789, train accuracy: 0.502, test accuracy:0.512\n",
      "Epoch 110: \n",
      " Loss value: 0.7855771780014038, train accuracy: 0.502, test accuracy:0.513\n",
      "Epoch 111: \n",
      " Loss value: 0.7840351462364197, train accuracy: 0.503, test accuracy:0.513\n",
      "Epoch 112: \n",
      " Loss value: 0.7824997305870056, train accuracy: 0.503, test accuracy:0.513\n",
      "Epoch 113: \n",
      " Loss value: 0.7809706926345825, train accuracy: 0.503, test accuracy:0.514\n",
      "Epoch 114: \n",
      " Loss value: 0.7794482707977295, train accuracy: 0.504, test accuracy:0.514\n",
      "Epoch 115: \n",
      " Loss value: 0.7779321670532227, train accuracy: 0.504, test accuracy:0.515\n",
      "Epoch 116: \n",
      " Loss value: 0.776422381401062, train accuracy: 0.506, test accuracy:0.515\n",
      "Epoch 117: \n",
      " Loss value: 0.7749190926551819, train accuracy: 0.508, test accuracy:0.515\n",
      "Epoch 118: \n",
      " Loss value: 0.7734220027923584, train accuracy: 0.509, test accuracy:0.516\n",
      "Epoch 119: \n",
      " Loss value: 0.7719311714172363, train accuracy: 0.51, test accuracy:0.516\n",
      "Epoch 120: \n",
      " Loss value: 0.7704465389251709, train accuracy: 0.51, test accuracy:0.517\n",
      "Epoch 121: \n",
      " Loss value: 0.7689681649208069, train accuracy: 0.511, test accuracy:0.517\n",
      "Epoch 122: \n",
      " Loss value: 0.76749587059021, train accuracy: 0.512, test accuracy:0.517\n",
      "Epoch 123: \n",
      " Loss value: 0.7660297751426697, train accuracy: 0.512, test accuracy:0.518\n",
      "Epoch 124: \n",
      " Loss value: 0.7645696401596069, train accuracy: 0.512, test accuracy:0.519\n",
      "Epoch 125: \n",
      " Loss value: 0.763115644454956, train accuracy: 0.512, test accuracy:0.519\n",
      "Epoch 126: \n",
      " Loss value: 0.7616676092147827, train accuracy: 0.512, test accuracy:0.52\n",
      "Epoch 127: \n",
      " Loss value: 0.7602255940437317, train accuracy: 0.512, test accuracy:0.52\n",
      "Epoch 128: \n",
      " Loss value: 0.7587895393371582, train accuracy: 0.512, test accuracy:0.521\n",
      "Epoch 129: \n",
      " Loss value: 0.7573593854904175, train accuracy: 0.513, test accuracy:0.521\n",
      "Epoch 130: \n",
      " Loss value: 0.7559350728988647, train accuracy: 0.514, test accuracy:0.521\n",
      "Epoch 131: \n",
      " Loss value: 0.7545166015625, train accuracy: 0.514, test accuracy:0.522\n",
      "Epoch 132: \n",
      " Loss value: 0.7531039714813232, train accuracy: 0.515, test accuracy:0.522\n",
      "Epoch 133: \n",
      " Loss value: 0.7516971826553345, train accuracy: 0.515, test accuracy:0.522\n",
      "Epoch 134: \n",
      " Loss value: 0.7502959966659546, train accuracy: 0.516, test accuracy:0.524\n",
      "Epoch 135: \n",
      " Loss value: 0.7489006519317627, train accuracy: 0.517, test accuracy:0.525\n",
      "Epoch 136: \n",
      " Loss value: 0.7475109100341797, train accuracy: 0.518, test accuracy:0.526\n",
      "Epoch 137: \n",
      " Loss value: 0.7461267709732056, train accuracy: 0.518, test accuracy:0.527\n",
      "Epoch 138: \n",
      " Loss value: 0.7447483539581299, train accuracy: 0.522, test accuracy:0.528\n",
      "Epoch 139: \n",
      " Loss value: 0.7433755397796631, train accuracy: 0.525, test accuracy:0.528\n",
      "Epoch 140: \n",
      " Loss value: 0.7420083284378052, train accuracy: 0.525, test accuracy:0.528\n",
      "Epoch 141: \n",
      " Loss value: 0.7406466007232666, train accuracy: 0.526, test accuracy:0.528\n",
      "Epoch 142: \n",
      " Loss value: 0.7392902970314026, train accuracy: 0.526, test accuracy:0.53\n",
      "Epoch 143: \n",
      " Loss value: 0.7379395365715027, train accuracy: 0.527, test accuracy:0.531\n",
      "Epoch 144: \n",
      " Loss value: 0.7365941405296326, train accuracy: 0.528, test accuracy:0.531\n",
      "Epoch 145: \n",
      " Loss value: 0.7352542281150818, train accuracy: 0.529, test accuracy:0.531\n",
      "Epoch 146: \n",
      " Loss value: 0.7339196801185608, train accuracy: 0.529, test accuracy:0.531\n",
      "Epoch 147: \n",
      " Loss value: 0.73259037733078, train accuracy: 0.529, test accuracy:0.531\n",
      "Epoch 148: \n",
      " Loss value: 0.7312665581703186, train accuracy: 0.53, test accuracy:0.531\n",
      "Epoch 149: \n",
      " Loss value: 0.7299479842185974, train accuracy: 0.531, test accuracy:0.531\n",
      "Epoch 150: \n",
      " Loss value: 0.7286347150802612, train accuracy: 0.532, test accuracy:0.531\n",
      "Epoch 151: \n",
      " Loss value: 0.7273266315460205, train accuracy: 0.532, test accuracy:0.531\n",
      "Epoch 152: \n",
      " Loss value: 0.72602379322052, train accuracy: 0.532, test accuracy:0.532\n",
      "Epoch 153: \n",
      " Loss value: 0.7247260808944702, train accuracy: 0.533, test accuracy:0.532\n",
      "Epoch 154: \n",
      " Loss value: 0.7234336137771606, train accuracy: 0.534, test accuracy:0.533\n",
      "Epoch 155: \n",
      " Loss value: 0.722146213054657, train accuracy: 0.534, test accuracy:0.534\n",
      "Epoch 156: \n",
      " Loss value: 0.720863938331604, train accuracy: 0.536, test accuracy:0.536\n",
      "Epoch 157: \n",
      " Loss value: 0.7195868492126465, train accuracy: 0.536, test accuracy:0.538\n",
      "Epoch 158: \n",
      " Loss value: 0.7183146476745605, train accuracy: 0.537, test accuracy:0.538\n",
      "Epoch 159: \n",
      " Loss value: 0.7170475125312805, train accuracy: 0.537, test accuracy:0.538\n",
      "Epoch 160: \n",
      " Loss value: 0.7157854437828064, train accuracy: 0.538, test accuracy:0.538\n",
      "Epoch 161: \n",
      " Loss value: 0.7145282626152039, train accuracy: 0.538, test accuracy:0.539\n",
      "Epoch 162: \n",
      " Loss value: 0.7132760882377625, train accuracy: 0.539, test accuracy:0.54\n",
      "Epoch 163: \n",
      " Loss value: 0.7120287418365479, train accuracy: 0.539, test accuracy:0.542\n",
      "Epoch 164: \n",
      " Loss value: 0.7107864022254944, train accuracy: 0.541, test accuracy:0.543\n",
      "Epoch 165: \n",
      " Loss value: 0.7095489501953125, train accuracy: 0.542, test accuracy:0.544\n",
      "Epoch 166: \n",
      " Loss value: 0.7083162665367126, train accuracy: 0.542, test accuracy:0.544\n",
      "Epoch 167: \n",
      " Loss value: 0.7070883512496948, train accuracy: 0.544, test accuracy:0.545\n",
      "Epoch 168: \n",
      " Loss value: 0.7058653831481934, train accuracy: 0.544, test accuracy:0.546\n",
      "Epoch 169: \n",
      " Loss value: 0.7046471238136292, train accuracy: 0.545, test accuracy:0.546\n",
      "Epoch 170: \n",
      " Loss value: 0.703433632850647, train accuracy: 0.545, test accuracy:0.547\n",
      "Epoch 171: \n",
      " Loss value: 0.7022247910499573, train accuracy: 0.545, test accuracy:0.548\n",
      "Epoch 172: \n",
      " Loss value: 0.7010207176208496, train accuracy: 0.545, test accuracy:0.548\n",
      "Epoch 173: \n",
      " Loss value: 0.6998212933540344, train accuracy: 0.545, test accuracy:0.549\n",
      "Epoch 174: \n",
      " Loss value: 0.6986264586448669, train accuracy: 0.545, test accuracy:0.549\n",
      "Epoch 175: \n",
      " Loss value: 0.6974363327026367, train accuracy: 0.547, test accuracy:0.548\n",
      "Epoch 176: \n",
      " Loss value: 0.696250855922699, train accuracy: 0.547, test accuracy:0.549\n",
      "Epoch 177: \n",
      " Loss value: 0.6950699090957642, train accuracy: 0.548, test accuracy:0.55\n",
      "Epoch 178: \n",
      " Loss value: 0.6938934922218323, train accuracy: 0.548, test accuracy:0.55\n",
      "Epoch 179: \n",
      " Loss value: 0.6927216053009033, train accuracy: 0.548, test accuracy:0.55\n",
      "Epoch 180: \n",
      " Loss value: 0.6915542483329773, train accuracy: 0.549, test accuracy:0.55\n",
      "Epoch 181: \n",
      " Loss value: 0.690391480922699, train accuracy: 0.55, test accuracy:0.55\n",
      "Epoch 182: \n",
      " Loss value: 0.6892329454421997, train accuracy: 0.55, test accuracy:0.55\n",
      "Epoch 183: \n",
      " Loss value: 0.6880791187286377, train accuracy: 0.55, test accuracy:0.55\n",
      "Epoch 184: \n",
      " Loss value: 0.6869295835494995, train accuracy: 0.552, test accuracy:0.55\n",
      "Epoch 185: \n",
      " Loss value: 0.6857843399047852, train accuracy: 0.553, test accuracy:0.551\n",
      "Epoch 186: \n",
      " Loss value: 0.6846436858177185, train accuracy: 0.554, test accuracy:0.551\n",
      "Epoch 187: \n",
      " Loss value: 0.6835072040557861, train accuracy: 0.557, test accuracy:0.552\n",
      "Epoch 188: \n",
      " Loss value: 0.6823752522468567, train accuracy: 0.557, test accuracy:0.553\n",
      "Epoch 189: \n",
      " Loss value: 0.6812474131584167, train accuracy: 0.558, test accuracy:0.555\n",
      "Epoch 190: \n",
      " Loss value: 0.680124044418335, train accuracy: 0.558, test accuracy:0.556\n",
      "Epoch 191: \n",
      " Loss value: 0.6790049076080322, train accuracy: 0.558, test accuracy:0.556\n",
      "Epoch 192: \n",
      " Loss value: 0.677889883518219, train accuracy: 0.558, test accuracy:0.557\n",
      "Epoch 193: \n",
      " Loss value: 0.6767792105674744, train accuracy: 0.558, test accuracy:0.559\n",
      "Epoch 194: \n",
      " Loss value: 0.6756727695465088, train accuracy: 0.56, test accuracy:0.559\n",
      "Epoch 195: \n",
      " Loss value: 0.6745705008506775, train accuracy: 0.562, test accuracy:0.56\n",
      "Epoch 196: \n",
      " Loss value: 0.6734723448753357, train accuracy: 0.562, test accuracy:0.56\n",
      "Epoch 197: \n",
      " Loss value: 0.6723783016204834, train accuracy: 0.562, test accuracy:0.56\n",
      "Epoch 198: \n",
      " Loss value: 0.6712884902954102, train accuracy: 0.563, test accuracy:0.56\n",
      "Epoch 199: \n",
      " Loss value: 0.6702027320861816, train accuracy: 0.563, test accuracy:0.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200: \n",
      " Loss value: 0.6691210865974426, train accuracy: 0.563, test accuracy:0.562\n",
      "Epoch 201: \n",
      " Loss value: 0.6680434942245483, train accuracy: 0.564, test accuracy:0.562\n",
      "Epoch 202: \n",
      " Loss value: 0.6669699549674988, train accuracy: 0.565, test accuracy:0.563\n",
      "Epoch 203: \n",
      " Loss value: 0.665900468826294, train accuracy: 0.565, test accuracy:0.563\n",
      "Epoch 204: \n",
      " Loss value: 0.6648349761962891, train accuracy: 0.566, test accuracy:0.563\n",
      "Epoch 205: \n",
      " Loss value: 0.6637734174728394, train accuracy: 0.566, test accuracy:0.563\n",
      "Epoch 206: \n",
      " Loss value: 0.6627159714698792, train accuracy: 0.566, test accuracy:0.563\n",
      "Epoch 207: \n",
      " Loss value: 0.6616622805595398, train accuracy: 0.566, test accuracy:0.563\n",
      "Epoch 208: \n",
      " Loss value: 0.6606125831604004, train accuracy: 0.566, test accuracy:0.564\n",
      "Epoch 209: \n",
      " Loss value: 0.6595668792724609, train accuracy: 0.567, test accuracy:0.564\n",
      "Epoch 210: \n",
      " Loss value: 0.6585250496864319, train accuracy: 0.57, test accuracy:0.565\n",
      "Epoch 211: \n",
      " Loss value: 0.6574869751930237, train accuracy: 0.57, test accuracy:0.566\n",
      "Epoch 212: \n",
      " Loss value: 0.6564528942108154, train accuracy: 0.573, test accuracy:0.566\n",
      "Epoch 213: \n",
      " Loss value: 0.6554226279258728, train accuracy: 0.573, test accuracy:0.567\n",
      "Epoch 214: \n",
      " Loss value: 0.6543959975242615, train accuracy: 0.573, test accuracy:0.568\n",
      "Epoch 215: \n",
      " Loss value: 0.6533733010292053, train accuracy: 0.573, test accuracy:0.569\n",
      "Epoch 216: \n",
      " Loss value: 0.6523544192314148, train accuracy: 0.573, test accuracy:0.571\n",
      "Epoch 217: \n",
      " Loss value: 0.6513392925262451, train accuracy: 0.573, test accuracy:0.571\n",
      "Epoch 218: \n",
      " Loss value: 0.6503278613090515, train accuracy: 0.573, test accuracy:0.571\n",
      "Epoch 219: \n",
      " Loss value: 0.6493201851844788, train accuracy: 0.574, test accuracy:0.571\n",
      "Epoch 220: \n",
      " Loss value: 0.6483161449432373, train accuracy: 0.574, test accuracy:0.571\n",
      "Epoch 221: \n",
      " Loss value: 0.6473159193992615, train accuracy: 0.575, test accuracy:0.571\n",
      "Epoch 222: \n",
      " Loss value: 0.6463193297386169, train accuracy: 0.575, test accuracy:0.571\n",
      "Epoch 223: \n",
      " Loss value: 0.6453263759613037, train accuracy: 0.576, test accuracy:0.571\n",
      "Epoch 224: \n",
      " Loss value: 0.6443370580673218, train accuracy: 0.579, test accuracy:0.572\n",
      "Epoch 225: \n",
      " Loss value: 0.6433513164520264, train accuracy: 0.58, test accuracy:0.573\n",
      "Epoch 226: \n",
      " Loss value: 0.6423692107200623, train accuracy: 0.58, test accuracy:0.573\n",
      "Epoch 227: \n",
      " Loss value: 0.6413906812667847, train accuracy: 0.581, test accuracy:0.573\n",
      "Epoch 228: \n",
      " Loss value: 0.6404157876968384, train accuracy: 0.584, test accuracy:0.575\n",
      "Epoch 229: \n",
      " Loss value: 0.6394443511962891, train accuracy: 0.585, test accuracy:0.575\n",
      "Epoch 230: \n",
      " Loss value: 0.6384764313697815, train accuracy: 0.587, test accuracy:0.576\n",
      "Epoch 231: \n",
      " Loss value: 0.6375120878219604, train accuracy: 0.589, test accuracy:0.576\n",
      "Epoch 232: \n",
      " Loss value: 0.6365512013435364, train accuracy: 0.592, test accuracy:0.577\n",
      "Epoch 233: \n",
      " Loss value: 0.635593831539154, train accuracy: 0.594, test accuracy:0.578\n",
      "Epoch 234: \n",
      " Loss value: 0.6346399188041687, train accuracy: 0.597, test accuracy:0.581\n",
      "Epoch 235: \n",
      " Loss value: 0.6336894631385803, train accuracy: 0.597, test accuracy:0.581\n",
      "Epoch 236: \n",
      " Loss value: 0.6327424049377441, train accuracy: 0.597, test accuracy:0.582\n",
      "Epoch 237: \n",
      " Loss value: 0.6317988038063049, train accuracy: 0.598, test accuracy:0.583\n",
      "Epoch 238: \n",
      " Loss value: 0.6308586001396179, train accuracy: 0.598, test accuracy:0.585\n",
      "Epoch 239: \n",
      " Loss value: 0.6299216747283936, train accuracy: 0.599, test accuracy:0.585\n",
      "Epoch 240: \n",
      " Loss value: 0.6289882659912109, train accuracy: 0.6, test accuracy:0.586\n",
      "Epoch 241: \n",
      " Loss value: 0.6280580759048462, train accuracy: 0.603, test accuracy:0.587\n",
      "Epoch 242: \n",
      " Loss value: 0.6271313428878784, train accuracy: 0.604, test accuracy:0.588\n",
      "Epoch 243: \n",
      " Loss value: 0.6262078881263733, train accuracy: 0.61, test accuracy:0.588\n",
      "Epoch 244: \n",
      " Loss value: 0.6252877116203308, train accuracy: 0.611, test accuracy:0.59\n",
      "Epoch 245: \n",
      " Loss value: 0.6243708729743958, train accuracy: 0.611, test accuracy:0.591\n",
      "Epoch 246: \n",
      " Loss value: 0.6234572529792786, train accuracy: 0.611, test accuracy:0.594\n",
      "Epoch 247: \n",
      " Loss value: 0.6225468516349792, train accuracy: 0.612, test accuracy:0.595\n",
      "Epoch 248: \n",
      " Loss value: 0.6216398477554321, train accuracy: 0.613, test accuracy:0.596\n",
      "Epoch 249: \n",
      " Loss value: 0.6207359433174133, train accuracy: 0.613, test accuracy:0.597\n",
      "Epoch 250: \n",
      " Loss value: 0.6198351979255676, train accuracy: 0.616, test accuracy:0.597\n",
      "Epoch 251: \n",
      " Loss value: 0.6189377307891846, train accuracy: 0.62, test accuracy:0.6\n",
      "Epoch 252: \n",
      " Loss value: 0.6180434823036194, train accuracy: 0.621, test accuracy:0.601\n",
      "Epoch 253: \n",
      " Loss value: 0.6171523332595825, train accuracy: 0.622, test accuracy:0.602\n",
      "Epoch 254: \n",
      " Loss value: 0.616264283657074, train accuracy: 0.622, test accuracy:0.603\n",
      "Epoch 255: \n",
      " Loss value: 0.6153795123100281, train accuracy: 0.623, test accuracy:0.603\n",
      "Epoch 256: \n",
      " Loss value: 0.614497721195221, train accuracy: 0.626, test accuracy:0.61\n",
      "Epoch 257: \n",
      " Loss value: 0.6136190891265869, train accuracy: 0.626, test accuracy:0.61\n",
      "Epoch 258: \n",
      " Loss value: 0.6127436757087708, train accuracy: 0.627, test accuracy:0.612\n",
      "Epoch 259: \n",
      " Loss value: 0.6118711829185486, train accuracy: 0.629, test accuracy:0.613\n",
      "Epoch 260: \n",
      " Loss value: 0.6110016703605652, train accuracy: 0.631, test accuracy:0.613\n",
      "Epoch 261: \n",
      " Loss value: 0.6101353764533997, train accuracy: 0.631, test accuracy:0.614\n",
      "Epoch 262: \n",
      " Loss value: 0.6092720627784729, train accuracy: 0.631, test accuracy:0.617\n",
      "Epoch 263: \n",
      " Loss value: 0.6084117293357849, train accuracy: 0.632, test accuracy:0.617\n",
      "Epoch 264: \n",
      " Loss value: 0.6075544357299805, train accuracy: 0.633, test accuracy:0.618\n",
      "Epoch 265: \n",
      " Loss value: 0.60670006275177, train accuracy: 0.633, test accuracy:0.618\n",
      "Epoch 266: \n",
      " Loss value: 0.6058487892150879, train accuracy: 0.633, test accuracy:0.623\n",
      "Epoch 267: \n",
      " Loss value: 0.6050004363059998, train accuracy: 0.634, test accuracy:0.624\n",
      "Epoch 268: \n",
      " Loss value: 0.6041548848152161, train accuracy: 0.634, test accuracy:0.626\n",
      "Epoch 269: \n",
      " Loss value: 0.6033124327659607, train accuracy: 0.634, test accuracy:0.626\n",
      "Epoch 270: \n",
      " Loss value: 0.6024728417396545, train accuracy: 0.637, test accuracy:0.627\n",
      "Epoch 271: \n",
      " Loss value: 0.6016361713409424, train accuracy: 0.638, test accuracy:0.628\n",
      "Epoch 272: \n",
      " Loss value: 0.6008024215698242, train accuracy: 0.639, test accuracy:0.628\n",
      "Epoch 273: \n",
      " Loss value: 0.5999714732170105, train accuracy: 0.64, test accuracy:0.629\n",
      "Epoch 274: \n",
      " Loss value: 0.599143385887146, train accuracy: 0.64, test accuracy:0.63\n",
      "Epoch 275: \n",
      " Loss value: 0.5983182191848755, train accuracy: 0.642, test accuracy:0.633\n",
      "Epoch 276: \n",
      " Loss value: 0.5974958539009094, train accuracy: 0.644, test accuracy:0.634\n",
      "Epoch 277: \n",
      " Loss value: 0.5966762900352478, train accuracy: 0.644, test accuracy:0.635\n",
      "Epoch 278: \n",
      " Loss value: 0.5958596467971802, train accuracy: 0.644, test accuracy:0.637\n",
      "Epoch 279: \n",
      " Loss value: 0.5950456261634827, train accuracy: 0.645, test accuracy:0.64\n",
      "Epoch 280: \n",
      " Loss value: 0.5942344069480896, train accuracy: 0.645, test accuracy:0.64\n",
      "Epoch 281: \n",
      " Loss value: 0.5934261083602905, train accuracy: 0.646, test accuracy:0.644\n",
      "Epoch 282: \n",
      " Loss value: 0.5926204323768616, train accuracy: 0.647, test accuracy:0.646\n",
      "Epoch 283: \n",
      " Loss value: 0.5918174386024475, train accuracy: 0.648, test accuracy:0.648\n",
      "Epoch 284: \n",
      " Loss value: 0.5910173654556274, train accuracy: 0.648, test accuracy:0.651\n",
      "Epoch 285: \n",
      " Loss value: 0.5902199149131775, train accuracy: 0.651, test accuracy:0.652\n",
      "Epoch 286: \n",
      " Loss value: 0.5894250869750977, train accuracy: 0.652, test accuracy:0.655\n",
      "Epoch 287: \n",
      " Loss value: 0.5886330604553223, train accuracy: 0.652, test accuracy:0.655\n",
      "Epoch 288: \n",
      " Loss value: 0.5878437757492065, train accuracy: 0.653, test accuracy:0.658\n",
      "Epoch 289: \n",
      " Loss value: 0.5870570540428162, train accuracy: 0.654, test accuracy:0.664\n",
      "Epoch 290: \n",
      " Loss value: 0.5862729549407959, train accuracy: 0.655, test accuracy:0.665\n",
      "Epoch 291: \n",
      " Loss value: 0.5854914784431458, train accuracy: 0.655, test accuracy:0.666\n",
      "Epoch 292: \n",
      " Loss value: 0.5847127437591553, train accuracy: 0.655, test accuracy:0.67\n",
      "Epoch 293: \n",
      " Loss value: 0.5839365720748901, train accuracy: 0.656, test accuracy:0.674\n",
      "Epoch 294: \n",
      " Loss value: 0.5831629633903503, train accuracy: 0.656, test accuracy:0.675\n",
      "Epoch 295: \n",
      " Loss value: 0.5823920369148254, train accuracy: 0.658, test accuracy:0.676\n",
      "Epoch 296: \n",
      " Loss value: 0.5816236138343811, train accuracy: 0.663, test accuracy:0.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297: \n",
      " Loss value: 0.5808577537536621, train accuracy: 0.665, test accuracy:0.679\n",
      "Epoch 298: \n",
      " Loss value: 0.5800944566726685, train accuracy: 0.665, test accuracy:0.68\n",
      "Epoch 299: \n",
      " Loss value: 0.5793337225914001, train accuracy: 0.667, test accuracy:0.682\n",
      "Epoch 300: \n",
      " Loss value: 0.5785754323005676, train accuracy: 0.667, test accuracy:0.683\n",
      "Epoch 301: \n",
      " Loss value: 0.5778197646141052, train accuracy: 0.669, test accuracy:0.683\n",
      "Epoch 302: \n",
      " Loss value: 0.5770666003227234, train accuracy: 0.67, test accuracy:0.686\n",
      "Epoch 303: \n",
      " Loss value: 0.5763158798217773, train accuracy: 0.67, test accuracy:0.688\n",
      "Epoch 304: \n",
      " Loss value: 0.5755676627159119, train accuracy: 0.671, test accuracy:0.688\n",
      "Epoch 305: \n",
      " Loss value: 0.574821949005127, train accuracy: 0.671, test accuracy:0.689\n",
      "Epoch 306: \n",
      " Loss value: 0.5740786194801331, train accuracy: 0.672, test accuracy:0.692\n",
      "Epoch 307: \n",
      " Loss value: 0.5733378529548645, train accuracy: 0.672, test accuracy:0.696\n",
      "Epoch 308: \n",
      " Loss value: 0.5725994110107422, train accuracy: 0.674, test accuracy:0.7\n",
      "Epoch 309: \n",
      " Loss value: 0.5718634128570557, train accuracy: 0.675, test accuracy:0.703\n",
      "Epoch 310: \n",
      " Loss value: 0.5711297988891602, train accuracy: 0.676, test accuracy:0.704\n",
      "Epoch 311: \n",
      " Loss value: 0.5703986883163452, train accuracy: 0.677, test accuracy:0.705\n",
      "Epoch 312: \n",
      " Loss value: 0.5696699619293213, train accuracy: 0.682, test accuracy:0.705\n",
      "Epoch 313: \n",
      " Loss value: 0.5689435005187988, train accuracy: 0.684, test accuracy:0.707\n",
      "Epoch 314: \n",
      " Loss value: 0.5682194828987122, train accuracy: 0.684, test accuracy:0.71\n",
      "Epoch 315: \n",
      " Loss value: 0.5674977898597717, train accuracy: 0.686, test accuracy:0.713\n",
      "Epoch 316: \n",
      " Loss value: 0.5667784214019775, train accuracy: 0.687, test accuracy:0.713\n",
      "Epoch 317: \n",
      " Loss value: 0.5660614371299744, train accuracy: 0.687, test accuracy:0.715\n",
      "Epoch 318: \n",
      " Loss value: 0.5653467178344727, train accuracy: 0.691, test accuracy:0.716\n",
      "Epoch 319: \n",
      " Loss value: 0.564634382724762, train accuracy: 0.692, test accuracy:0.718\n",
      "Epoch 320: \n",
      " Loss value: 0.5639243125915527, train accuracy: 0.695, test accuracy:0.72\n",
      "Epoch 321: \n",
      " Loss value: 0.5632166266441345, train accuracy: 0.695, test accuracy:0.723\n",
      "Epoch 322: \n",
      " Loss value: 0.5625110268592834, train accuracy: 0.697, test accuracy:0.725\n",
      "Epoch 323: \n",
      " Loss value: 0.5618078112602234, train accuracy: 0.698, test accuracy:0.726\n",
      "Epoch 324: \n",
      " Loss value: 0.56110680103302, train accuracy: 0.699, test accuracy:0.73\n",
      "Epoch 325: \n",
      " Loss value: 0.5604080557823181, train accuracy: 0.701, test accuracy:0.734\n",
      "Epoch 326: \n",
      " Loss value: 0.5597116351127625, train accuracy: 0.702, test accuracy:0.735\n",
      "Epoch 327: \n",
      " Loss value: 0.5590173602104187, train accuracy: 0.702, test accuracy:0.737\n",
      "Epoch 328: \n",
      " Loss value: 0.5583252310752869, train accuracy: 0.704, test accuracy:0.738\n",
      "Epoch 329: \n",
      " Loss value: 0.5576354265213013, train accuracy: 0.707, test accuracy:0.738\n",
      "Epoch 330: \n",
      " Loss value: 0.5569478273391724, train accuracy: 0.708, test accuracy:0.739\n",
      "Epoch 331: \n",
      " Loss value: 0.5562622547149658, train accuracy: 0.714, test accuracy:0.742\n",
      "Epoch 332: \n",
      " Loss value: 0.5555790662765503, train accuracy: 0.714, test accuracy:0.746\n",
      "Epoch 333: \n",
      " Loss value: 0.5548979043960571, train accuracy: 0.716, test accuracy:0.747\n",
      "Epoch 334: \n",
      " Loss value: 0.5542188882827759, train accuracy: 0.72, test accuracy:0.752\n",
      "Epoch 335: \n",
      " Loss value: 0.5535420179367065, train accuracy: 0.72, test accuracy:0.754\n",
      "Epoch 336: \n",
      " Loss value: 0.5528672933578491, train accuracy: 0.721, test accuracy:0.755\n",
      "Epoch 337: \n",
      " Loss value: 0.5521947145462036, train accuracy: 0.722, test accuracy:0.757\n",
      "Epoch 338: \n",
      " Loss value: 0.5515242218971252, train accuracy: 0.726, test accuracy:0.76\n",
      "Epoch 339: \n",
      " Loss value: 0.550855815410614, train accuracy: 0.727, test accuracy:0.764\n",
      "Epoch 340: \n",
      " Loss value: 0.5501895546913147, train accuracy: 0.729, test accuracy:0.766\n",
      "Epoch 341: \n",
      " Loss value: 0.549525260925293, train accuracy: 0.73, test accuracy:0.767\n",
      "Epoch 342: \n",
      " Loss value: 0.5488632321357727, train accuracy: 0.735, test accuracy:0.768\n",
      "Epoch 343: \n",
      " Loss value: 0.5482031106948853, train accuracy: 0.738, test accuracy:0.769\n",
      "Epoch 344: \n",
      " Loss value: 0.5475450754165649, train accuracy: 0.743, test accuracy:0.769\n",
      "Epoch 345: \n",
      " Loss value: 0.5468891859054565, train accuracy: 0.743, test accuracy:0.769\n",
      "Epoch 346: \n",
      " Loss value: 0.5462351441383362, train accuracy: 0.743, test accuracy:0.77\n",
      "Epoch 347: \n",
      " Loss value: 0.5455832481384277, train accuracy: 0.748, test accuracy:0.773\n",
      "Epoch 348: \n",
      " Loss value: 0.5449333786964417, train accuracy: 0.752, test accuracy:0.775\n",
      "Epoch 349: \n",
      " Loss value: 0.5442854166030884, train accuracy: 0.756, test accuracy:0.778\n",
      "Epoch 350: \n",
      " Loss value: 0.5436395406723022, train accuracy: 0.758, test accuracy:0.779\n",
      "Epoch 351: \n",
      " Loss value: 0.5429955720901489, train accuracy: 0.76, test accuracy:0.781\n",
      "Epoch 352: \n",
      " Loss value: 0.542353630065918, train accuracy: 0.76, test accuracy:0.783\n",
      "Epoch 353: \n",
      " Loss value: 0.5417135953903198, train accuracy: 0.762, test accuracy:0.785\n",
      "Epoch 354: \n",
      " Loss value: 0.541075587272644, train accuracy: 0.765, test accuracy:0.787\n",
      "Epoch 355: \n",
      " Loss value: 0.5404395461082458, train accuracy: 0.766, test accuracy:0.79\n",
      "Epoch 356: \n",
      " Loss value: 0.5398053526878357, train accuracy: 0.77, test accuracy:0.792\n",
      "Epoch 357: \n",
      " Loss value: 0.5391730666160583, train accuracy: 0.771, test accuracy:0.796\n",
      "Epoch 358: \n",
      " Loss value: 0.5385428667068481, train accuracy: 0.773, test accuracy:0.799\n",
      "Epoch 359: \n",
      " Loss value: 0.5379144549369812, train accuracy: 0.774, test accuracy:0.8\n",
      "Epoch 360: \n",
      " Loss value: 0.5372879505157471, train accuracy: 0.774, test accuracy:0.802\n",
      "Epoch 361: \n",
      " Loss value: 0.5366633534431458, train accuracy: 0.779, test accuracy:0.803\n",
      "Epoch 362: \n",
      " Loss value: 0.536040723323822, train accuracy: 0.783, test accuracy:0.803\n",
      "Epoch 363: \n",
      " Loss value: 0.5354198217391968, train accuracy: 0.786, test accuracy:0.803\n",
      "Epoch 364: \n",
      " Loss value: 0.5348008871078491, train accuracy: 0.786, test accuracy:0.805\n",
      "Epoch 365: \n",
      " Loss value: 0.5341837406158447, train accuracy: 0.791, test accuracy:0.809\n",
      "Epoch 366: \n",
      " Loss value: 0.5335685014724731, train accuracy: 0.793, test accuracy:0.81\n",
      "Epoch 367: \n",
      " Loss value: 0.5329549908638, train accuracy: 0.797, test accuracy:0.815\n",
      "Epoch 368: \n",
      " Loss value: 0.5323434472084045, train accuracy: 0.798, test accuracy:0.82\n",
      "Epoch 369: \n",
      " Loss value: 0.5317336320877075, train accuracy: 0.8, test accuracy:0.825\n",
      "Epoch 370: \n",
      " Loss value: 0.5311257243156433, train accuracy: 0.802, test accuracy:0.828\n",
      "Epoch 371: \n",
      " Loss value: 0.5305195450782776, train accuracy: 0.803, test accuracy:0.831\n",
      "Epoch 372: \n",
      " Loss value: 0.5299152135848999, train accuracy: 0.806, test accuracy:0.835\n",
      "Epoch 373: \n",
      " Loss value: 0.5293126106262207, train accuracy: 0.806, test accuracy:0.835\n",
      "Epoch 374: \n",
      " Loss value: 0.5287117958068848, train accuracy: 0.808, test accuracy:0.838\n",
      "Epoch 375: \n",
      " Loss value: 0.5281127691268921, train accuracy: 0.811, test accuracy:0.841\n",
      "Epoch 376: \n",
      " Loss value: 0.5275155305862427, train accuracy: 0.816, test accuracy:0.842\n",
      "Epoch 377: \n",
      " Loss value: 0.5269200205802917, train accuracy: 0.818, test accuracy:0.842\n",
      "Epoch 378: \n",
      " Loss value: 0.5263262391090393, train accuracy: 0.822, test accuracy:0.843\n",
      "Epoch 379: \n",
      " Loss value: 0.5257342457771301, train accuracy: 0.826, test accuracy:0.845\n",
      "Epoch 380: \n",
      " Loss value: 0.5251439213752747, train accuracy: 0.83, test accuracy:0.85\n",
      "Epoch 381: \n",
      " Loss value: 0.5245553851127625, train accuracy: 0.83, test accuracy:0.854\n",
      "Epoch 382: \n",
      " Loss value: 0.523968517780304, train accuracy: 0.833, test accuracy:0.855\n",
      "Epoch 383: \n",
      " Loss value: 0.523383378982544, train accuracy: 0.837, test accuracy:0.856\n",
      "Epoch 384: \n",
      " Loss value: 0.5227998495101929, train accuracy: 0.837, test accuracy:0.858\n",
      "Epoch 385: \n",
      " Loss value: 0.5222181081771851, train accuracy: 0.839, test accuracy:0.86\n",
      "Epoch 386: \n",
      " Loss value: 0.5216379761695862, train accuracy: 0.842, test accuracy:0.862\n",
      "Epoch 387: \n",
      " Loss value: 0.5210596323013306, train accuracy: 0.845, test accuracy:0.865\n",
      "Epoch 388: \n",
      " Loss value: 0.5204827785491943, train accuracy: 0.849, test accuracy:0.869\n",
      "Epoch 389: \n",
      " Loss value: 0.5199077725410461, train accuracy: 0.85, test accuracy:0.871\n",
      "Epoch 390: \n",
      " Loss value: 0.5193342566490173, train accuracy: 0.852, test accuracy:0.871\n",
      "Epoch 391: \n",
      " Loss value: 0.518762469291687, train accuracy: 0.856, test accuracy:0.873\n",
      "Epoch 392: \n",
      " Loss value: 0.5181922316551208, train accuracy: 0.859, test accuracy:0.876\n",
      "Epoch 393: \n",
      " Loss value: 0.5176237225532532, train accuracy: 0.862, test accuracy:0.879\n",
      "Epoch 394: \n",
      " Loss value: 0.5170567631721497, train accuracy: 0.863, test accuracy:0.883\n",
      "Epoch 395: \n",
      " Loss value: 0.5164914727210999, train accuracy: 0.867, test accuracy:0.886\n",
      "Epoch 396: \n",
      " Loss value: 0.5159277319908142, train accuracy: 0.869, test accuracy:0.888\n",
      "Epoch 397: \n",
      " Loss value: 0.5153656005859375, train accuracy: 0.875, test accuracy:0.892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398: \n",
      " Loss value: 0.5148051381111145, train accuracy: 0.877, test accuracy:0.894\n",
      "Epoch 399: \n",
      " Loss value: 0.5142461657524109, train accuracy: 0.879, test accuracy:0.895\n",
      "Epoch 400: \n",
      " Loss value: 0.5136888027191162, train accuracy: 0.88, test accuracy:0.898\n",
      "Epoch 401: \n",
      " Loss value: 0.5131329298019409, train accuracy: 0.88, test accuracy:0.902\n",
      "Epoch 402: \n",
      " Loss value: 0.5125786662101746, train accuracy: 0.88, test accuracy:0.903\n",
      "Epoch 403: \n",
      " Loss value: 0.5120260119438171, train accuracy: 0.881, test accuracy:0.906\n",
      "Epoch 404: \n",
      " Loss value: 0.5114747881889343, train accuracy: 0.882, test accuracy:0.906\n",
      "Epoch 405: \n",
      " Loss value: 0.5109251141548157, train accuracy: 0.885, test accuracy:0.909\n",
      "Epoch 406: \n",
      " Loss value: 0.5103769898414612, train accuracy: 0.887, test accuracy:0.909\n",
      "Epoch 407: \n",
      " Loss value: 0.5098304152488708, train accuracy: 0.888, test accuracy:0.909\n",
      "Epoch 408: \n",
      " Loss value: 0.5092853903770447, train accuracy: 0.892, test accuracy:0.91\n",
      "Epoch 409: \n",
      " Loss value: 0.5087417364120483, train accuracy: 0.896, test accuracy:0.912\n",
      "Epoch 410: \n",
      " Loss value: 0.5081996917724609, train accuracy: 0.896, test accuracy:0.915\n",
      "Epoch 411: \n",
      " Loss value: 0.5076591372489929, train accuracy: 0.899, test accuracy:0.915\n",
      "Epoch 412: \n",
      " Loss value: 0.5071200132369995, train accuracy: 0.901, test accuracy:0.916\n",
      "Epoch 413: \n",
      " Loss value: 0.5065824389457703, train accuracy: 0.903, test accuracy:0.917\n",
      "Epoch 414: \n",
      " Loss value: 0.5060462355613708, train accuracy: 0.905, test accuracy:0.919\n",
      "Epoch 415: \n",
      " Loss value: 0.5055115818977356, train accuracy: 0.905, test accuracy:0.919\n",
      "Epoch 416: \n",
      " Loss value: 0.504978358745575, train accuracy: 0.907, test accuracy:0.921\n",
      "Epoch 417: \n",
      " Loss value: 0.5044465661048889, train accuracy: 0.907, test accuracy:0.922\n",
      "Epoch 418: \n",
      " Loss value: 0.5039162039756775, train accuracy: 0.907, test accuracy:0.926\n",
      "Epoch 419: \n",
      " Loss value: 0.5033873319625854, train accuracy: 0.908, test accuracy:0.926\n",
      "Epoch 420: \n",
      " Loss value: 0.502859890460968, train accuracy: 0.909, test accuracy:0.93\n",
      "Epoch 421: \n",
      " Loss value: 0.5023338794708252, train accuracy: 0.912, test accuracy:0.93\n",
      "Epoch 422: \n",
      " Loss value: 0.5018092393875122, train accuracy: 0.914, test accuracy:0.931\n",
      "Epoch 423: \n",
      " Loss value: 0.5012860298156738, train accuracy: 0.916, test accuracy:0.931\n",
      "Epoch 424: \n",
      " Loss value: 0.5007641911506653, train accuracy: 0.918, test accuracy:0.933\n",
      "Epoch 425: \n",
      " Loss value: 0.5002437829971313, train accuracy: 0.92, test accuracy:0.934\n",
      "Epoch 426: \n",
      " Loss value: 0.499724805355072, train accuracy: 0.921, test accuracy:0.935\n",
      "Epoch 427: \n",
      " Loss value: 0.49920710921287537, train accuracy: 0.921, test accuracy:0.936\n",
      "Epoch 428: \n",
      " Loss value: 0.4986908435821533, train accuracy: 0.923, test accuracy:0.936\n",
      "Epoch 429: \n",
      " Loss value: 0.4981760084629059, train accuracy: 0.924, test accuracy:0.937\n",
      "Epoch 430: \n",
      " Loss value: 0.49766242504119873, train accuracy: 0.924, test accuracy:0.937\n",
      "Epoch 431: \n",
      " Loss value: 0.4971502721309662, train accuracy: 0.926, test accuracy:0.938\n",
      "Epoch 432: \n",
      " Loss value: 0.4966394603252411, train accuracy: 0.927, test accuracy:0.939\n",
      "Epoch 433: \n",
      " Loss value: 0.49612995982170105, train accuracy: 0.928, test accuracy:0.939\n",
      "Epoch 434: \n",
      " Loss value: 0.49562183022499084, train accuracy: 0.93, test accuracy:0.94\n",
      "Epoch 435: \n",
      " Loss value: 0.4951150417327881, train accuracy: 0.931, test accuracy:0.94\n",
      "Epoch 436: \n",
      " Loss value: 0.4946095645427704, train accuracy: 0.931, test accuracy:0.94\n",
      "Epoch 437: \n",
      " Loss value: 0.49410536885261536, train accuracy: 0.933, test accuracy:0.941\n",
      "Epoch 438: \n",
      " Loss value: 0.4936025142669678, train accuracy: 0.935, test accuracy:0.942\n",
      "Epoch 439: \n",
      " Loss value: 0.49310100078582764, train accuracy: 0.935, test accuracy:0.943\n",
      "Epoch 440: \n",
      " Loss value: 0.49260076880455017, train accuracy: 0.935, test accuracy:0.943\n",
      "Epoch 441: \n",
      " Loss value: 0.49210187792778015, train accuracy: 0.936, test accuracy:0.946\n",
      "Epoch 442: \n",
      " Loss value: 0.49160417914390564, train accuracy: 0.936, test accuracy:0.947\n",
      "Epoch 443: \n",
      " Loss value: 0.4911077916622162, train accuracy: 0.937, test accuracy:0.947\n",
      "Epoch 444: \n",
      " Loss value: 0.4906127452850342, train accuracy: 0.938, test accuracy:0.949\n",
      "Epoch 445: \n",
      " Loss value: 0.4901188313961029, train accuracy: 0.938, test accuracy:0.95\n",
      "Epoch 446: \n",
      " Loss value: 0.48962631821632385, train accuracy: 0.939, test accuracy:0.95\n",
      "Epoch 447: \n",
      " Loss value: 0.4891349971294403, train accuracy: 0.939, test accuracy:0.95\n",
      "Epoch 448: \n",
      " Loss value: 0.48864489793777466, train accuracy: 0.94, test accuracy:0.951\n",
      "Epoch 449: \n",
      " Loss value: 0.48815613985061646, train accuracy: 0.941, test accuracy:0.952\n",
      "Epoch 450: \n",
      " Loss value: 0.48766857385635376, train accuracy: 0.942, test accuracy:0.952\n",
      "Epoch 451: \n",
      " Loss value: 0.4871821999549866, train accuracy: 0.943, test accuracy:0.954\n",
      "Epoch 452: \n",
      " Loss value: 0.48669713735580444, train accuracy: 0.943, test accuracy:0.954\n",
      "Epoch 453: \n",
      " Loss value: 0.4862132668495178, train accuracy: 0.943, test accuracy:0.954\n",
      "Epoch 454: \n",
      " Loss value: 0.4857305884361267, train accuracy: 0.943, test accuracy:0.954\n",
      "Epoch 455: \n",
      " Loss value: 0.4852491319179535, train accuracy: 0.943, test accuracy:0.954\n",
      "Epoch 456: \n",
      " Loss value: 0.48476892709732056, train accuracy: 0.943, test accuracy:0.955\n",
      "Epoch 457: \n",
      " Loss value: 0.48428982496261597, train accuracy: 0.945, test accuracy:0.956\n",
      "Epoch 458: \n",
      " Loss value: 0.48381200432777405, train accuracy: 0.947, test accuracy:0.956\n",
      "Epoch 459: \n",
      " Loss value: 0.48333534598350525, train accuracy: 0.947, test accuracy:0.956\n",
      "Epoch 460: \n",
      " Loss value: 0.48285987973213196, train accuracy: 0.947, test accuracy:0.957\n",
      "Epoch 461: \n",
      " Loss value: 0.4823856055736542, train accuracy: 0.948, test accuracy:0.957\n",
      "Epoch 462: \n",
      " Loss value: 0.4819124639034271, train accuracy: 0.948, test accuracy:0.957\n",
      "Epoch 463: \n",
      " Loss value: 0.4814404845237732, train accuracy: 0.948, test accuracy:0.958\n",
      "Epoch 464: \n",
      " Loss value: 0.48096969723701477, train accuracy: 0.948, test accuracy:0.958\n",
      "Epoch 465: \n",
      " Loss value: 0.48050007224082947, train accuracy: 0.95, test accuracy:0.958\n",
      "Epoch 466: \n",
      " Loss value: 0.4800315499305725, train accuracy: 0.951, test accuracy:0.958\n",
      "Epoch 467: \n",
      " Loss value: 0.47956421971321106, train accuracy: 0.951, test accuracy:0.958\n",
      "Epoch 468: \n",
      " Loss value: 0.4790980815887451, train accuracy: 0.952, test accuracy:0.958\n",
      "Epoch 469: \n",
      " Loss value: 0.47863295674324036, train accuracy: 0.952, test accuracy:0.958\n",
      "Epoch 470: \n",
      " Loss value: 0.4781690537929535, train accuracy: 0.952, test accuracy:0.959\n",
      "Epoch 471: \n",
      " Loss value: 0.4777062237262726, train accuracy: 0.952, test accuracy:0.959\n",
      "Epoch 472: \n",
      " Loss value: 0.47724449634552, train accuracy: 0.952, test accuracy:0.959\n",
      "Epoch 473: \n",
      " Loss value: 0.4767839312553406, train accuracy: 0.952, test accuracy:0.959\n",
      "Epoch 474: \n",
      " Loss value: 0.4763244688510895, train accuracy: 0.954, test accuracy:0.959\n",
      "Epoch 475: \n",
      " Loss value: 0.47586604952812195, train accuracy: 0.955, test accuracy:0.96\n",
      "Epoch 476: \n",
      " Loss value: 0.47540879249572754, train accuracy: 0.957, test accuracy:0.962\n",
      "Epoch 477: \n",
      " Loss value: 0.4749526083469391, train accuracy: 0.957, test accuracy:0.962\n",
      "Epoch 478: \n",
      " Loss value: 0.47449755668640137, train accuracy: 0.958, test accuracy:0.962\n",
      "Epoch 479: \n",
      " Loss value: 0.47404351830482483, train accuracy: 0.958, test accuracy:0.962\n",
      "Epoch 480: \n",
      " Loss value: 0.47359058260917664, train accuracy: 0.958, test accuracy:0.962\n",
      "Epoch 481: \n",
      " Loss value: 0.4731387197971344, train accuracy: 0.958, test accuracy:0.962\n",
      "Epoch 482: \n",
      " Loss value: 0.47268790006637573, train accuracy: 0.958, test accuracy:0.963\n",
      "Epoch 483: \n",
      " Loss value: 0.4722382128238678, train accuracy: 0.959, test accuracy:0.963\n",
      "Epoch 484: \n",
      " Loss value: 0.47178953886032104, train accuracy: 0.959, test accuracy:0.963\n",
      "Epoch 485: \n",
      " Loss value: 0.4713418781757355, train accuracy: 0.959, test accuracy:0.964\n",
      "Epoch 486: \n",
      " Loss value: 0.47089534997940063, train accuracy: 0.96, test accuracy:0.964\n",
      "Epoch 487: \n",
      " Loss value: 0.470449835062027, train accuracy: 0.961, test accuracy:0.964\n",
      "Epoch 488: \n",
      " Loss value: 0.4700053036212921, train accuracy: 0.961, test accuracy:0.966\n",
      "Epoch 489: \n",
      " Loss value: 0.4695618152618408, train accuracy: 0.962, test accuracy:0.967\n",
      "Epoch 490: \n",
      " Loss value: 0.4691193699836731, train accuracy: 0.963, test accuracy:0.967\n",
      "Epoch 491: \n",
      " Loss value: 0.46867799758911133, train accuracy: 0.963, test accuracy:0.967\n",
      "Epoch 492: \n",
      " Loss value: 0.46823760867118835, train accuracy: 0.963, test accuracy:0.967\n",
      "Epoch 493: \n",
      " Loss value: 0.4677982032299042, train accuracy: 0.964, test accuracy:0.968\n",
      "Epoch 494: \n",
      " Loss value: 0.4673598110675812, train accuracy: 0.964, test accuracy:0.969\n",
      "Epoch 495: \n",
      " Loss value: 0.46692249178886414, train accuracy: 0.964, test accuracy:0.969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496: \n",
      " Loss value: 0.4664860963821411, train accuracy: 0.965, test accuracy:0.969\n",
      "Epoch 497: \n",
      " Loss value: 0.46605077385902405, train accuracy: 0.965, test accuracy:0.97\n",
      "Epoch 498: \n",
      " Loss value: 0.465616375207901, train accuracy: 0.965, test accuracy:0.97\n",
      "Epoch 499: \n",
      " Loss value: 0.46518296003341675, train accuracy: 0.965, test accuracy:0.971\n",
      "Epoch 500: \n",
      " Loss value: 0.4647505581378937, train accuracy: 0.966, test accuracy:0.971\n",
      "Epoch 501: \n",
      " Loss value: 0.4643190801143646, train accuracy: 0.966, test accuracy:0.972\n",
      "Epoch 502: \n",
      " Loss value: 0.46388861536979675, train accuracy: 0.966, test accuracy:0.972\n",
      "Epoch 503: \n",
      " Loss value: 0.4634591042995453, train accuracy: 0.968, test accuracy:0.972\n",
      "Epoch 504: \n",
      " Loss value: 0.46303054690361023, train accuracy: 0.969, test accuracy:0.972\n",
      "Epoch 505: \n",
      " Loss value: 0.46260303258895874, train accuracy: 0.97, test accuracy:0.972\n",
      "Epoch 506: \n",
      " Loss value: 0.4621764123439789, train accuracy: 0.971, test accuracy:0.972\n",
      "Epoch 507: \n",
      " Loss value: 0.46175074577331543, train accuracy: 0.971, test accuracy:0.973\n",
      "Epoch 508: \n",
      " Loss value: 0.4613260328769684, train accuracy: 0.971, test accuracy:0.973\n",
      "Epoch 509: \n",
      " Loss value: 0.46090221405029297, train accuracy: 0.971, test accuracy:0.973\n",
      "Epoch 510: \n",
      " Loss value: 0.46047937870025635, train accuracy: 0.971, test accuracy:0.973\n",
      "Epoch 511: \n",
      " Loss value: 0.46005743741989136, train accuracy: 0.973, test accuracy:0.973\n",
      "Epoch 512: \n",
      " Loss value: 0.4596364498138428, train accuracy: 0.975, test accuracy:0.973\n",
      "Epoch 513: \n",
      " Loss value: 0.4592163562774658, train accuracy: 0.975, test accuracy:0.973\n",
      "Epoch 514: \n",
      " Loss value: 0.45879724621772766, train accuracy: 0.975, test accuracy:0.974\n",
      "Epoch 515: \n",
      " Loss value: 0.45837900042533875, train accuracy: 0.976, test accuracy:0.974\n",
      "Epoch 516: \n",
      " Loss value: 0.45796167850494385, train accuracy: 0.976, test accuracy:0.974\n",
      "Epoch 517: \n",
      " Loss value: 0.4575452208518982, train accuracy: 0.977, test accuracy:0.974\n",
      "Epoch 518: \n",
      " Loss value: 0.45712971687316895, train accuracy: 0.977, test accuracy:0.974\n",
      "Epoch 519: \n",
      " Loss value: 0.4567151367664337, train accuracy: 0.978, test accuracy:0.974\n",
      "Epoch 520: \n",
      " Loss value: 0.45630139112472534, train accuracy: 0.978, test accuracy:0.974\n",
      "Epoch 521: \n",
      " Loss value: 0.455888569355011, train accuracy: 0.978, test accuracy:0.975\n",
      "Epoch 522: \n",
      " Loss value: 0.4554765820503235, train accuracy: 0.978, test accuracy:0.975\n",
      "Epoch 523: \n",
      " Loss value: 0.4550655484199524, train accuracy: 0.978, test accuracy:0.975\n",
      "Epoch 524: \n",
      " Loss value: 0.4546552896499634, train accuracy: 0.978, test accuracy:0.975\n",
      "Epoch 525: \n",
      " Loss value: 0.45424607396125793, train accuracy: 0.978, test accuracy:0.976\n",
      "Epoch 526: \n",
      " Loss value: 0.4538376033306122, train accuracy: 0.978, test accuracy:0.976\n",
      "Epoch 527: \n",
      " Loss value: 0.4534299969673157, train accuracy: 0.978, test accuracy:0.976\n",
      "Epoch 528: \n",
      " Loss value: 0.4530233144760132, train accuracy: 0.978, test accuracy:0.976\n",
      "Epoch 529: \n",
      " Loss value: 0.45261743664741516, train accuracy: 0.978, test accuracy:0.976\n",
      "Epoch 530: \n",
      " Loss value: 0.4522124230861664, train accuracy: 0.978, test accuracy:0.976\n",
      "Epoch 531: \n",
      " Loss value: 0.45180824398994446, train accuracy: 0.978, test accuracy:0.976\n",
      "Epoch 532: \n",
      " Loss value: 0.45140495896339417, train accuracy: 0.978, test accuracy:0.976\n",
      "Epoch 533: \n",
      " Loss value: 0.45100244879722595, train accuracy: 0.978, test accuracy:0.976\n",
      "Epoch 534: \n",
      " Loss value: 0.45060083270072937, train accuracy: 0.979, test accuracy:0.976\n",
      "Epoch 535: \n",
      " Loss value: 0.45020005106925964, train accuracy: 0.979, test accuracy:0.976\n",
      "Epoch 536: \n",
      " Loss value: 0.4498000741004944, train accuracy: 0.98, test accuracy:0.976\n",
      "Epoch 537: \n",
      " Loss value: 0.449400931596756, train accuracy: 0.981, test accuracy:0.976\n",
      "Epoch 538: \n",
      " Loss value: 0.44900256395339966, train accuracy: 0.981, test accuracy:0.976\n",
      "Epoch 539: \n",
      " Loss value: 0.44860509037971497, train accuracy: 0.981, test accuracy:0.976\n",
      "Epoch 540: \n",
      " Loss value: 0.44820836186408997, train accuracy: 0.981, test accuracy:0.977\n",
      "Epoch 541: \n",
      " Loss value: 0.4478124976158142, train accuracy: 0.981, test accuracy:0.977\n",
      "Epoch 542: \n",
      " Loss value: 0.4474174380302429, train accuracy: 0.983, test accuracy:0.978\n",
      "Epoch 543: \n",
      " Loss value: 0.4470231831073761, train accuracy: 0.983, test accuracy:0.978\n",
      "Epoch 544: \n",
      " Loss value: 0.44662970304489136, train accuracy: 0.984, test accuracy:0.978\n",
      "Epoch 545: \n",
      " Loss value: 0.4462369978427887, train accuracy: 0.984, test accuracy:0.978\n",
      "Epoch 546: \n",
      " Loss value: 0.4458451569080353, train accuracy: 0.984, test accuracy:0.978\n",
      "Epoch 547: \n",
      " Loss value: 0.44545403122901917, train accuracy: 0.984, test accuracy:0.978\n",
      "Epoch 548: \n",
      " Loss value: 0.4450637400150299, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 549: \n",
      " Loss value: 0.44467419385910034, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 550: \n",
      " Loss value: 0.44428545236587524, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 551: \n",
      " Loss value: 0.4438974857330322, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 552: \n",
      " Loss value: 0.4435103237628937, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 553: \n",
      " Loss value: 0.44312387704849243, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 554: \n",
      " Loss value: 0.4427381753921509, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 555: \n",
      " Loss value: 0.4423532783985138, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 556: \n",
      " Loss value: 0.4419691562652588, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 557: \n",
      " Loss value: 0.4415857195854187, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 558: \n",
      " Loss value: 0.4412030577659607, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 559: \n",
      " Loss value: 0.44082117080688477, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 560: \n",
      " Loss value: 0.44043999910354614, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 561: \n",
      " Loss value: 0.4400596022605896, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 562: \n",
      " Loss value: 0.4396798610687256, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 563: \n",
      " Loss value: 0.4393009543418884, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 564: \n",
      " Loss value: 0.4389227032661438, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 565: \n",
      " Loss value: 0.43854522705078125, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 566: \n",
      " Loss value: 0.438168466091156, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 567: \n",
      " Loss value: 0.4377923905849457, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 568: \n",
      " Loss value: 0.43741708993911743, train accuracy: 0.984, test accuracy:0.979\n",
      "Epoch 569: \n",
      " Loss value: 0.4370424747467041, train accuracy: 0.984, test accuracy:0.98\n",
      "Epoch 570: \n",
      " Loss value: 0.4366685450077057, train accuracy: 0.984, test accuracy:0.98\n",
      "Epoch 571: \n",
      " Loss value: 0.43629536032676697, train accuracy: 0.984, test accuracy:0.98\n",
      "Epoch 572: \n",
      " Loss value: 0.43592286109924316, train accuracy: 0.984, test accuracy:0.98\n",
      "Epoch 573: \n",
      " Loss value: 0.4355510175228119, train accuracy: 0.984, test accuracy:0.981\n",
      "Epoch 574: \n",
      " Loss value: 0.4351798892021179, train accuracy: 0.984, test accuracy:0.981\n",
      "Epoch 575: \n",
      " Loss value: 0.43480950593948364, train accuracy: 0.984, test accuracy:0.981\n",
      "Epoch 576: \n",
      " Loss value: 0.4344397783279419, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 577: \n",
      " Loss value: 0.43407076597213745, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 578: \n",
      " Loss value: 0.43370240926742554, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 579: \n",
      " Loss value: 0.4333347678184509, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 580: \n",
      " Loss value: 0.43296775221824646, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 581: \n",
      " Loss value: 0.4326014518737793, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 582: \n",
      " Loss value: 0.4322357773780823, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 583: \n",
      " Loss value: 0.43187084794044495, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 584: \n",
      " Loss value: 0.43150651454925537, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 585: \n",
      " Loss value: 0.4311428964138031, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 586: \n",
      " Loss value: 0.4307798743247986, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 587: \n",
      " Loss value: 0.430417537689209, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 588: \n",
      " Loss value: 0.4300558865070343, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 589: \n",
      " Loss value: 0.42969486117362976, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 590: \n",
      " Loss value: 0.42933446168899536, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 591: \n",
      " Loss value: 0.4289747178554535, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 592: \n",
      " Loss value: 0.42861565947532654, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 593: \n",
      " Loss value: 0.4282572269439697, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 594: \n",
      " Loss value: 0.42789942026138306, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 595: \n",
      " Loss value: 0.4275422692298889, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 596: \n",
      " Loss value: 0.42718571424484253, train accuracy: 0.984, test accuracy:0.983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 597: \n",
      " Loss value: 0.4268297553062439, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 598: \n",
      " Loss value: 0.4264744222164154, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 599: \n",
      " Loss value: 0.4261198043823242, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 600: \n",
      " Loss value: 0.4257657527923584, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 601: \n",
      " Loss value: 0.4254123568534851, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 602: \n",
      " Loss value: 0.4250594675540924, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 603: \n",
      " Loss value: 0.424707293510437, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 604: \n",
      " Loss value: 0.42435571551322937, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 605: \n",
      " Loss value: 0.4240046739578247, train accuracy: 0.984, test accuracy:0.982\n",
      "Epoch 606: \n",
      " Loss value: 0.4236542880535126, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 607: \n",
      " Loss value: 0.4233044683933258, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 608: \n",
      " Loss value: 0.42295533418655396, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 609: \n",
      " Loss value: 0.4226067066192627, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 610: \n",
      " Loss value: 0.4222586750984192, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 611: \n",
      " Loss value: 0.4219112694263458, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 612: \n",
      " Loss value: 0.42156440019607544, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 613: \n",
      " Loss value: 0.4212181270122528, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 614: \n",
      " Loss value: 0.4208725094795227, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 615: \n",
      " Loss value: 0.4205274283885956, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 616: \n",
      " Loss value: 0.4201829135417938, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 617: \n",
      " Loss value: 0.41983896493911743, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 618: \n",
      " Loss value: 0.4194956123828888, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 619: \n",
      " Loss value: 0.41915279626846313, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 620: \n",
      " Loss value: 0.41881054639816284, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 621: \n",
      " Loss value: 0.4184689223766327, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 622: \n",
      " Loss value: 0.41812777519226074, train accuracy: 0.984, test accuracy:0.983\n",
      "Epoch 623: \n",
      " Loss value: 0.41778722405433655, train accuracy: 0.984, test accuracy:0.984\n",
      "Epoch 624: \n",
      " Loss value: 0.41744720935821533, train accuracy: 0.984, test accuracy:0.985\n",
      "Epoch 625: \n",
      " Loss value: 0.41710782051086426, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 626: \n",
      " Loss value: 0.4167689085006714, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 627: \n",
      " Loss value: 0.41643059253692627, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 628: \n",
      " Loss value: 0.41609278321266174, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 629: \n",
      " Loss value: 0.4157554805278778, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 630: \n",
      " Loss value: 0.4154188334941864, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 631: \n",
      " Loss value: 0.4150826334953308, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 632: \n",
      " Loss value: 0.4147469997406006, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 633: \n",
      " Loss value: 0.41441190242767334, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 634: \n",
      " Loss value: 0.4140773415565491, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 635: \n",
      " Loss value: 0.4137432873249054, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 636: \n",
      " Loss value: 0.4134097695350647, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 637: \n",
      " Loss value: 0.41307681798934937, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 638: \n",
      " Loss value: 0.41274434328079224, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 639: \n",
      " Loss value: 0.4124124050140381, train accuracy: 0.985, test accuracy:0.985\n",
      "Epoch 640: \n",
      " Loss value: 0.4120810031890869, train accuracy: 0.985, test accuracy:0.986\n",
      "Epoch 641: \n",
      " Loss value: 0.41175007820129395, train accuracy: 0.985, test accuracy:0.986\n",
      "Epoch 642: \n",
      " Loss value: 0.41141971945762634, train accuracy: 0.985, test accuracy:0.986\n",
      "Epoch 643: \n",
      " Loss value: 0.41108980774879456, train accuracy: 0.985, test accuracy:0.986\n",
      "Epoch 644: \n",
      " Loss value: 0.41076043248176575, train accuracy: 0.985, test accuracy:0.987\n",
      "Epoch 645: \n",
      " Loss value: 0.4104315936565399, train accuracy: 0.986, test accuracy:0.987\n",
      "Epoch 646: \n",
      " Loss value: 0.4101031422615051, train accuracy: 0.986, test accuracy:0.987\n",
      "Epoch 647: \n",
      " Loss value: 0.40977534651756287, train accuracy: 0.986, test accuracy:0.987\n",
      "Epoch 648: \n",
      " Loss value: 0.40944793820381165, train accuracy: 0.986, test accuracy:0.987\n",
      "Epoch 649: \n",
      " Loss value: 0.4091211259365082, train accuracy: 0.987, test accuracy:0.987\n",
      "Epoch 650: \n",
      " Loss value: 0.40879470109939575, train accuracy: 0.987, test accuracy:0.987\n",
      "Epoch 651: \n",
      " Loss value: 0.4084688425064087, train accuracy: 0.987, test accuracy:0.987\n",
      "Epoch 652: \n",
      " Loss value: 0.4081434905529022, train accuracy: 0.987, test accuracy:0.987\n",
      "Epoch 653: \n",
      " Loss value: 0.40781864523887634, train accuracy: 0.987, test accuracy:0.987\n",
      "Epoch 654: \n",
      " Loss value: 0.4074941575527191, train accuracy: 0.987, test accuracy:0.987\n",
      "Epoch 655: \n",
      " Loss value: 0.40717026591300964, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 656: \n",
      " Loss value: 0.406846821308136, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 657: \n",
      " Loss value: 0.40652385354042053, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 658: \n",
      " Loss value: 0.4062013626098633, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 659: \n",
      " Loss value: 0.40587928891181946, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 660: \n",
      " Loss value: 0.4055578112602234, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 661: \n",
      " Loss value: 0.40523675084114075, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 662: \n",
      " Loss value: 0.4049161672592163, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 663: \n",
      " Loss value: 0.4045960307121277, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 664: \n",
      " Loss value: 0.40427637100219727, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 665: \n",
      " Loss value: 0.40395718812942505, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 666: \n",
      " Loss value: 0.40363848209381104, train accuracy: 0.987, test accuracy:0.986\n",
      "Epoch 667: \n",
      " Loss value: 0.40332022309303284, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 668: \n",
      " Loss value: 0.40300241112709045, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 669: \n",
      " Loss value: 0.4026850461959839, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 670: \n",
      " Loss value: 0.4023681581020355, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 671: \n",
      " Loss value: 0.4020516872406006, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 672: \n",
      " Loss value: 0.40173572301864624, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 673: \n",
      " Loss value: 0.4014202356338501, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 674: \n",
      " Loss value: 0.4011051058769226, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 675: \n",
      " Loss value: 0.40079042315483093, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 676: \n",
      " Loss value: 0.40047621726989746, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 677: \n",
      " Loss value: 0.4001624286174774, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 678: \n",
      " Loss value: 0.3998491168022156, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 679: \n",
      " Loss value: 0.39953625202178955, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 680: \n",
      " Loss value: 0.39922377467155457, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 681: \n",
      " Loss value: 0.3989117443561554, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 682: \n",
      " Loss value: 0.39860016107559204, train accuracy: 0.988, test accuracy:0.986\n",
      "Epoch 683: \n",
      " Loss value: 0.3982889950275421, train accuracy: 0.989, test accuracy:0.986\n",
      "Epoch 684: \n",
      " Loss value: 0.3979782462120056, train accuracy: 0.989, test accuracy:0.986\n",
      "Epoch 685: \n",
      " Loss value: 0.3976679742336273, train accuracy: 0.989, test accuracy:0.986\n",
      "Epoch 686: \n",
      " Loss value: 0.39735808968544006, train accuracy: 0.989, test accuracy:0.986\n",
      "Epoch 687: \n",
      " Loss value: 0.39704862236976624, train accuracy: 0.989, test accuracy:0.986\n",
      "Epoch 688: \n",
      " Loss value: 0.39673951268196106, train accuracy: 0.989, test accuracy:0.986\n",
      "Epoch 689: \n",
      " Loss value: 0.3964309096336365, train accuracy: 0.989, test accuracy:0.986\n",
      "Epoch 690: \n",
      " Loss value: 0.39612269401550293, train accuracy: 0.989, test accuracy:0.986\n",
      "Epoch 691: \n",
      " Loss value: 0.3958149254322052, train accuracy: 0.989, test accuracy:0.986\n",
      "Epoch 692: \n",
      " Loss value: 0.3955075442790985, train accuracy: 0.989, test accuracy:0.986\n",
      "Epoch 693: \n",
      " Loss value: 0.39520058035850525, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 694: \n",
      " Loss value: 0.394894003868103, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 695: \n",
      " Loss value: 0.39458781480789185, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 696: \n",
      " Loss value: 0.3942820727825165, train accuracy: 0.989, test accuracy:0.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697: \n",
      " Loss value: 0.39397677779197693, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 698: \n",
      " Loss value: 0.39367184042930603, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 699: \n",
      " Loss value: 0.3933672606945038, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 700: \n",
      " Loss value: 0.39306312799453735, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 701: \n",
      " Loss value: 0.39275941252708435, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 702: \n",
      " Loss value: 0.3924560844898224, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 703: \n",
      " Loss value: 0.39215314388275146, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 704: \n",
      " Loss value: 0.3918505907058716, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 705: \n",
      " Loss value: 0.39154839515686035, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 706: \n",
      " Loss value: 0.39124658703804016, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 707: \n",
      " Loss value: 0.3909452557563782, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 708: \n",
      " Loss value: 0.39064422249794006, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 709: \n",
      " Loss value: 0.3903436064720154, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 710: \n",
      " Loss value: 0.39004337787628174, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 711: \n",
      " Loss value: 0.3897435665130615, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 712: \n",
      " Loss value: 0.3894440531730652, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 713: \n",
      " Loss value: 0.38914498686790466, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 714: \n",
      " Loss value: 0.3888462483882904, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 715: \n",
      " Loss value: 0.3885479271411896, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 716: \n",
      " Loss value: 0.388249933719635, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 717: \n",
      " Loss value: 0.3879523277282715, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 718: \n",
      " Loss value: 0.387655109167099, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 719: \n",
      " Loss value: 0.38735827803611755, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 720: \n",
      " Loss value: 0.38706183433532715, train accuracy: 0.989, test accuracy:0.987\n",
      "Epoch 721: \n",
      " Loss value: 0.38676565885543823, train accuracy: 0.989, test accuracy:0.988\n",
      "Epoch 722: \n",
      " Loss value: 0.38646990060806274, train accuracy: 0.989, test accuracy:0.988\n",
      "Epoch 723: \n",
      " Loss value: 0.3861745297908783, train accuracy: 0.989, test accuracy:0.988\n",
      "Epoch 724: \n",
      " Loss value: 0.3858795166015625, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 725: \n",
      " Loss value: 0.3855848014354706, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 726: \n",
      " Loss value: 0.3852905333042145, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 727: \n",
      " Loss value: 0.38499659299850464, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 728: \n",
      " Loss value: 0.38470298051834106, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 729: \n",
      " Loss value: 0.38440969586372375, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 730: \n",
      " Loss value: 0.3841167986392975, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 731: \n",
      " Loss value: 0.3838242292404175, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 732: \n",
      " Loss value: 0.3835320770740509, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 733: \n",
      " Loss value: 0.3832401633262634, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 734: \n",
      " Loss value: 0.3829486668109894, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 735: \n",
      " Loss value: 0.382657527923584, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 736: \n",
      " Loss value: 0.38236674666404724, train accuracy: 0.99, test accuracy:0.988\n",
      "Epoch 737: \n",
      " Loss value: 0.382076233625412, train accuracy: 0.99, test accuracy:0.989\n",
      "Epoch 738: \n",
      " Loss value: 0.38178613781929016, train accuracy: 0.99, test accuracy:0.989\n",
      "Epoch 739: \n",
      " Loss value: 0.3814963400363922, train accuracy: 0.99, test accuracy:0.989\n",
      "Epoch 740: \n",
      " Loss value: 0.3812068998813629, train accuracy: 0.99, test accuracy:0.989\n",
      "Epoch 741: \n",
      " Loss value: 0.3809177577495575, train accuracy: 0.99, test accuracy:0.989\n",
      "Epoch 742: \n",
      " Loss value: 0.3806290328502655, train accuracy: 0.99, test accuracy:0.989\n",
      "Epoch 743: \n",
      " Loss value: 0.3803405463695526, train accuracy: 0.99, test accuracy:0.989\n",
      "Epoch 744: \n",
      " Loss value: 0.3800524175167084, train accuracy: 0.99, test accuracy:0.989\n",
      "Epoch 745: \n",
      " Loss value: 0.37976470589637756, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 746: \n",
      " Loss value: 0.37947726249694824, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 747: \n",
      " Loss value: 0.3791901171207428, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 748: \n",
      " Loss value: 0.3789033591747284, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 749: \n",
      " Loss value: 0.37861689925193787, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 750: \n",
      " Loss value: 0.3783307373523712, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 751: \n",
      " Loss value: 0.3780449628829956, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 752: \n",
      " Loss value: 0.37775948643684387, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 753: \n",
      " Loss value: 0.3774743378162384, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 754: \n",
      " Loss value: 0.3771895170211792, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 755: \n",
      " Loss value: 0.3769049644470215, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 756: \n",
      " Loss value: 0.3766207993030548, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 757: \n",
      " Loss value: 0.3763369023799896, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 758: \n",
      " Loss value: 0.3760533034801483, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 759: \n",
      " Loss value: 0.37577006220817566, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 760: \n",
      " Loss value: 0.3754871189594269, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 761: \n",
      " Loss value: 0.37520450353622437, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 762: \n",
      " Loss value: 0.3749221861362457, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 763: \n",
      " Loss value: 0.37464016675949097, train accuracy: 0.991, test accuracy:0.989\n",
      "Epoch 764: \n",
      " Loss value: 0.3743584454059601, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 765: \n",
      " Loss value: 0.37407705187797546, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 766: \n",
      " Loss value: 0.3737959861755371, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 767: \n",
      " Loss value: 0.37351518869400024, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 768: \n",
      " Loss value: 0.37323468923568726, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 769: \n",
      " Loss value: 0.37295448780059814, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 770: \n",
      " Loss value: 0.3726746439933777, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 771: \n",
      " Loss value: 0.3723950684070587, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 772: \n",
      " Loss value: 0.37211576104164124, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 773: \n",
      " Loss value: 0.37183678150177, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 774: \n",
      " Loss value: 0.37155812978744507, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 775: \n",
      " Loss value: 0.3712797164916992, train accuracy: 0.991, test accuracy:0.99\n",
      "Epoch 776: \n",
      " Loss value: 0.371001660823822, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 777: \n",
      " Loss value: 0.3707238733768463, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 778: \n",
      " Loss value: 0.3704463243484497, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 779: \n",
      " Loss value: 0.37016913294792175, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 780: \n",
      " Loss value: 0.3698922097682953, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 781: \n",
      " Loss value: 0.3696156144142151, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 782: \n",
      " Loss value: 0.369339257478714, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 783: \n",
      " Loss value: 0.369063138961792, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 784: \n",
      " Loss value: 0.36878740787506104, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 785: \n",
      " Loss value: 0.36851194500923157, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 786: \n",
      " Loss value: 0.3682367205619812, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 787: \n",
      " Loss value: 0.3679618239402771, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 788: \n",
      " Loss value: 0.3676871657371521, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 789: \n",
      " Loss value: 0.3674127757549286, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 790: \n",
      " Loss value: 0.36713871359825134, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 791: \n",
      " Loss value: 0.3668648898601532, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 792: \n",
      " Loss value: 0.3665913939476013, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 793: \n",
      " Loss value: 0.36631813645362854, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 794: \n",
      " Loss value: 0.36604514718055725, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 795: \n",
      " Loss value: 0.3657724857330322, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 796: \n",
      " Loss value: 0.3655000627040863, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 797: \n",
      " Loss value: 0.36522790789604187, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 798: \n",
      " Loss value: 0.3649560213088989, train accuracy: 0.992, test accuracy:0.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799: \n",
      " Loss value: 0.36468440294265747, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 800: \n",
      " Loss value: 0.3644130825996399, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 801: \n",
      " Loss value: 0.3641420006752014, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 802: \n",
      " Loss value: 0.3638712167739868, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 803: \n",
      " Loss value: 0.3636006712913513, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 804: \n",
      " Loss value: 0.3633304536342621, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 805: \n",
      " Loss value: 0.3630604147911072, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 806: \n",
      " Loss value: 0.36279070377349854, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 807: \n",
      " Loss value: 0.3625212013721466, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 808: \n",
      " Loss value: 0.36225199699401855, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 809: \n",
      " Loss value: 0.3619830310344696, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 810: \n",
      " Loss value: 0.36171436309814453, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 811: \n",
      " Loss value: 0.36144593358039856, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 812: \n",
      " Loss value: 0.36117780208587646, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 813: \n",
      " Loss value: 0.3609098494052887, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 814: \n",
      " Loss value: 0.3606421947479248, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 815: \n",
      " Loss value: 0.3603748083114624, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 816: \n",
      " Loss value: 0.3601076602935791, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 817: \n",
      " Loss value: 0.3598407506942749, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 818: \n",
      " Loss value: 0.3595741391181946, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 819: \n",
      " Loss value: 0.35930773615837097, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 820: \n",
      " Loss value: 0.35904163122177124, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 821: \n",
      " Loss value: 0.35877570509910583, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 822: \n",
      " Loss value: 0.3585101068019867, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 823: \n",
      " Loss value: 0.35824474692344666, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 824: \n",
      " Loss value: 0.3579796254634857, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 825: \n",
      " Loss value: 0.3577147126197815, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 826: \n",
      " Loss value: 0.35745006799697876, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 827: \n",
      " Loss value: 0.3571856617927551, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 828: \n",
      " Loss value: 0.3569214940071106, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 829: \n",
      " Loss value: 0.35665762424468994, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 830: \n",
      " Loss value: 0.3563939929008484, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 831: \n",
      " Loss value: 0.35613054037094116, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 832: \n",
      " Loss value: 0.3558673560619354, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 833: \n",
      " Loss value: 0.35560446977615356, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 834: \n",
      " Loss value: 0.35534176230430603, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 835: \n",
      " Loss value: 0.35507932305336, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 836: \n",
      " Loss value: 0.35481712222099304, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 837: \n",
      " Loss value: 0.3545551002025604, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 838: \n",
      " Loss value: 0.35429346561431885, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 839: \n",
      " Loss value: 0.3540319502353668, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 840: \n",
      " Loss value: 0.3537706434726715, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 841: \n",
      " Loss value: 0.3535096347332001, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 842: \n",
      " Loss value: 0.35324880480766296, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 843: \n",
      " Loss value: 0.35298827290534973, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 844: \n",
      " Loss value: 0.3527279496192932, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 845: \n",
      " Loss value: 0.3524678349494934, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 846: \n",
      " Loss value: 0.3522080183029175, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 847: \n",
      " Loss value: 0.3519483506679535, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 848: \n",
      " Loss value: 0.3516889810562134, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 849: \n",
      " Loss value: 0.35142982006073, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 850: \n",
      " Loss value: 0.3511708974838257, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 851: \n",
      " Loss value: 0.3509121835231781, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 852: \n",
      " Loss value: 0.35065364837646484, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 853: \n",
      " Loss value: 0.35039544105529785, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 854: \n",
      " Loss value: 0.3501373827457428, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 855: \n",
      " Loss value: 0.3498796224594116, train accuracy: 0.992, test accuracy:0.99\n",
      "Epoch 856: \n",
      " Loss value: 0.34962204098701477, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 857: \n",
      " Loss value: 0.349364697933197, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 858: \n",
      " Loss value: 0.3491075336933136, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 859: \n",
      " Loss value: 0.34885066747665405, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 860: \n",
      " Loss value: 0.3485940098762512, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 861: \n",
      " Loss value: 0.3483375310897827, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 862: \n",
      " Loss value: 0.3480812907218933, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 863: \n",
      " Loss value: 0.3478252589702606, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 864: \n",
      " Loss value: 0.34756946563720703, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 865: \n",
      " Loss value: 0.34731388092041016, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 866: \n",
      " Loss value: 0.3470584750175476, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 867: \n",
      " Loss value: 0.34680330753326416, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 868: \n",
      " Loss value: 0.3465484082698822, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 869: \n",
      " Loss value: 0.3462936282157898, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 870: \n",
      " Loss value: 0.34603917598724365, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 871: \n",
      " Loss value: 0.34578490257263184, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 872: \n",
      " Loss value: 0.34553080797195435, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 873: \n",
      " Loss value: 0.34527698159217834, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 874: \n",
      " Loss value: 0.3450232744216919, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 875: \n",
      " Loss value: 0.3447698950767517, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 876: \n",
      " Loss value: 0.34451669454574585, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 877: \n",
      " Loss value: 0.3442636728286743, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 878: \n",
      " Loss value: 0.3440109193325043, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 879: \n",
      " Loss value: 0.34375834465026855, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 880: \n",
      " Loss value: 0.34350597858428955, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 881: \n",
      " Loss value: 0.34325385093688965, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 882: \n",
      " Loss value: 0.3430019021034241, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 883: \n",
      " Loss value: 0.3427501618862152, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 884: \n",
      " Loss value: 0.34249863028526306, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 885: \n",
      " Loss value: 0.3422473073005676, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 886: \n",
      " Loss value: 0.3419961929321289, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 887: \n",
      " Loss value: 0.3417453169822693, train accuracy: 0.992, test accuracy:0.991\n",
      "Epoch 888: \n",
      " Loss value: 0.341494619846344, train accuracy: 0.993, test accuracy:0.991\n",
      "Epoch 889: \n",
      " Loss value: 0.3412441313266754, train accuracy: 0.993, test accuracy:0.991\n",
      "Epoch 890: \n",
      " Loss value: 0.34099382162094116, train accuracy: 0.993, test accuracy:0.991\n",
      "Epoch 891: \n",
      " Loss value: 0.3407437801361084, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 892: \n",
      " Loss value: 0.3404938876628876, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 893: \n",
      " Loss value: 0.3402441740036011, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 894: \n",
      " Loss value: 0.3399946987628937, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 895: \n",
      " Loss value: 0.339745432138443, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 896: \n",
      " Loss value: 0.339496374130249, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 897: \n",
      " Loss value: 0.3392474949359894, train accuracy: 0.993, test accuracy:0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 898: \n",
      " Loss value: 0.33899882435798645, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 899: \n",
      " Loss value: 0.33875033259391785, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 900: \n",
      " Loss value: 0.3385021388530731, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 901: \n",
      " Loss value: 0.33825403451919556, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 902: \n",
      " Loss value: 0.3380061388015747, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 903: \n",
      " Loss value: 0.33775851130485535, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 904: \n",
      " Loss value: 0.33751100301742554, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 905: \n",
      " Loss value: 0.3372637629508972, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 906: \n",
      " Loss value: 0.3370167016983032, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 907: \n",
      " Loss value: 0.33676981925964355, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 908: \n",
      " Loss value: 0.3365231454372406, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 909: \n",
      " Loss value: 0.33627668023109436, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 910: \n",
      " Loss value: 0.33603039383888245, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 911: \n",
      " Loss value: 0.335784375667572, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 912: \n",
      " Loss value: 0.33553844690322876, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 913: \n",
      " Loss value: 0.3352927267551422, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 914: \n",
      " Loss value: 0.33504727482795715, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 915: \n",
      " Loss value: 0.33480191230773926, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 916: \n",
      " Loss value: 0.3345567584037781, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 917: \n",
      " Loss value: 0.334311842918396, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 918: \n",
      " Loss value: 0.33406710624694824, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 919: \n",
      " Loss value: 0.3338225781917572, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 920: \n",
      " Loss value: 0.3335782289505005, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 921: \n",
      " Loss value: 0.3333340585231781, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 922: \n",
      " Loss value: 0.3330901265144348, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 923: \n",
      " Loss value: 0.3328463137149811, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 924: \n",
      " Loss value: 0.33260270953178406, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 925: \n",
      " Loss value: 0.33235934376716614, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 926: \n",
      " Loss value: 0.33211612701416016, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 927: \n",
      " Loss value: 0.3318730890750885, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 928: \n",
      " Loss value: 0.33163025975227356, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 929: \n",
      " Loss value: 0.33138763904571533, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 930: \n",
      " Loss value: 0.33114516735076904, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 931: \n",
      " Loss value: 0.33090293407440186, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 932: \n",
      " Loss value: 0.3306608200073242, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 933: \n",
      " Loss value: 0.33041897416114807, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 934: \n",
      " Loss value: 0.33017730712890625, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 935: \n",
      " Loss value: 0.32993578910827637, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 936: \n",
      " Loss value: 0.3296944499015808, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 937: \n",
      " Loss value: 0.32945331931114197, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 938: \n",
      " Loss value: 0.3292123079299927, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 939: \n",
      " Loss value: 0.3289715349674225, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 940: \n",
      " Loss value: 0.3287309408187866, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 941: \n",
      " Loss value: 0.3284904956817627, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 942: \n",
      " Loss value: 0.32825031876564026, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 943: \n",
      " Loss value: 0.3280102610588074, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 944: \n",
      " Loss value: 0.3277703821659088, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 945: \n",
      " Loss value: 0.32753074169158936, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 946: \n",
      " Loss value: 0.32729119062423706, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 947: \n",
      " Loss value: 0.32705193758010864, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 948: \n",
      " Loss value: 0.3268128037452698, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 949: \n",
      " Loss value: 0.32657384872436523, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 950: \n",
      " Loss value: 0.326335072517395, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 951: \n",
      " Loss value: 0.3260965049266815, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 952: \n",
      " Loss value: 0.32585808634757996, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 953: \n",
      " Loss value: 0.3256199061870575, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 954: \n",
      " Loss value: 0.32538190484046936, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 955: \n",
      " Loss value: 0.32514405250549316, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 956: \n",
      " Loss value: 0.3249063789844513, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 957: \n",
      " Loss value: 0.324668824672699, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 958: \n",
      " Loss value: 0.32443156838417053, train accuracy: 0.992, test accuracy:0.992\n",
      "Epoch 959: \n",
      " Loss value: 0.32419440150260925, train accuracy: 0.992, test accuracy:0.992\n",
      "Epoch 960: \n",
      " Loss value: 0.3239574730396271, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 961: \n",
      " Loss value: 0.32372063398361206, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 962: \n",
      " Loss value: 0.32348400354385376, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 963: \n",
      " Loss value: 0.3232475817203522, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 964: \n",
      " Loss value: 0.3230113387107849, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 965: \n",
      " Loss value: 0.3227752149105072, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 966: \n",
      " Loss value: 0.3225393295288086, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 967: \n",
      " Loss value: 0.3223036527633667, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 968: \n",
      " Loss value: 0.32206812500953674, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 969: \n",
      " Loss value: 0.3218327462673187, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 970: \n",
      " Loss value: 0.32159754633903503, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 971: \n",
      " Loss value: 0.32136252522468567, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 972: \n",
      " Loss value: 0.32112768292427063, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 973: \n",
      " Loss value: 0.3208930492401123, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 974: \n",
      " Loss value: 0.32065853476524353, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 975: \n",
      " Loss value: 0.32042425870895386, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 976: \n",
      " Loss value: 0.3201901316642761, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 977: \n",
      " Loss value: 0.3199561834335327, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 978: \n",
      " Loss value: 0.31972238421440125, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 979: \n",
      " Loss value: 0.3194887936115265, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 980: \n",
      " Loss value: 0.31925538182258606, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 981: \n",
      " Loss value: 0.3190220296382904, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 982: \n",
      " Loss value: 0.31878894567489624, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 983: \n",
      " Loss value: 0.3185560405254364, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 984: \n",
      " Loss value: 0.3183232843875885, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 985: \n",
      " Loss value: 0.3180907070636749, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 986: \n",
      " Loss value: 0.3178582787513733, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 987: \n",
      " Loss value: 0.31762608885765076, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 988: \n",
      " Loss value: 0.3173940181732178, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 989: \n",
      " Loss value: 0.31716209650039673, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 990: \n",
      " Loss value: 0.3169303834438324, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 991: \n",
      " Loss value: 0.3166988492012024, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 992: \n",
      " Loss value: 0.3164674937725067, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 993: \n",
      " Loss value: 0.316236287355423, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 994: \n",
      " Loss value: 0.31600528955459595, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 995: \n",
      " Loss value: 0.31577444076538086, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 996: \n",
      " Loss value: 0.3155437409877777, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 997: \n",
      " Loss value: 0.3153132200241089, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 998: \n",
      " Loss value: 0.31508293747901917, train accuracy: 0.993, test accuracy:0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999: \n",
      " Loss value: 0.3148527443408966, train accuracy: 0.993, test accuracy:0.992\n",
      "Epoch 1000: \n",
      " Loss value: 0.3146227300167084, train accuracy: 0.993, test accuracy:0.992\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "# Instantiate an optimizer to train the model.\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model1(X_train)\n",
    "        loss_value = loss_fn(y_train, preds)\n",
    "    grads = tape.gradient(loss_value, model1.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model1.trainable_variables))\n",
    "    train_accuracy = accuracy_score(np.where(preds.numpy()>0.5,1,0), y_train.numpy())\n",
    "    test_preds = model1(X_test)\n",
    "    test_accuracy = accuracy_score(np.where(test_preds.numpy()>0.5,1,0), y_test)\n",
    "    print(f\"Epoch {epoch+1}: \\n Loss value: {loss_value}, train accuracy: {train_accuracy}, test accuracy:{test_accuracy}\")\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4d0f78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = []\n",
    "B = []\n",
    "deltas_w = []\n",
    "deltas_b = []\n",
    "\n",
    "for layer in model1.layers:\n",
    "    W.append(layer.w)\n",
    "    B.append(layer.b)\n",
    "    deltas_w.append(tf.random.normal(shape=layer.w.shape))\n",
    "    deltas_b.append(tf.random.normal(shape=layer.b.shape))\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "bb3c09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 500\n",
    "step = 0.1\n",
    "alphas = list(np.arange(-limit,0, step)) + list(np.arange(0, limit, step))\n",
    "losses = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    \n",
    "    W_m = []\n",
    "    B_m = []\n",
    "\n",
    "    for l in range(len(W)):\n",
    "        w_m = W[l] + alpha * deltas_w[l]\n",
    "        b_m = B[l] + alpha * deltas_b[l]\n",
    "        W_m.append(w_m)\n",
    "        B_m.append(b_m)\n",
    "        \n",
    "    predicted = model1(X_train, W_m, B_m)\n",
    "    loss_value = loss_fn(y_train, predicted)\n",
    "    losses.append(loss_value.numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "50c6e781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "7f334db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "636afb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.lineplot(x=alphas, y=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "8e68b682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.33080345>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model1(X_train, W_m, B_m)\n",
    "loss_value = loss_fn(y_train, predicted)\n",
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0b75d12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.3143929>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model1(X_train, W, B)\n",
    "loss_value = loss_fn(y_train, predicted)\n",
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f86c86ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.33080345>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3b00848a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-10.0,\n",
       " -9.99,\n",
       " -9.98,\n",
       " -9.97,\n",
       " -9.96,\n",
       " -9.950000000000001,\n",
       " -9.940000000000001,\n",
       " -9.930000000000001,\n",
       " -9.920000000000002,\n",
       " -9.910000000000002,\n",
       " -9.900000000000002,\n",
       " -9.890000000000002,\n",
       " -9.880000000000003,\n",
       " -9.870000000000003,\n",
       " -9.860000000000003,\n",
       " -9.850000000000003,\n",
       " -9.840000000000003,\n",
       " -9.830000000000004,\n",
       " -9.820000000000004,\n",
       " -9.810000000000004,\n",
       " -9.800000000000004,\n",
       " -9.790000000000004,\n",
       " -9.780000000000005,\n",
       " -9.770000000000005,\n",
       " -9.760000000000005,\n",
       " -9.750000000000005,\n",
       " -9.740000000000006,\n",
       " -9.730000000000006,\n",
       " -9.720000000000006,\n",
       " -9.710000000000006,\n",
       " -9.700000000000006,\n",
       " -9.690000000000007,\n",
       " -9.680000000000007,\n",
       " -9.670000000000007,\n",
       " -9.660000000000007,\n",
       " -9.650000000000007,\n",
       " -9.640000000000008,\n",
       " -9.630000000000008,\n",
       " -9.620000000000008,\n",
       " -9.610000000000008,\n",
       " -9.600000000000009,\n",
       " -9.590000000000009,\n",
       " -9.580000000000009,\n",
       " -9.57000000000001,\n",
       " -9.56000000000001,\n",
       " -9.55000000000001,\n",
       " -9.54000000000001,\n",
       " -9.53000000000001,\n",
       " -9.52000000000001,\n",
       " -9.51000000000001,\n",
       " -9.50000000000001,\n",
       " -9.49000000000001,\n",
       " -9.480000000000011,\n",
       " -9.470000000000011,\n",
       " -9.460000000000012,\n",
       " -9.450000000000012,\n",
       " -9.440000000000012,\n",
       " -9.430000000000012,\n",
       " -9.420000000000012,\n",
       " -9.410000000000013,\n",
       " -9.400000000000013,\n",
       " -9.390000000000013,\n",
       " -9.380000000000013,\n",
       " -9.370000000000013,\n",
       " -9.360000000000014,\n",
       " -9.350000000000014,\n",
       " -9.340000000000014,\n",
       " -9.330000000000014,\n",
       " -9.320000000000014,\n",
       " -9.310000000000015,\n",
       " -9.300000000000015,\n",
       " -9.290000000000015,\n",
       " -9.280000000000015,\n",
       " -9.270000000000016,\n",
       " -9.260000000000016,\n",
       " -9.250000000000016,\n",
       " -9.240000000000016,\n",
       " -9.230000000000016,\n",
       " -9.220000000000017,\n",
       " -9.210000000000017,\n",
       " -9.200000000000017,\n",
       " -9.190000000000017,\n",
       " -9.180000000000017,\n",
       " -9.170000000000018,\n",
       " -9.160000000000018,\n",
       " -9.150000000000018,\n",
       " -9.140000000000018,\n",
       " -9.130000000000019,\n",
       " -9.120000000000019,\n",
       " -9.110000000000019,\n",
       " -9.10000000000002,\n",
       " -9.09000000000002,\n",
       " -9.08000000000002,\n",
       " -9.07000000000002,\n",
       " -9.06000000000002,\n",
       " -9.05000000000002,\n",
       " -9.04000000000002,\n",
       " -9.03000000000002,\n",
       " -9.020000000000021,\n",
       " -9.010000000000021,\n",
       " -9.000000000000021,\n",
       " -8.990000000000022,\n",
       " -8.980000000000022,\n",
       " -8.970000000000022,\n",
       " -8.960000000000022,\n",
       " -8.950000000000022,\n",
       " -8.940000000000023,\n",
       " -8.930000000000023,\n",
       " -8.920000000000023,\n",
       " -8.910000000000023,\n",
       " -8.900000000000023,\n",
       " -8.890000000000024,\n",
       " -8.880000000000024,\n",
       " -8.870000000000024,\n",
       " -8.860000000000024,\n",
       " -8.850000000000025,\n",
       " -8.840000000000025,\n",
       " -8.830000000000025,\n",
       " -8.820000000000025,\n",
       " -8.810000000000025,\n",
       " -8.800000000000026,\n",
       " -8.790000000000026,\n",
       " -8.780000000000026,\n",
       " -8.770000000000026,\n",
       " -8.760000000000026,\n",
       " -8.750000000000027,\n",
       " -8.740000000000027,\n",
       " -8.730000000000027,\n",
       " -8.720000000000027,\n",
       " -8.710000000000027,\n",
       " -8.700000000000028,\n",
       " -8.690000000000028,\n",
       " -8.680000000000028,\n",
       " -8.670000000000028,\n",
       " -8.660000000000029,\n",
       " -8.650000000000029,\n",
       " -8.640000000000029,\n",
       " -8.63000000000003,\n",
       " -8.62000000000003,\n",
       " -8.61000000000003,\n",
       " -8.60000000000003,\n",
       " -8.59000000000003,\n",
       " -8.58000000000003,\n",
       " -8.57000000000003,\n",
       " -8.56000000000003,\n",
       " -8.550000000000031,\n",
       " -8.540000000000031,\n",
       " -8.530000000000031,\n",
       " -8.520000000000032,\n",
       " -8.510000000000032,\n",
       " -8.500000000000032,\n",
       " -8.490000000000032,\n",
       " -8.480000000000032,\n",
       " -8.470000000000033,\n",
       " -8.460000000000033,\n",
       " -8.450000000000033,\n",
       " -8.440000000000033,\n",
       " -8.430000000000033,\n",
       " -8.420000000000034,\n",
       " -8.410000000000034,\n",
       " -8.400000000000034,\n",
       " -8.390000000000034,\n",
       " -8.380000000000035,\n",
       " -8.370000000000035,\n",
       " -8.360000000000035,\n",
       " -8.350000000000035,\n",
       " -8.340000000000035,\n",
       " -8.330000000000036,\n",
       " -8.320000000000036,\n",
       " -8.310000000000036,\n",
       " -8.300000000000036,\n",
       " -8.290000000000036,\n",
       " -8.280000000000037,\n",
       " -8.270000000000037,\n",
       " -8.260000000000037,\n",
       " -8.250000000000037,\n",
       " -8.240000000000038,\n",
       " -8.230000000000038,\n",
       " -8.220000000000038,\n",
       " -8.210000000000038,\n",
       " -8.200000000000038,\n",
       " -8.190000000000039,\n",
       " -8.180000000000039,\n",
       " -8.170000000000039,\n",
       " -8.16000000000004,\n",
       " -8.15000000000004,\n",
       " -8.14000000000004,\n",
       " -8.13000000000004,\n",
       " -8.12000000000004,\n",
       " -8.11000000000004,\n",
       " -8.10000000000004,\n",
       " -8.09000000000004,\n",
       " -8.080000000000041,\n",
       " -8.070000000000041,\n",
       " -8.060000000000041,\n",
       " -8.050000000000042,\n",
       " -8.040000000000042,\n",
       " -8.030000000000042,\n",
       " -8.020000000000042,\n",
       " -8.010000000000042,\n",
       " -8.000000000000043,\n",
       " -7.990000000000043,\n",
       " -7.980000000000043,\n",
       " -7.970000000000043,\n",
       " -7.9600000000000435,\n",
       " -7.950000000000044,\n",
       " -7.940000000000044,\n",
       " -7.930000000000044,\n",
       " -7.920000000000044,\n",
       " -7.9100000000000446,\n",
       " -7.900000000000045,\n",
       " -7.890000000000045,\n",
       " -7.880000000000045,\n",
       " -7.870000000000045,\n",
       " -7.860000000000046,\n",
       " -7.850000000000046,\n",
       " -7.840000000000046,\n",
       " -7.830000000000046,\n",
       " -7.8200000000000465,\n",
       " -7.810000000000047,\n",
       " -7.800000000000047,\n",
       " -7.790000000000047,\n",
       " -7.780000000000047,\n",
       " -7.7700000000000475,\n",
       " -7.760000000000048,\n",
       " -7.750000000000048,\n",
       " -7.740000000000048,\n",
       " -7.730000000000048,\n",
       " -7.720000000000049,\n",
       " -7.710000000000049,\n",
       " -7.700000000000049,\n",
       " -7.690000000000049,\n",
       " -7.6800000000000495,\n",
       " -7.67000000000005,\n",
       " -7.66000000000005,\n",
       " -7.65000000000005,\n",
       " -7.64000000000005,\n",
       " -7.6300000000000505,\n",
       " -7.620000000000051,\n",
       " -7.610000000000051,\n",
       " -7.600000000000051,\n",
       " -7.590000000000051,\n",
       " -7.580000000000052,\n",
       " -7.570000000000052,\n",
       " -7.560000000000052,\n",
       " -7.550000000000052,\n",
       " -7.540000000000052,\n",
       " -7.530000000000053,\n",
       " -7.520000000000053,\n",
       " -7.510000000000053,\n",
       " -7.500000000000053,\n",
       " -7.4900000000000535,\n",
       " -7.480000000000054,\n",
       " -7.470000000000054,\n",
       " -7.460000000000054,\n",
       " -7.450000000000054,\n",
       " -7.440000000000055,\n",
       " -7.430000000000055,\n",
       " -7.420000000000055,\n",
       " -7.410000000000055,\n",
       " -7.400000000000055,\n",
       " -7.390000000000056,\n",
       " -7.380000000000056,\n",
       " -7.370000000000056,\n",
       " -7.360000000000056,\n",
       " -7.3500000000000565,\n",
       " -7.340000000000057,\n",
       " -7.330000000000057,\n",
       " -7.320000000000057,\n",
       " -7.310000000000057,\n",
       " -7.3000000000000576,\n",
       " -7.290000000000058,\n",
       " -7.280000000000058,\n",
       " -7.270000000000058,\n",
       " -7.260000000000058,\n",
       " -7.250000000000059,\n",
       " -7.240000000000059,\n",
       " -7.230000000000059,\n",
       " -7.220000000000059,\n",
       " -7.2100000000000595,\n",
       " -7.20000000000006,\n",
       " -7.19000000000006,\n",
       " -7.18000000000006,\n",
       " -7.17000000000006,\n",
       " -7.1600000000000605,\n",
       " -7.150000000000061,\n",
       " -7.140000000000061,\n",
       " -7.130000000000061,\n",
       " -7.120000000000061,\n",
       " -7.110000000000062,\n",
       " -7.100000000000062,\n",
       " -7.090000000000062,\n",
       " -7.080000000000062,\n",
       " -7.0700000000000625,\n",
       " -7.060000000000063,\n",
       " -7.050000000000063,\n",
       " -7.040000000000063,\n",
       " -7.030000000000063,\n",
       " -7.0200000000000635,\n",
       " -7.010000000000064,\n",
       " -7.000000000000064,\n",
       " -6.990000000000064,\n",
       " -6.980000000000064,\n",
       " -6.970000000000065,\n",
       " -6.960000000000065,\n",
       " -6.950000000000065,\n",
       " -6.940000000000065,\n",
       " -6.930000000000065,\n",
       " -6.920000000000066,\n",
       " -6.910000000000066,\n",
       " -6.900000000000066,\n",
       " -6.890000000000066,\n",
       " -6.8800000000000665,\n",
       " -6.870000000000067,\n",
       " -6.860000000000067,\n",
       " -6.850000000000067,\n",
       " -6.840000000000067,\n",
       " -6.830000000000068,\n",
       " -6.820000000000068,\n",
       " -6.810000000000068,\n",
       " -6.800000000000068,\n",
       " -6.790000000000068,\n",
       " -6.780000000000069,\n",
       " -6.770000000000069,\n",
       " -6.760000000000069,\n",
       " -6.750000000000069,\n",
       " -6.7400000000000695,\n",
       " -6.73000000000007,\n",
       " -6.72000000000007,\n",
       " -6.71000000000007,\n",
       " -6.70000000000007,\n",
       " -6.690000000000071,\n",
       " -6.680000000000071,\n",
       " -6.670000000000071,\n",
       " -6.660000000000071,\n",
       " -6.650000000000071,\n",
       " -6.640000000000072,\n",
       " -6.630000000000072,\n",
       " -6.620000000000072,\n",
       " -6.610000000000072,\n",
       " -6.6000000000000725,\n",
       " -6.590000000000073,\n",
       " -6.580000000000073,\n",
       " -6.570000000000073,\n",
       " -6.560000000000073,\n",
       " -6.5500000000000735,\n",
       " -6.540000000000074,\n",
       " -6.530000000000074,\n",
       " -6.520000000000074,\n",
       " -6.510000000000074,\n",
       " -6.500000000000075,\n",
       " -6.490000000000075,\n",
       " -6.480000000000075,\n",
       " -6.470000000000075,\n",
       " -6.4600000000000755,\n",
       " -6.450000000000076,\n",
       " -6.440000000000076,\n",
       " -6.430000000000076,\n",
       " -6.420000000000076,\n",
       " -6.4100000000000765,\n",
       " -6.400000000000077,\n",
       " -6.390000000000077,\n",
       " -6.380000000000077,\n",
       " -6.370000000000077,\n",
       " -6.360000000000078,\n",
       " -6.350000000000078,\n",
       " -6.340000000000078,\n",
       " -6.330000000000078,\n",
       " -6.320000000000078,\n",
       " -6.310000000000079,\n",
       " -6.300000000000079,\n",
       " -6.290000000000079,\n",
       " -6.280000000000079,\n",
       " -6.2700000000000795,\n",
       " -6.26000000000008,\n",
       " -6.25000000000008,\n",
       " -6.24000000000008,\n",
       " -6.23000000000008,\n",
       " -6.220000000000081,\n",
       " -6.210000000000081,\n",
       " -6.200000000000081,\n",
       " -6.190000000000081,\n",
       " -6.180000000000081,\n",
       " -6.170000000000082,\n",
       " -6.160000000000082,\n",
       " -6.150000000000082,\n",
       " -6.140000000000082,\n",
       " -6.1300000000000825,\n",
       " -6.120000000000083,\n",
       " -6.110000000000083,\n",
       " -6.100000000000083,\n",
       " -6.090000000000083,\n",
       " -6.080000000000084,\n",
       " -6.070000000000084,\n",
       " -6.060000000000084,\n",
       " -6.050000000000084,\n",
       " -6.040000000000084,\n",
       " -6.030000000000085,\n",
       " -6.020000000000085,\n",
       " -6.010000000000085,\n",
       " -6.000000000000085,\n",
       " -5.9900000000000855,\n",
       " -5.980000000000086,\n",
       " -5.970000000000086,\n",
       " -5.960000000000086,\n",
       " -5.950000000000086,\n",
       " -5.9400000000000865,\n",
       " -5.930000000000087,\n",
       " -5.920000000000087,\n",
       " -5.910000000000087,\n",
       " -5.900000000000087,\n",
       " -5.890000000000088,\n",
       " -5.880000000000088,\n",
       " -5.870000000000088,\n",
       " -5.860000000000088,\n",
       " -5.8500000000000885,\n",
       " -5.840000000000089,\n",
       " -5.830000000000089,\n",
       " -5.820000000000089,\n",
       " -5.810000000000089,\n",
       " -5.8000000000000895,\n",
       " -5.79000000000009,\n",
       " -5.78000000000009,\n",
       " -5.77000000000009,\n",
       " -5.76000000000009,\n",
       " -5.750000000000091,\n",
       " -5.740000000000091,\n",
       " -5.730000000000091,\n",
       " -5.720000000000091,\n",
       " -5.7100000000000914,\n",
       " -5.700000000000092,\n",
       " -5.690000000000092,\n",
       " -5.680000000000092,\n",
       " -5.670000000000092,\n",
       " -5.6600000000000925,\n",
       " -5.650000000000093,\n",
       " -5.640000000000093,\n",
       " -5.630000000000093,\n",
       " -5.620000000000093,\n",
       " -5.610000000000094,\n",
       " -5.600000000000094,\n",
       " -5.590000000000094,\n",
       " -5.580000000000094,\n",
       " -5.570000000000094,\n",
       " -5.560000000000095,\n",
       " -5.550000000000095,\n",
       " -5.540000000000095,\n",
       " -5.530000000000095,\n",
       " -5.5200000000000955,\n",
       " -5.510000000000096,\n",
       " -5.500000000000096,\n",
       " -5.490000000000096,\n",
       " -5.480000000000096,\n",
       " -5.470000000000097,\n",
       " -5.460000000000097,\n",
       " -5.450000000000097,\n",
       " -5.440000000000097,\n",
       " -5.430000000000097,\n",
       " -5.420000000000098,\n",
       " -5.410000000000098,\n",
       " -5.400000000000098,\n",
       " -5.390000000000098,\n",
       " -5.3800000000000985,\n",
       " -5.370000000000099,\n",
       " -5.360000000000099,\n",
       " -5.350000000000099,\n",
       " -5.340000000000099,\n",
       " -5.3300000000000995,\n",
       " -5.3200000000001,\n",
       " -5.3100000000001,\n",
       " -5.3000000000001,\n",
       " -5.2900000000001,\n",
       " -5.280000000000101,\n",
       " -5.270000000000101,\n",
       " -5.260000000000101,\n",
       " -5.250000000000101,\n",
       " -5.2400000000001015,\n",
       " -5.230000000000102,\n",
       " -5.220000000000102,\n",
       " -5.210000000000102,\n",
       " -5.200000000000102,\n",
       " -5.1900000000001025,\n",
       " -5.180000000000103,\n",
       " -5.170000000000103,\n",
       " -5.160000000000103,\n",
       " -5.150000000000103,\n",
       " -5.140000000000104,\n",
       " -5.130000000000104,\n",
       " -5.120000000000104,\n",
       " -5.110000000000104,\n",
       " -5.1000000000001044,\n",
       " -5.090000000000105,\n",
       " -5.080000000000105,\n",
       " -5.070000000000105,\n",
       " -5.060000000000105,\n",
       " -5.0500000000001055,\n",
       " -5.040000000000106,\n",
       " -5.030000000000106,\n",
       " -5.020000000000106,\n",
       " -5.010000000000106,\n",
       " -5.000000000000107,\n",
       " -4.990000000000107,\n",
       " -4.980000000000107,\n",
       " -4.970000000000107,\n",
       " -4.960000000000107,\n",
       " -4.950000000000108,\n",
       " -4.940000000000108,\n",
       " -4.930000000000108,\n",
       " -4.920000000000108,\n",
       " -4.9100000000001085,\n",
       " -4.900000000000109,\n",
       " -4.890000000000109,\n",
       " -4.880000000000109,\n",
       " -4.870000000000109,\n",
       " -4.86000000000011,\n",
       " -4.85000000000011,\n",
       " -4.84000000000011,\n",
       " -4.83000000000011,\n",
       " -4.82000000000011,\n",
       " -4.810000000000111,\n",
       " -4.800000000000111,\n",
       " -4.790000000000111,\n",
       " -4.780000000000111,\n",
       " -4.7700000000001115,\n",
       " -4.760000000000112,\n",
       " -4.750000000000112,\n",
       " -4.740000000000112,\n",
       " -4.730000000000112,\n",
       " -4.7200000000001125,\n",
       " -4.710000000000113,\n",
       " -4.700000000000113,\n",
       " -4.690000000000113,\n",
       " -4.680000000000113,\n",
       " -4.670000000000114,\n",
       " -4.660000000000114,\n",
       " -4.650000000000114,\n",
       " -4.640000000000114,\n",
       " -4.6300000000001145,\n",
       " -4.620000000000115,\n",
       " -4.610000000000115,\n",
       " -4.600000000000115,\n",
       " -4.590000000000115,\n",
       " -4.5800000000001155,\n",
       " -4.570000000000116,\n",
       " -4.560000000000116,\n",
       " -4.550000000000116,\n",
       " -4.540000000000116,\n",
       " -4.530000000000117,\n",
       " -4.520000000000117,\n",
       " -4.510000000000117,\n",
       " -4.500000000000117,\n",
       " -4.4900000000001175,\n",
       " -4.480000000000118,\n",
       " -4.470000000000118,\n",
       " -4.460000000000118,\n",
       " -4.450000000000118,\n",
       " -4.4400000000001185,\n",
       " -4.430000000000119,\n",
       " -4.420000000000119,\n",
       " -4.410000000000119,\n",
       " -4.400000000000119,\n",
       " -4.39000000000012,\n",
       " -4.38000000000012,\n",
       " -4.37000000000012,\n",
       " -4.36000000000012,\n",
       " -4.35000000000012,\n",
       " -4.340000000000121,\n",
       " -4.330000000000121,\n",
       " -4.320000000000121,\n",
       " -4.310000000000121,\n",
       " -4.3000000000001215,\n",
       " -4.290000000000122,\n",
       " -4.280000000000122,\n",
       " -4.270000000000122,\n",
       " -4.260000000000122,\n",
       " -4.250000000000123,\n",
       " -4.240000000000123,\n",
       " -4.230000000000123,\n",
       " -4.220000000000123,\n",
       " -4.210000000000123,\n",
       " -4.200000000000124,\n",
       " -4.190000000000124,\n",
       " -4.180000000000124,\n",
       " -4.170000000000124,\n",
       " -4.1600000000001245,\n",
       " -4.150000000000125,\n",
       " -4.140000000000125,\n",
       " -4.130000000000125,\n",
       " -4.120000000000125,\n",
       " -4.1100000000001256,\n",
       " -4.100000000000126,\n",
       " -4.090000000000126,\n",
       " -4.080000000000126,\n",
       " -4.070000000000126,\n",
       " -4.060000000000127,\n",
       " -4.050000000000127,\n",
       " -4.040000000000127,\n",
       " -4.030000000000127,\n",
       " -4.0200000000001275,\n",
       " -4.010000000000128,\n",
       " -4.000000000000128,\n",
       " -3.990000000000128,\n",
       " -3.9800000000001283,\n",
       " -3.9700000000001285,\n",
       " -3.9600000000001288,\n",
       " -3.950000000000129,\n",
       " -3.940000000000129,\n",
       " -3.9300000000001294,\n",
       " -3.9200000000001296,\n",
       " -3.91000000000013,\n",
       " -3.90000000000013,\n",
       " -3.8900000000001302,\n",
       " -3.8800000000001305,\n",
       " -3.8700000000001307,\n",
       " -3.860000000000131,\n",
       " -3.850000000000131,\n",
       " -3.8400000000001313,\n",
       " -3.8300000000001315,\n",
       " -3.8200000000001317,\n",
       " -3.810000000000132,\n",
       " -3.800000000000132,\n",
       " -3.7900000000001324,\n",
       " -3.7800000000001326,\n",
       " -3.770000000000133,\n",
       " -3.760000000000133,\n",
       " -3.7500000000001332,\n",
       " -3.7400000000001334,\n",
       " -3.7300000000001337,\n",
       " -3.720000000000134,\n",
       " -3.710000000000134,\n",
       " -3.7000000000001343,\n",
       " -3.6900000000001345,\n",
       " -3.6800000000001347,\n",
       " -3.670000000000135,\n",
       " -3.660000000000135,\n",
       " -3.6500000000001354,\n",
       " -3.6400000000001356,\n",
       " -3.630000000000136,\n",
       " -3.620000000000136,\n",
       " -3.610000000000136,\n",
       " -3.6000000000001364,\n",
       " -3.5900000000001366,\n",
       " -3.580000000000137,\n",
       " -3.570000000000137,\n",
       " -3.5600000000001373,\n",
       " -3.5500000000001375,\n",
       " -3.5400000000001377,\n",
       " -3.530000000000138,\n",
       " -3.520000000000138,\n",
       " -3.5100000000001383,\n",
       " -3.5000000000001386,\n",
       " -3.4900000000001388,\n",
       " -3.480000000000139,\n",
       " -3.470000000000139,\n",
       " -3.4600000000001394,\n",
       " -3.4500000000001396,\n",
       " -3.44000000000014,\n",
       " -3.43000000000014,\n",
       " -3.4200000000001403,\n",
       " -3.4100000000001405,\n",
       " -3.4000000000001407,\n",
       " -3.390000000000141,\n",
       " -3.380000000000141,\n",
       " -3.3700000000001413,\n",
       " -3.3600000000001415,\n",
       " -3.3500000000001418,\n",
       " -3.340000000000142,\n",
       " -3.330000000000142,\n",
       " -3.3200000000001424,\n",
       " -3.3100000000001426,\n",
       " -3.300000000000143,\n",
       " -3.290000000000143,\n",
       " -3.2800000000001432,\n",
       " -3.2700000000001435,\n",
       " -3.2600000000001437,\n",
       " -3.250000000000144,\n",
       " -3.240000000000144,\n",
       " -3.2300000000001443,\n",
       " -3.2200000000001445,\n",
       " -3.2100000000001447,\n",
       " -3.200000000000145,\n",
       " -3.190000000000145,\n",
       " -3.1800000000001454,\n",
       " -3.1700000000001456,\n",
       " -3.160000000000146,\n",
       " -3.150000000000146,\n",
       " -3.1400000000001462,\n",
       " -3.1300000000001464,\n",
       " -3.1200000000001467,\n",
       " -3.110000000000147,\n",
       " -3.100000000000147,\n",
       " -3.0900000000001473,\n",
       " -3.0800000000001475,\n",
       " -3.0700000000001477,\n",
       " -3.060000000000148,\n",
       " -3.050000000000148,\n",
       " -3.0400000000001484,\n",
       " -3.0300000000001486,\n",
       " -3.020000000000149,\n",
       " -3.010000000000149,\n",
       " -3.000000000000149,\n",
       " -2.9900000000001494,\n",
       " -2.9800000000001496,\n",
       " -2.97000000000015,\n",
       " -2.96000000000015,\n",
       " -2.9500000000001503,\n",
       " -2.9400000000001505,\n",
       " -2.9300000000001507,\n",
       " -2.920000000000151,\n",
       " -2.910000000000151,\n",
       " -2.9000000000001513,\n",
       " -2.8900000000001516,\n",
       " -2.8800000000001518,\n",
       " -2.870000000000152,\n",
       " -2.860000000000152,\n",
       " -2.8500000000001524,\n",
       " -2.8400000000001526,\n",
       " -2.830000000000153,\n",
       " -2.820000000000153,\n",
       " -2.8100000000001533,\n",
       " -2.8000000000001535,\n",
       " -2.7900000000001537,\n",
       " -2.780000000000154,\n",
       " -2.770000000000154,\n",
       " -2.7600000000001543,\n",
       " -2.7500000000001545,\n",
       " -2.7400000000001548,\n",
       " -2.730000000000155,\n",
       " -2.720000000000155,\n",
       " -2.7100000000001554,\n",
       " -2.7000000000001556,\n",
       " -2.690000000000156,\n",
       " -2.680000000000156,\n",
       " -2.6700000000001562,\n",
       " -2.6600000000001565,\n",
       " -2.6500000000001567,\n",
       " -2.640000000000157,\n",
       " -2.630000000000157,\n",
       " -2.6200000000001573,\n",
       " -2.6100000000001575,\n",
       " -2.6000000000001577,\n",
       " -2.590000000000158,\n",
       " -2.580000000000158,\n",
       " -2.5700000000001584,\n",
       " -2.5600000000001586,\n",
       " -2.550000000000159,\n",
       " -2.540000000000159,\n",
       " -2.5300000000001592,\n",
       " -2.5200000000001594,\n",
       " -2.5100000000001597,\n",
       " -2.50000000000016,\n",
       " -2.49000000000016,\n",
       " -2.4800000000001603,\n",
       " -2.4700000000001605,\n",
       " -2.4600000000001607,\n",
       " -2.450000000000161,\n",
       " -2.440000000000161,\n",
       " -2.4300000000001614,\n",
       " -2.4200000000001616,\n",
       " -2.410000000000162,\n",
       " -2.400000000000162,\n",
       " -2.390000000000162,\n",
       " -2.3800000000001624,\n",
       " -2.3700000000001626,\n",
       " -2.360000000000163,\n",
       " -2.350000000000163,\n",
       " -2.3400000000001633,\n",
       " -2.3300000000001635,\n",
       " -2.3200000000001637,\n",
       " -2.310000000000164,\n",
       " -2.300000000000164,\n",
       " -2.2900000000001643,\n",
       " -2.2800000000001646,\n",
       " -2.2700000000001648,\n",
       " -2.260000000000165,\n",
       " -2.250000000000165,\n",
       " -2.2400000000001654,\n",
       " -2.2300000000001656,\n",
       " -2.220000000000166,\n",
       " -2.210000000000166,\n",
       " -2.2000000000001663,\n",
       " -2.1900000000001665,\n",
       " -2.1800000000001667,\n",
       " -2.170000000000167,\n",
       " -2.160000000000167,\n",
       " -2.1500000000001673,\n",
       " -2.1400000000001675,\n",
       " -2.1300000000001678,\n",
       " -2.120000000000168,\n",
       " -2.110000000000168,\n",
       " -2.1000000000001684,\n",
       " -2.0900000000001686,\n",
       " -2.080000000000169,\n",
       " -2.070000000000169,\n",
       " -2.0600000000001693,\n",
       " -2.0500000000001695,\n",
       " -2.0400000000001697,\n",
       " -2.03000000000017,\n",
       " -2.02000000000017,\n",
       " -2.0100000000001703,\n",
       " -2.0000000000001705,\n",
       " -1.9900000000001707,\n",
       " -1.980000000000171,\n",
       " -1.9700000000001712,\n",
       " -1.9600000000001714,\n",
       " -1.9500000000001716,\n",
       " -1.9400000000001718,\n",
       " -1.930000000000172,\n",
       " -1.9200000000001722,\n",
       " -1.9100000000001724,\n",
       " -1.9000000000001727,\n",
       " -1.8900000000001729,\n",
       " -1.880000000000173,\n",
       " -1.8700000000001733,\n",
       " -1.8600000000001735,\n",
       " -1.8500000000001737,\n",
       " -1.840000000000174,\n",
       " -1.8300000000001742,\n",
       " -1.8200000000001744,\n",
       " -1.8100000000001746,\n",
       " -1.8000000000001748,\n",
       " -1.790000000000175,\n",
       " -1.7800000000001752,\n",
       " -1.7700000000001754,\n",
       " -1.7600000000001756,\n",
       " -1.7500000000001759,\n",
       " -1.740000000000176,\n",
       " -1.7300000000001763,\n",
       " -1.7200000000001765,\n",
       " -1.7100000000001767,\n",
       " -1.700000000000177,\n",
       " -1.6900000000001771,\n",
       " -1.6800000000001774,\n",
       " -1.6700000000001776,\n",
       " -1.6600000000001778,\n",
       " -1.650000000000178,\n",
       " -1.6400000000001782,\n",
       " -1.6300000000001784,\n",
       " -1.6200000000001786,\n",
       " -1.6100000000001788,\n",
       " -1.600000000000179,\n",
       " -1.5900000000001793,\n",
       " -1.5800000000001795,\n",
       " -1.5700000000001797,\n",
       " -1.56000000000018,\n",
       " -1.5500000000001801,\n",
       " -1.5400000000001803,\n",
       " -1.5300000000001805,\n",
       " -1.5200000000001808,\n",
       " -1.510000000000181,\n",
       " -1.5000000000001812,\n",
       " -1.4900000000001814,\n",
       " -1.4800000000001816,\n",
       " -1.4700000000001818,\n",
       " -1.460000000000182,\n",
       " -1.4500000000001823,\n",
       " -1.4400000000001825,\n",
       " -1.4300000000001827,\n",
       " -1.420000000000183,\n",
       " -1.410000000000183,\n",
       " -1.4000000000001833,\n",
       " -1.3900000000001835,\n",
       " -1.3800000000001837,\n",
       " -1.370000000000184,\n",
       " -1.3600000000001842,\n",
       " -1.3500000000001844,\n",
       " -1.3400000000001846,\n",
       " -1.3300000000001848,\n",
       " -1.320000000000185,\n",
       " -1.3100000000001852,\n",
       " -1.3000000000001855,\n",
       " -1.2900000000001857,\n",
       " -1.2800000000001859,\n",
       " -1.270000000000186,\n",
       " -1.2600000000001863,\n",
       " -1.2500000000001865,\n",
       " -1.2400000000001867,\n",
       " -1.230000000000187,\n",
       " -1.2200000000001872,\n",
       " -1.2100000000001874,\n",
       " -1.2000000000001876,\n",
       " -1.1900000000001878,\n",
       " -1.180000000000188,\n",
       " -1.1700000000001882,\n",
       " -1.1600000000001884,\n",
       " -1.1500000000001886,\n",
       " -1.1400000000001889,\n",
       " -1.130000000000189,\n",
       " -1.1200000000001893,\n",
       " -1.1100000000001895,\n",
       " -1.1000000000001897,\n",
       " -1.09000000000019,\n",
       " -1.0800000000001901,\n",
       " -1.0700000000001904,\n",
       " -1.0600000000001906,\n",
       " -1.0500000000001908,\n",
       " -1.040000000000191,\n",
       " -1.0300000000001912,\n",
       " -1.0200000000001914,\n",
       " -1.0100000000001916,\n",
       " -1.0000000000001918,\n",
       " -0.9900000000001921,\n",
       " -0.9800000000001923,\n",
       " -0.9700000000001925,\n",
       " -0.9600000000001927,\n",
       " -0.9500000000001929,\n",
       " -0.9400000000001931,\n",
       " -0.9300000000001933,\n",
       " -0.9200000000001936,\n",
       " -0.9100000000001938,\n",
       " -0.900000000000194,\n",
       " -0.8900000000001942,\n",
       " -0.8800000000001944,\n",
       " -0.8700000000001946,\n",
       " -0.8600000000001948,\n",
       " -0.850000000000195,\n",
       " -0.8400000000001953,\n",
       " -0.8300000000001955,\n",
       " -0.8200000000001957,\n",
       " -0.8100000000001959,\n",
       " -0.8000000000001961,\n",
       " -0.7900000000001963,\n",
       " -0.7800000000001965,\n",
       " -0.7700000000001967,\n",
       " -0.760000000000197,\n",
       " -0.7500000000001972,\n",
       " -0.7400000000001974,\n",
       " -0.7300000000001976,\n",
       " -0.7200000000001978,\n",
       " -0.710000000000198,\n",
       " -0.7000000000001982,\n",
       " -0.6900000000001985,\n",
       " -0.6800000000001987,\n",
       " -0.6700000000001989,\n",
       " -0.6600000000001991,\n",
       " -0.6500000000001993,\n",
       " -0.6400000000001995,\n",
       " -0.6300000000001997,\n",
       " -0.6200000000002,\n",
       " -0.6100000000002002,\n",
       " -0.6000000000002004,\n",
       " -0.5900000000002006,\n",
       " -0.5800000000002008,\n",
       " -0.570000000000201,\n",
       " -0.5600000000002012,\n",
       " -0.5500000000002014,\n",
       " -0.5400000000002017,\n",
       " -0.5300000000002019,\n",
       " -0.5200000000002021,\n",
       " -0.5100000000002023,\n",
       " -0.5000000000002025,\n",
       " -0.4900000000002027,\n",
       " -0.48000000000020293,\n",
       " -0.47000000000020314,\n",
       " -0.46000000000020336,\n",
       " -0.45000000000020357,\n",
       " -0.4400000000002038,\n",
       " -0.430000000000204,\n",
       " -0.4200000000002042,\n",
       " -0.4100000000002044,\n",
       " -0.40000000000020464,\n",
       " -0.39000000000020485,\n",
       " -0.38000000000020506,\n",
       " -0.3700000000002053,\n",
       " -0.3600000000002055,\n",
       " -0.3500000000002057,\n",
       " -0.3400000000002059,\n",
       " -0.33000000000020613,\n",
       " -0.32000000000020634,\n",
       " -0.31000000000020655,\n",
       " -0.30000000000020677,\n",
       " -0.290000000000207,\n",
       " -0.2800000000002072,\n",
       " -0.2700000000002074,\n",
       " -0.2600000000002076,\n",
       " -0.25000000000020783,\n",
       " -0.24000000000020805,\n",
       " -0.23000000000020826,\n",
       " -0.22000000000020847,\n",
       " -0.2100000000002087,\n",
       " -0.2000000000002089,\n",
       " -0.1900000000002091,\n",
       " -0.18000000000020933,\n",
       " -0.17000000000020954,\n",
       " -0.16000000000020975,\n",
       " -0.15000000000020997,\n",
       " -0.14000000000021018,\n",
       " -0.1300000000002104,\n",
       " -0.1200000000002106,\n",
       " -0.11000000000021082,\n",
       " -0.10000000000021103,\n",
       " -0.09000000000021124,\n",
       " -0.08000000000021146,\n",
       " -0.07000000000021167,\n",
       " -0.060000000000211884,\n",
       " -0.0500000000002121,\n",
       " -0.04000000000021231,\n",
       " -0.030000000000212523,\n",
       " -0.020000000000212736,\n",
       " -0.01000000000021295,\n",
       " ...]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(np.arange(-10,0,0.01)) + list(np.arange(0,10, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ed892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "648bc100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 0.45336023, -0.9794788 ,  0.64927137, -0.87026834],\n",
       "       [ 0.12372956,  0.8818089 ,  2.1138792 , -0.79620713]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7008ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d932b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1fdc473e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 0.34056675,  0.66649157, -1.677834  ,  0.29489797],\n",
       "       [-0.1447164 ,  0.05614753, -0.79268354, -0.20606565]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas_w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8a61142c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.04010563, -0.06534716,  0.02347064, -0.06697482], dtype=float32)>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "01e5cd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.08302011,  0.01551136,  0.25632986, -0.00209872], dtype=float32)>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "638c7730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.4291447 , 0.80858517, 2.328592  , 0.64876103], dtype=float32)>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas_b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7f99a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = dense1.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "93191060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'b:0' shape=(4,) dtype=float32, numpy=array([ 0.04010563, -0.06534716,  0.02347064, -0.06697482], dtype=float32)>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "22669136",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = tf.expand_dims(dense1.b, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "eab28264",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = tf.concat([b1, w1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "23ec1bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[ 0.04010563, -0.06534716,  0.02347064, -0.06697482],\n",
       "       [ 0.41930357, -1.0461279 ,  0.81705475, -0.89975816],\n",
       "       [ 0.1382012 ,  0.8761941 ,  2.1931477 , -0.77560055]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38fd4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2bf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "70626c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = dense2.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "404e3fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = dense2.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8f7132f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta2 = tf.concat([tf.expand_dims(b2, axis=0), w2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "78ef1445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[ 0.7815066 ],\n",
       "       [ 0.3895463 ],\n",
       "       [-2.1350412 ],\n",
       "       [-0.14336525],\n",
       "       [-0.19272782]], dtype=float32)>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "46bfaff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} ConcatOp : Dimension 1 in both shapes must be equal: shape[0] = [1,3,4] vs. shape[1] = [1,5,1] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-224-e03a1498bf91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7208\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7209\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} ConcatOp : Dimension 1 in both shapes must be equal: shape[0] = [1,3,4] vs. shape[1] = [1,5,1] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "tf.concat([tf.expand_dims(theta1, axis=0), tf.expand_dims(theta2, axis=0)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a51a30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c46cce44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(preds,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7b6db01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6953f241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
